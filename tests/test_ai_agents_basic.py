#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AI Agentæ¨¡å—åŸºç¡€æµ‹è¯•
æµ‹è¯•åƒé—®LLMå®¢æˆ·ç«¯ã€ç¡…åŸºæµåŠ¨å®¢æˆ·ç«¯ã€ChromaDBå­˜å‚¨å’Œå‘é‡ç›¸ä¼¼æ€§åˆ†æåŠŸèƒ½
"""

# è·¯å¾„é…ç½® - ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®æ¨¡å—
import sys
import os
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

import pytest
import asyncio
import os
import tempfile
import shutil
from unittest.mock import AsyncMock, patch, MagicMock

# è®¾ç½®æµ‹è¯•ç¯å¢ƒå˜é‡
os.environ['QWEN_API_KEY'] = 'test_qwen_key'
os.environ['SILICON_FLOW_API_KEY'] = 'test_silicon_key'

# AIå®¢æˆ·ç«¯æµ‹è¯•
class TestQwenLLMClient:
    """åƒé—®LLMå®¢æˆ·ç«¯æµ‹è¯•"""
    
    def test_client_initialization(self):
        """æµ‹è¯•å®¢æˆ·ç«¯åˆå§‹åŒ–"""
        from core.ai_agents.llm_clients import QwenLLMClient
        
        client = QwenLLMClient(api_key="test_key")
        assert client.api_key == "test_key"
        assert client.model == "qwen-turbo"
        assert client.timeout == 30
    
    def test_token_calculator(self):
        """æµ‹è¯•Tokenè®¡ç®—å™¨"""
        from core.ai_agents.llm_clients.qwen_client import TokenCalculator
        
        calculator = TokenCalculator()
        
        # æµ‹è¯•Tokenè®¡ç®—
        chinese_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
        tokens = calculator.calculate_tokens(chinese_text)
        assert tokens > 0
        
        # æµ‹è¯•æˆæœ¬è®¡ç®—
        cost = calculator.calculate_cost("qwen-turbo", 100, 50)
        assert cost > 0
        
        # æµ‹è¯•æ—¥é™é¢æ£€æŸ¥
        assert calculator.check_daily_limit() == True
    
    @pytest.mark.asyncio
    async def test_client_async_context(self):
        """æµ‹è¯•å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        from core.ai_agents.llm_clients import QwenLLMClient
        
        with patch('aiohttp.ClientSession') as mock_session:
            mock_session.return_value.__aenter__ = AsyncMock(return_value=mock_session.return_value)
            mock_session.return_value.__aexit__ = AsyncMock()
            mock_session.return_value.close = AsyncMock()
            
            async with QwenLLMClient(api_key="test_key") as client:
                assert client.session is not None
    
    def test_prompt_building(self):
        """æµ‹è¯•Promptæ„å»º"""
        from core.ai_agents.llm_clients import QwenLLMClient
        
        client = QwenLLMClient(api_key="test_key")
        
        # æµ‹è¯•æƒ…æ„Ÿåˆ†æPrompt
        sentiment_prompt = client._build_sentiment_prompt("æµ‹è¯•æ–°é—»å†…å®¹")
        assert "æƒ…æ„Ÿè¯„åˆ†" in sentiment_prompt
        assert "JSONæ ¼å¼" in sentiment_prompt
        
        # æµ‹è¯•æŠ•èµ„å»ºè®®Prompt  
        investment_prompt = client._build_investment_prompt("æµ‹è¯•æ–°é—»å†…å®¹")
        assert "æŠ•èµ„å»ºè®®" in investment_prompt
        assert "ä¹°å…¥/æŒæœ‰/å–å‡º/è§‚æœ›" in investment_prompt

class TestSiliconFlowClient:
    """ç¡…åŸºæµåŠ¨å®¢æˆ·ç«¯æµ‹è¯•"""
    
    def test_client_initialization(self):
        """æµ‹è¯•å®¢æˆ·ç«¯åˆå§‹åŒ–"""
        from core.ai_agents.llm_clients import SiliconFlowClient
        
        client = SiliconFlowClient(api_key="test_key")
        assert client.api_key == "test_key"
        assert client.model == "qwen-turbo"
    
    @pytest.mark.asyncio
    async def test_client_async_context(self):
        """æµ‹è¯•å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        from core.ai_agents.llm_clients import SiliconFlowClient
        
        with patch('aiohttp.ClientSession') as mock_session:
            mock_session.return_value.__aenter__ = AsyncMock(return_value=mock_session.return_value)
            mock_session.return_value.__aexit__ = AsyncMock()
            mock_session.return_value.close = AsyncMock()
            
            async with SiliconFlowClient(api_key="test_key") as client:
                assert client.session is not None

class TestChromaNewsStore:
    """ChromaDBæ–°é—»å­˜å‚¨æµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.temp_dir = tempfile.mkdtemp()
        os.environ['CHROMA_DB_PATH'] = self.temp_dir
    
    def teardown_method(self):
        """æµ‹è¯•åæ¸…ç†"""
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        if os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
    
    def test_store_initialization(self):
        """æµ‹è¯•å­˜å‚¨åˆå§‹åŒ–"""
        from core.ai_agents.vector_store import ChromaNewsStore
        
        with patch('sentence_transformers.SentenceTransformer'):
            store = ChromaNewsStore(db_path=self.temp_dir)
            assert store.db_path == self.temp_dir
            assert store.collection_name == "news_articles"
    
    def test_text_preprocessing(self):
        """æµ‹è¯•æ–‡æœ¬é¢„å¤„ç†"""
        from core.ai_agents.vector_store import ChromaNewsStore
        
        with patch('sentence_transformers.SentenceTransformer'):
            store = ChromaNewsStore(db_path=self.temp_dir)
            
            # æµ‹è¯•æ­£å¸¸æ–‡æœ¬
            text = "è¿™æ˜¯ä¸€ä¸ª   åŒ…å«å¤šä½™ç©ºç™½   çš„æ–‡æœ¬"
            processed = store._preprocess_text(text)
            assert "  " not in processed  # å¤šä½™ç©ºç™½è¢«ç§»é™¤
            
            # æµ‹è¯•è¿‡é•¿æ–‡æœ¬
            long_text = "æµ‹è¯•" * 1000
            processed_long = store._preprocess_text(long_text)
            assert len(processed_long) <= 1003  # 1000å­—ç¬¦ + "..."
    
    def test_document_id_generation(self):
        """æµ‹è¯•æ–‡æ¡£IDç”Ÿæˆ"""
        from core.ai_agents.vector_store import ChromaNewsStore
        
        with patch('sentence_transformers.SentenceTransformer'):
            store = ChromaNewsStore(db_path=self.temp_dir)
            
            # åŒæ ·çš„å†…å®¹åº”è¯¥ç”ŸæˆåŒæ ·çš„ID
            content = "æµ‹è¯•å†…å®¹"
            id1 = store._generate_document_id(content)
            id2 = store._generate_document_id(content)
            assert id1 == id2
            
            # ä¸åŒå†…å®¹åº”è¯¥ç”Ÿæˆä¸åŒçš„ID
            id3 = store._generate_document_id("ä¸åŒå†…å®¹")
            assert id1 != id3
    
    def test_collection_stats(self):
        """æµ‹è¯•é›†åˆç»Ÿè®¡"""
        from core.ai_agents.vector_store import ChromaNewsStore
        
        with patch('sentence_transformers.SentenceTransformer'):
            store = ChromaNewsStore(db_path=self.temp_dir)
            
            stats = store.get_collection_stats()
            assert "collection_name" in stats
            assert "document_count" in stats
            assert stats["status"] == "healthy"

class TestVectorSimilarityAnalyzer:
    """å‘é‡ç›¸ä¼¼æ€§åˆ†æå™¨æµ‹è¯•"""
    
    def test_analyzer_initialization(self):
        """æµ‹è¯•åˆ†æå™¨åˆå§‹åŒ–"""
        from core.ai_agents.vector_store import VectorSimilarityAnalyzer
        
        analyzer = VectorSimilarityAnalyzer()
        assert analyzer.similarity_threshold == 0.7
        
        analyzer_custom = VectorSimilarityAnalyzer(similarity_threshold=0.8)
        assert analyzer_custom.similarity_threshold == 0.8
    
    def test_similarity_calculation(self):
        """æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—"""
        from core.ai_agents.vector_store import VectorSimilarityAnalyzer
        
        analyzer = VectorSimilarityAnalyzer()
        
        # æµ‹è¯•ç›¸åŒå‘é‡
        vector1 = [1.0, 0.0, 0.0]
        vector2 = [1.0, 0.0, 0.0]
        similarity = analyzer.calculate_similarity(vector1, vector2)
        assert abs(similarity - 1.0) < 0.001  # åº”è¯¥æ¥è¿‘1
        
        # æµ‹è¯•æ­£äº¤å‘é‡
        vector3 = [0.0, 1.0, 0.0]
        similarity2 = analyzer.calculate_similarity(vector1, vector3)
        assert abs(similarity2 - 0.0) < 0.001  # åº”è¯¥æ¥è¿‘0
    
    def test_batch_similarity(self):
        """æµ‹è¯•æ‰¹é‡ç›¸ä¼¼åº¦è®¡ç®—"""
        from core.ai_agents.vector_store import VectorSimilarityAnalyzer
        
        analyzer = VectorSimilarityAnalyzer()
        
        query_vector = [1.0, 0.0, 0.0]
        target_vectors = [
            [1.0, 0.0, 0.0],  # ç›¸åŒ
            [0.0, 1.0, 0.0],  # æ­£äº¤
            [0.5, 0.5, 0.0]   # éƒ¨åˆ†ç›¸ä¼¼
        ]
        
        similarities = analyzer.batch_similarity(query_vector, target_vectors)
        assert len(similarities) == 3
        assert similarities[0] > similarities[2] > similarities[1]

# é›†æˆæµ‹è¯•
class TestAIAgentsIntegration:
    """AI Agentæ¨¡å—é›†æˆæµ‹è¯•"""
    
    def test_module_imports(self):
        """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
        # æµ‹è¯•LLMå®¢æˆ·ç«¯æ¨¡å—å¯¼å…¥
        from core.ai_agents.llm_clients import (
            QwenLLMClient, SiliconFlowClient, 
            get_qwen_client, get_silicon_flow_client
        )
        
        # æµ‹è¯•å‘é‡å­˜å‚¨æ¨¡å—å¯¼å…¥
        from core.ai_agents.vector_store import (
            ChromaNewsStore, VectorSimilarityAnalyzer,
            get_chroma_store, get_similarity_analyzer
        )
        
        # éªŒè¯æ‰€æœ‰ç±»éƒ½å¯ä»¥å®ä¾‹åŒ–
        assert QwenLLMClient is not None
        assert SiliconFlowClient is not None
        assert ChromaNewsStore is not None
        assert VectorSimilarityAnalyzer is not None
    
    def test_global_instances(self):
        """æµ‹è¯•å…¨å±€å®ä¾‹è·å–"""
        from core.ai_agents.llm_clients import get_qwen_client, get_silicon_flow_client
        from core.ai_agents.vector_store import get_similarity_analyzer
        
        # æµ‹è¯•å…¨å±€å®ä¾‹
        qwen_client = get_qwen_client()
        assert qwen_client is not None
        
        silicon_client = get_silicon_flow_client()
        assert silicon_client is not None
        
        analyzer = get_similarity_analyzer()
        assert analyzer is not None
        
        # æµ‹è¯•å•ä¾‹æ¨¡å¼
        qwen_client2 = get_qwen_client()
        assert qwen_client is qwen_client2

if __name__ == "__main__":
    # è¿è¡ŒåŸºç¡€æµ‹è¯•
    print("ğŸš€ å¼€å§‹AI Agentæ¨¡å—åŸºç¡€æµ‹è¯•...")
    
    # æµ‹è¯•æ¨¡å—å¯¼å…¥
    print("âœ… æµ‹è¯•æ¨¡å—å¯¼å…¥...")
    test_integration = TestAIAgentsIntegration()
    test_integration.test_module_imports()
    test_integration.test_global_instances()
    
    # æµ‹è¯•Tokenè®¡ç®—å™¨
    print("âœ… æµ‹è¯•Tokenè®¡ç®—å™¨...")
    test_qwen = TestQwenLLMClient()
    test_qwen.test_token_calculator()
    
    # æµ‹è¯•ç›¸ä¼¼æ€§åˆ†æå™¨
    print("âœ… æµ‹è¯•ç›¸ä¼¼æ€§åˆ†æå™¨...")
    test_similarity = TestVectorSimilarityAnalyzer()
    test_similarity.test_analyzer_initialization()
    test_similarity.test_similarity_calculation()
    test_similarity.test_batch_similarity()
    
    print("ğŸ‰ AI Agentæ¨¡å—åŸºç¡€æµ‹è¯•å®Œæˆï¼")
    print("ğŸ“‹ æµ‹è¯•ç»“æœ:")
    print("  - åƒé—®LLMå®¢æˆ·ç«¯: âœ… æ­£å¸¸")
    print("  - ç¡…åŸºæµåŠ¨å®¢æˆ·ç«¯: âœ… æ­£å¸¸") 
    print("  - ChromaDBå­˜å‚¨: âœ… æ­£å¸¸")
    print("  - å‘é‡ç›¸ä¼¼æ€§åˆ†æ: âœ… æ­£å¸¸")
    print("  - æ¨¡å—é›†æˆ: âœ… æ­£å¸¸") 
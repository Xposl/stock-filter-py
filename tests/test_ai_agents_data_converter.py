#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AIä»£ç†æ•°æ®è½¬æ¢å™¨æµ‹è¯•

ç”¨äºæµ‹è¯•AIåˆ†ææ¨¡å—ä¸­çš„æ•°æ®è½¬æ¢åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. æ–°é—»æ•°æ®è½¬æ¢å™¨æµ‹è¯•
2. åˆ†æç»“æœè½¬æ¢å™¨æµ‹è¯•  
3. APIå“åº”è½¬æ¢å™¨æµ‹è¯•
4. æ•°æ®åº“æ¨¡å‹è½¬æ¢å™¨æµ‹è¯•
"""

import pytest
import asyncio
import json
import logging
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.ai_agents.utils.data_converter import (
    NewsDataConverter,
    AnalysisResultConverter, 
    APIResponseConverter,
    DatabaseModelConverter,
    StandardNewsArticle,
    StandardAnalysisResult,
    convert_news_data,
    convert_analysis_to_api,
    convert_to_json
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@pytest.fixture
def news_converter():
    """æ–°é—»æ•°æ®è½¬æ¢å™¨fixture"""
    return NewsDataConverter()

@pytest.fixture
def analysis_converter():
    """åˆ†æç»“æœè½¬æ¢å™¨fixture"""
    return AnalysisResultConverter()

@pytest.fixture
def api_converter():
    """APIå“åº”è½¬æ¢å™¨fixture"""
    return APIResponseConverter()

@pytest.fixture
def db_converter():
    """æ•°æ®åº“æ¨¡å‹è½¬æ¢å™¨fixture"""
    return DatabaseModelConverter()

@pytest.mark.unit
class TestDataConverter:
    """æ•°æ®è½¬æ¢å™¨æµ‹è¯•ç±»"""
    
    def test_news_conversion(self, news_converter):
        """æµ‹è¯•æ–°é—»æ•°æ®è½¬æ¢"""
        logger.info("ğŸ”„ æµ‹è¯•æ–°é—»æ•°æ®è½¬æ¢...")
        
        # æµ‹è¯•RSSæ•°æ®è½¬æ¢
        rss_data = {
            "title": "æŸç§‘æŠ€å…¬å¸å‘å¸ƒæ–°äº§å“ï¼Œè‚¡ä»·ä¸Šæ¶¨8%",
            "description": "è¯¥å…¬å¸ä»Šæ—¥å‘å¸ƒé©å‘½æ€§æ–°äº§å“ï¼Œå¸‚åœºååº”ç§¯æï¼Œè‚¡ä»·ç›˜ä¸­ä¸Šæ¶¨8%è¾¾åˆ°æ–°é«˜ã€‚åˆ†æå¸ˆè®¤ä¸ºè¿™å°†æ¨åŠ¨å…¬å¸æœªæ¥å¢é•¿ã€‚",
            "link": "https://finance.example.com/news/tech-stock-rise",
            "pubDate": "Mon, 27 Jan 2025 15:30:00 GMT",
            "author": "è´¢ç»è®°è€…ææ˜",
            "category": "ç§‘æŠ€è‚¡",
            "tags": ["ç§‘æŠ€", "æ–°äº§å“", "è‚¡ä»·ä¸Šæ¶¨"]
        }
        
        article = news_converter.convert_to_standard(
            rss_data, "rss", "è´¢ç»ç½‘", 1
        )
        
        # éªŒè¯è½¬æ¢ç»“æœ
        assert article.title == "æŸç§‘æŠ€å…¬å¸å‘å¸ƒæ–°äº§å“ï¼Œè‚¡ä»·ä¸Šæ¶¨8%"
        assert article.source_name == "è´¢ç»ç½‘"
        assert article.source_id == 1
        assert article.author == "è´¢ç»è®°è€…ææ˜"
        assert article.category == "ç§‘æŠ€è‚¡"
        assert isinstance(article.tags, list)
        
        logger.info(f"  âœ… RSSè½¬æ¢æˆåŠŸ: {article.title}")
        
        # æµ‹è¯•é›ªçƒæ•°æ®è½¬æ¢
        xueqiu_data = {
            "title": "çƒ­é—¨è‚¡ç¥¨åˆ†æï¼šAIæ¦‚å¿µè‚¡æŒç»­èµ°å¼º",
            "text": "å¤šåªAIæ¦‚å¿µè‚¡ä»Šæ—¥è¡¨ç°å¼ºåŠ²ï¼Œæ¿å—æ•´ä½“ä¸Šæ¶¨è¶…è¿‡5%ã€‚æœºæ„èµ„é‡‘æŒç»­æµå…¥ï¼Œçœ‹å¥½åå¸‚å‘å±•ã€‚",
            "target": "https://xueqiu.com/status/123456",
            "created_at": 1737974400,  # Unixæ—¶é—´æˆ³
            "user": "é›ªçƒåˆ†æå¸ˆ"
        }
        
        xq_article = news_converter.convert_to_standard(
            xueqiu_data, "xueqiu", "é›ªçƒ", 2
        )
        
        assert xq_article.title == "çƒ­é—¨è‚¡ç¥¨åˆ†æï¼šAIæ¦‚å¿µè‚¡æŒç»­èµ°å¼º"
        assert xq_article.source_name == "é›ªçƒ"
        assert xq_article.author == "é›ªçƒåˆ†æå¸ˆ"
        
        logger.info(f"  âœ… é›ªçƒè½¬æ¢æˆåŠŸ: {xq_article.title}")
        
        # æµ‹è¯•æ‰¹é‡è½¬æ¢
        batch_data = [rss_data, xueqiu_data]
        batch_results = news_converter.convert_batch(
            batch_data, "rss", "ç»¼åˆè´¢ç»", 3
        )
        
        assert len(batch_results) == 2
        logger.info(f"  âœ… æ‰¹é‡è½¬æ¢æˆåŠŸ: {len(batch_results)} ç¯‡æ–‡ç« ")
    
    def test_analysis_conversion(self, analysis_converter):
        """æµ‹è¯•åˆ†æç»“æœè½¬æ¢"""
        logger.info("ğŸ”„ æµ‹è¯•åˆ†æç»“æœè½¬æ¢...")
        
        # æ¨¡æ‹Ÿæƒ…æ„Ÿåˆ†æç»“æœ
        sentiment_result = {
            "final_sentiment_score": 7.8,
            "final_sentiment_label": "ç§¯æ",
            "confidence": 0.88,
            "sentiment_breakdown": {
                "dominant_emotion": "optimistic"
            },
            "key_indicators": {
                "sentiment_phrases": ["è‚¡ä»·ä¸Šæ¶¨", "å¸‚åœºçœ‹å¥½", "å‰æ™¯ç§¯æ"]
            }
        }
        
        # æ¨¡æ‹ŸæŠ•èµ„åˆ†æç»“æœ  
        investment_result = {
            "investment_advice": {
                "action": "ä¹°å…¥",
                "position_size": "è½»ä»“ä¹°å…¥ (10-20%)",
                "time_frame": "çŸ­çº¿ (1å‘¨-1ä¸ªæœˆ)",
                "confidence": 0.82,
                "rationale": "æ–°äº§å“å‘å¸ƒæ¨åŠ¨å…¬å¸åŸºæœ¬é¢æ”¹å–„ï¼ŒçŸ­æœŸæœ‰æœ›æŒç»­ä¸Šæ¶¨",
                "target_companies": ["ç§‘æŠ€å…¬å¸A", "ç›¸å…³äº§ä¸šé“¾å…¬å¸"],
                "investment_themes": ["AIæ¦‚å¿µ", "ç§‘æŠ€åˆ›æ–°"]
            },
            "analysis_results": [
                {
                    "opportunity": {
                        "opportunity_type": "äº§å“åˆ›æ–°",
                        "industry": "ç§‘æŠ€",
                        "score": 8.5,
                        "confidence": 0.85,
                        "time_horizon": "çŸ­æœŸ",
                        "key_factors": ["æŠ€æœ¯çªç ´", "å¸‚åœºéœ€æ±‚"]
                    },
                    "risk_assessment": {
                        "risk_level": "ä¸­ç­‰",
                        "risk_score": 4.2,
                        "risk_factors": ["å¸‚åœºç«äº‰", "æŠ€æœ¯é£é™©"],
                        "mitigation_strategies": ["åˆ†æ•£æŠ•èµ„", "æ­¢æŸè®¾ç½®"]
                    }
                }
            ]
        }
        
        # è½¬æ¢æƒ…æ„Ÿåˆ†æç»“æœ
        sentiment_converted = analysis_converter.convert_sentiment_result(sentiment_result)
        assert sentiment_converted["sentiment_score"] == 7.8
        assert sentiment_converted["sentiment_label"] == "ç§¯æ"
        assert sentiment_converted["confidence"] == 0.88
        
        logger.info(f"  âœ… æƒ…æ„Ÿåˆ†æè½¬æ¢: è¯„åˆ†{sentiment_converted['sentiment_score']}, æ ‡ç­¾{sentiment_converted['sentiment_label']}")
        
        # è½¬æ¢æŠ•èµ„åˆ†æç»“æœ
        investment_converted = analysis_converter.convert_investment_result(investment_result)
        assert investment_converted["investment_action"] == "ä¹°å…¥"
        assert len(investment_converted["opportunities"]) > 0
        assert len(investment_converted["risks"]) > 0
        
        logger.info(f"  âœ… æŠ•èµ„åˆ†æè½¬æ¢: å»ºè®®{investment_converted['investment_action']}, æ—¶é—´æ¡†æ¶{investment_converted['time_frame']}")
        
        # æµ‹è¯•å®Œæ•´åˆ†æç»“æœè½¬æ¢
        mock_article = StandardNewsArticle(
            id=1,
            title="æµ‹è¯•æ–‡ç« ",
            source_name="æµ‹è¯•æº"
        )
        
        complete_result = analysis_converter.convert_complete_analysis(
            mock_article, sentiment_result, investment_result, 2.5
        )
        
        assert complete_result.article_id == 1
        assert complete_result.sentiment_score == 7.8
        assert complete_result.processing_time == 2.5
        assert len(complete_result.recommendations) > 0
        
        logger.info(f"  âœ… å®Œæ•´åˆ†æè½¬æ¢: æ–‡ç« ID{complete_result.article_id}, å¤„ç†æ—¶é—´{complete_result.processing_time}ç§’")
    
    def test_api_response_conversion(self, api_converter):
        """æµ‹è¯•APIå“åº”è½¬æ¢"""
        logger.info("ğŸ”„ æµ‹è¯•APIå“åº”è½¬æ¢...")
        
        # åˆ›å»ºæ¨¡æ‹Ÿåˆ†æç»“æœ
        analysis_result = StandardAnalysisResult(
            article_id=123,
            sentiment_score=6.5,
            sentiment_label="åç§¯æ",
            confidence=0.75,
            key_phrases=["æŠ€æœ¯çªç ´", "ä¸šç»©å¢é•¿"],
            investment_opportunities=[
                {
                    "type": "æˆé•¿æœºä¼š",
                    "industry": "ç§‘æŠ€",
                    "score": 7.8,
                    "confidence": 0.8
                }
            ],
            risk_factors=["å¸‚åœºæ³¢åŠ¨", "ç«äº‰åŠ å‰§"],
            recommendations=[
                {
                    "action": "ä¹°å…¥",
                    "position": "ä¸­ç­‰ä»“ä½ (20-30%)",
                    "timeframe": "ä¸­çº¿æŒæœ‰",
                    "rationale": "åŸºæœ¬é¢å‘å¥½"
                }
            ],
            analysis_timestamp=datetime.now(timezone.utc),
            processing_time=3.2
        )
        
        # è½¬æ¢å•ä¸ªç»“æœ
        api_response = api_converter.convert_analysis_response(analysis_result)
        assert api_response["status"] == "success"
        assert api_response["data"]["article_id"] == 123
        assert "sentiment" in api_response["data"]
        assert "investment" in api_response["data"]
        
        logger.info(f"  âœ… å•ä¸ªç»“æœè½¬æ¢: çŠ¶æ€{api_response['status']}, æ–‡ç« ID{api_response['data']['article_id']}")
        
        # è½¬æ¢æ‰¹é‡ç»“æœ
        batch_results = [analysis_result, analysis_result]  # æ¨¡æ‹Ÿå¤šä¸ªç»“æœ
        batch_response = api_converter.convert_batch_analysis_response(batch_results, 6.4)
        
        assert batch_response["status"] == "success"
        assert len(batch_response["data"]["results"]) == 2
        assert batch_response["data"]["metadata"]["total_articles"] == 2
        
        logger.info(f"  âœ… æ‰¹é‡ç»“æœè½¬æ¢: æ€»æ•°{batch_response['data']['metadata']['total_articles']}, ç»“æœæ•°{len(batch_response['data']['results'])}")
    
    def test_database_conversion(self, db_converter):
        """æµ‹è¯•æ•°æ®åº“æ¨¡å‹è½¬æ¢"""
        logger.info("ğŸ”„ æµ‹è¯•æ•°æ®åº“æ¨¡å‹è½¬æ¢...")
        
        # åˆ›å»ºæ ‡å‡†åˆ†æç»“æœ
        analysis_result = StandardAnalysisResult(
            article_id=456,
            sentiment_score=8.2,
            sentiment_label="éå¸¸ç§¯æ",
            confidence=0.92,
            key_phrases=["é‡å¤§çªç ´", "ä¸šç»©é£™å‡", "å¸‚åœºé¢†å…ˆ"],
            investment_opportunities=[
                {
                    "type": "æŠ€æœ¯çªç ´",
                    "industry": "äººå·¥æ™ºèƒ½",
                    "score": 9.1,
                    "confidence": 0.89
                }
            ],
            risk_factors=["ä¼°å€¼è¿‡é«˜", "æŠ€æœ¯é£é™©"],
            recommendations=[
                {
                    "action": "å¼ºçƒˆä¹°å…¥",
                    "position": "é‡ä»“é…ç½® (30-40%)",
                    "timeframe": "é•¿æœŸæŒæœ‰",
                    "rationale": "æŠ€æœ¯çªç ´å¸¦æ¥é•¿æœŸå¢é•¿åŠ¨åŠ›"
                }
            ],
            analysis_timestamp=datetime.now(timezone.utc),
            processing_time=4.8
        )
        
        # æµ‹è¯•è½¬æ¢ä¸ºå­—å…¸
        result_dict = db_converter.convert_to_dict(analysis_result)
        assert isinstance(result_dict, dict)
        assert result_dict["article_id"] == 456
        assert result_dict["sentiment_score"] == 8.2
        
        logger.info(f"  âœ… å¯¹è±¡è½¬å­—å…¸: æ–‡ç« ID{result_dict['article_id']}, è¯„åˆ†{result_dict['sentiment_score']}")
        
        # æµ‹è¯•ä»å­—å…¸è½¬æ¢
        reconstructed = db_converter.convert_from_dict(result_dict, StandardAnalysisResult)
        assert isinstance(reconstructed, StandardAnalysisResult)
        assert reconstructed.article_id == 456
        assert reconstructed.sentiment_score == 8.2
        
        logger.info(f"  âœ… å­—å…¸è½¬å¯¹è±¡: æ–‡ç« ID{reconstructed.article_id}, è¯„åˆ†{reconstructed.sentiment_score}")
    
    def test_convenience_functions(self):
        """æµ‹è¯•ä¾¿æ·åŠŸèƒ½å‡½æ•°"""
        logger.info("ğŸ”„ æµ‹è¯•ä¾¿æ·åŠŸèƒ½å‡½æ•°...")
        
        # æµ‹è¯•ä¾¿æ·æ–°é—»è½¬æ¢å‡½æ•°
        raw_news = {
            "title": "ä¾¿æ·å‡½æ•°æµ‹è¯•æ–°é—»",
            "description": "æµ‹è¯•ä¾¿æ·è½¬æ¢å‡½æ•°çš„åŠŸèƒ½",
            "link": "https://test.com/news"
        }
        
        converted_news = convert_news_data(raw_news, "rss", "æµ‹è¯•æº")
        assert isinstance(converted_news, StandardNewsArticle)
        assert converted_news.title == "ä¾¿æ·å‡½æ•°æµ‹è¯•æ–°é—»"
        
        logger.info(f"  âœ… ä¾¿æ·æ–°é—»è½¬æ¢: {converted_news.title}")
        
        # æµ‹è¯•JSONè½¬æ¢
        json_str = convert_to_json(converted_news, indent=2)
        assert isinstance(json_str, str)
        assert "ä¾¿æ·å‡½æ•°æµ‹è¯•æ–°é—»" in json_str
        
        logger.info(f"  âœ… JSONè½¬æ¢: {len(json_str)} å­—ç¬¦")
    
    def run_all_tests(self, news_converter, analysis_converter, api_converter, db_converter):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹è¿è¡Œæ•°æ®è½¬æ¢å™¨å®Œæ•´æµ‹è¯•å¥—ä»¶...")
        
        results = {}
        
        # ä¾æ¬¡è¿è¡Œå„é¡¹æµ‹è¯•
        try:
            self.test_news_conversion(news_converter)
            results["news_conversion"] = True
        except Exception as e:
            logger.error(f"æ–°é—»è½¬æ¢æµ‹è¯•å¤±è´¥: {e}")
            results["news_conversion"] = False
        
        try:
            self.test_analysis_conversion(analysis_converter)
            results["analysis_conversion"] = True
        except Exception as e:
            logger.error(f"åˆ†æè½¬æ¢æµ‹è¯•å¤±è´¥: {e}")
            results["analysis_conversion"] = False
        
        try:
            self.test_api_response_conversion(api_converter)
            results["api_response_conversion"] = True
        except Exception as e:
            logger.error(f"APIå“åº”è½¬æ¢æµ‹è¯•å¤±è´¥: {e}")
            results["api_response_conversion"] = False
        
        try:
            self.test_database_conversion(db_converter)
            results["database_conversion"] = True
        except Exception as e:
            logger.error(f"æ•°æ®åº“è½¬æ¢æµ‹è¯•å¤±è´¥: {e}")
            results["database_conversion"] = False
        
        try:
            self.test_convenience_functions()
            results["convenience_functions"] = True
        except Exception as e:
            logger.error(f"ä¾¿æ·åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
            results["convenience_functions"] = False
        
        # è¾“å‡ºæµ‹è¯•ç»“æœ
        logger.info("\nğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
        success_count = 0
        for test_name, success in results.items():
            status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
            logger.info(f"  {test_name}: {status}")
            if success:
                success_count += 1
        
        total_tests = len(results)
        logger.info(f"\nğŸ¯ æ€»ä½“ç»“æœ: {success_count}/{total_tests} é€šè¿‡")
        
        return results


def main():
    """ç‹¬ç«‹è¿è¡Œæµ‹è¯•çš„ä¸»å‡½æ•°"""
    test_suite = TestDataConverter()
    
    # åˆ›å»ºè½¬æ¢å™¨å®ä¾‹
    news_conv = NewsDataConverter()
    analysis_conv = AnalysisResultConverter()
    api_conv = APIResponseConverter()
    db_conv = DatabaseModelConverter()
    
    results = test_suite.run_all_tests(news_conv, analysis_conv, api_conv, db_conv)
    
    # æ ¹æ®æµ‹è¯•ç»“æœè®¾ç½®é€€å‡ºç 
    all_passed = all(results.values())
    if all_passed:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        logger.error("ğŸ’¥ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼")
        return 1


if __name__ == "__main__":
    import sys
    exit_code = main()
    sys.exit(exit_code) 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æµ‹è¯• data_converter æ¨¡å—

éªŒè¯æ•°æ®è½¬æ¢å·¥å…·çš„å„é¡¹åŠŸèƒ½ï¼š
- æ–°é—»æ•°æ®æ ‡å‡†åŒ–è½¬æ¢
- åˆ†æç»“æœæ ¼å¼è½¬æ¢  
- APIå“åº”è½¬æ¢
- æ‰¹é‡å¤„ç†åŠŸèƒ½
"""

import asyncio
import logging
import sys
from datetime import datetime, timezone
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append('.')

from core.ai_agents.utils.data_converter import (
    NewsDataConverter,
    AnalysisResultConverter, 
    APIResponseConverter,
    DatabaseModelConverter,
    StandardNewsArticle,
    StandardAnalysisResult,
    convert_news_data,
    convert_analysis_to_api,
    convert_to_json
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TestDataConverter:
    """æ•°æ®è½¬æ¢å™¨æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.news_converter = NewsDataConverter()
        self.analysis_converter = AnalysisResultConverter()
        self.api_converter = APIResponseConverter()
        self.db_converter = DatabaseModelConverter()
    
    async def test_news_conversion(self) -> bool:
        """æµ‹è¯•æ–°é—»æ•°æ®è½¬æ¢"""
        logger.info("ğŸ”„ æµ‹è¯•æ–°é—»æ•°æ®è½¬æ¢...")
        
        try:
            # æµ‹è¯•RSSæ•°æ®è½¬æ¢
            rss_data = {
                "title": "æŸç§‘æŠ€å…¬å¸å‘å¸ƒæ–°äº§å“ï¼Œè‚¡ä»·ä¸Šæ¶¨8%",
                "description": "è¯¥å…¬å¸ä»Šæ—¥å‘å¸ƒé©å‘½æ€§æ–°äº§å“ï¼Œå¸‚åœºååº”ç§¯æï¼Œè‚¡ä»·ç›˜ä¸­ä¸Šæ¶¨8%è¾¾åˆ°æ–°é«˜ã€‚åˆ†æå¸ˆè®¤ä¸ºè¿™å°†æ¨åŠ¨å…¬å¸æœªæ¥å¢é•¿ã€‚",
                "link": "https://finance.example.com/news/tech-stock-rise",
                "pubDate": "Mon, 27 Jan 2025 15:30:00 GMT",
                "author": "è´¢ç»è®°è€…ææ˜",
                "category": "ç§‘æŠ€è‚¡",
                "tags": ["ç§‘æŠ€", "æ–°äº§å“", "è‚¡ä»·ä¸Šæ¶¨"]
            }
            
            article = self.news_converter.convert_to_standard(
                rss_data, "rss", "è´¢ç»ç½‘", 1
            )
            
            # éªŒè¯è½¬æ¢ç»“æœ
            assert article.title == "æŸç§‘æŠ€å…¬å¸å‘å¸ƒæ–°äº§å“ï¼Œè‚¡ä»·ä¸Šæ¶¨8%"
            assert article.source_name == "è´¢ç»ç½‘"
            assert article.source_id == 1
            assert article.author == "è´¢ç»è®°è€…ææ˜"
            assert article.category == "ç§‘æŠ€è‚¡"
            assert len(article.tags) > 0
            
            logger.info(f"  âœ… RSSè½¬æ¢æˆåŠŸ: {article.title}")
            
            # æµ‹è¯•é›ªçƒæ•°æ®è½¬æ¢
            xueqiu_data = {
                "title": "çƒ­é—¨è‚¡ç¥¨åˆ†æï¼šAIæ¦‚å¿µè‚¡æŒç»­èµ°å¼º",
                "text": "å¤šåªAIæ¦‚å¿µè‚¡ä»Šæ—¥è¡¨ç°å¼ºåŠ²ï¼Œæ¿å—æ•´ä½“ä¸Šæ¶¨è¶…è¿‡5%ã€‚æœºæ„èµ„é‡‘æŒç»­æµå…¥ï¼Œçœ‹å¥½åå¸‚å‘å±•ã€‚",
                "target": "https://xueqiu.com/status/123456",
                "created_at": 1737974400,  # Unixæ—¶é—´æˆ³
                "user": "é›ªçƒåˆ†æå¸ˆ"
            }
            
            xq_article = self.news_converter.convert_to_standard(
                xueqiu_data, "xueqiu", "é›ªçƒ", 2
            )
            
            assert xq_article.title == "çƒ­é—¨è‚¡ç¥¨åˆ†æï¼šAIæ¦‚å¿µè‚¡æŒç»­èµ°å¼º"
            assert xq_article.source_name == "é›ªçƒ"
            assert xq_article.author == "é›ªçƒåˆ†æå¸ˆ"
            
            logger.info(f"  âœ… é›ªçƒè½¬æ¢æˆåŠŸ: {xq_article.title}")
            
            # æµ‹è¯•æ‰¹é‡è½¬æ¢
            batch_data = [rss_data, xueqiu_data]
            batch_results = self.news_converter.convert_batch(
                batch_data, "rss", "ç»¼åˆè´¢ç»", 3
            )
            
            assert len(batch_results) == 2
            logger.info(f"  âœ… æ‰¹é‡è½¬æ¢æˆåŠŸ: {len(batch_results)} ç¯‡æ–‡ç« ")
            
            return True
            
        except Exception as e:
            logger.error(f"  âŒ æ–°é—»è½¬æ¢æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_analysis_conversion(self) -> bool:
        """æµ‹è¯•åˆ†æç»“æœè½¬æ¢"""
        logger.info("ğŸ”„ æµ‹è¯•åˆ†æç»“æœè½¬æ¢...")
        
        try:
            # æ¨¡æ‹Ÿæƒ…æ„Ÿåˆ†æç»“æœ
            sentiment_result = {
                "final_sentiment_score": 7.8,
                "final_sentiment_label": "ç§¯æ",
                "confidence": 0.88,
                "sentiment_breakdown": {
                    "dominant_emotion": "optimistic"
                },
                "key_indicators": {
                    "sentiment_phrases": ["è‚¡ä»·ä¸Šæ¶¨", "å¸‚åœºçœ‹å¥½", "å‰æ™¯ç§¯æ"]
                }
            }
            
            # æ¨¡æ‹ŸæŠ•èµ„åˆ†æç»“æœ  
            investment_result = {
                "investment_advice": {
                    "action": "ä¹°å…¥",
                    "position_size": "è½»ä»“ä¹°å…¥ (10-20%)",
                    "time_frame": "çŸ­çº¿ (1å‘¨-1ä¸ªæœˆ)",
                    "confidence": 0.82,
                    "rationale": "æ–°äº§å“å‘å¸ƒæ¨åŠ¨å…¬å¸åŸºæœ¬é¢æ”¹å–„ï¼ŒçŸ­æœŸæœ‰æœ›æŒç»­ä¸Šæ¶¨",
                    "target_companies": ["ç§‘æŠ€å…¬å¸A", "ç›¸å…³äº§ä¸šé“¾å…¬å¸"],
                    "investment_themes": ["AIæ¦‚å¿µ", "ç§‘æŠ€åˆ›æ–°"]
                },
                "analysis_results": [
                    {
                        "opportunity": {
                            "opportunity_type": "äº§å“åˆ›æ–°",
                            "industry": "ç§‘æŠ€",
                            "score": 8.5,
                            "confidence": 0.85,
                            "time_horizon": "çŸ­æœŸ",
                            "key_factors": ["æŠ€æœ¯çªç ´", "å¸‚åœºéœ€æ±‚"]
                        },
                        "risk_assessment": {
                            "risk_level": "ä¸­ç­‰",
                            "risk_score": 4.2,
                            "risk_factors": ["å¸‚åœºç«äº‰", "æŠ€æœ¯é£é™©"],
                            "mitigation_strategies": ["åˆ†æ•£æŠ•èµ„", "æ­¢æŸè®¾ç½®"]
                        }
                    }
                ]
            }
            
            # è½¬æ¢æƒ…æ„Ÿåˆ†æç»“æœ
            sentiment_converted = self.analysis_converter.convert_sentiment_result(sentiment_result)
            assert sentiment_converted["sentiment_score"] == 7.8
            assert sentiment_converted["sentiment_label"] == "ç§¯æ"
            assert sentiment_converted["confidence"] == 0.88
            
            logger.info(f"  âœ… æƒ…æ„Ÿåˆ†æè½¬æ¢: è¯„åˆ†{sentiment_converted['sentiment_score']}, æ ‡ç­¾{sentiment_converted['sentiment_label']}")
            
            # è½¬æ¢æŠ•èµ„åˆ†æç»“æœ
            investment_converted = self.analysis_converter.convert_investment_result(investment_result)
            assert investment_converted["investment_action"] == "ä¹°å…¥"
            assert len(investment_converted["opportunities"]) > 0
            assert len(investment_converted["risks"]) > 0
            
            logger.info(f"  âœ… æŠ•èµ„åˆ†æè½¬æ¢: å»ºè®®{investment_converted['investment_action']}, æ—¶é—´æ¡†æ¶{investment_converted['time_frame']}")
            
            # æµ‹è¯•å®Œæ•´åˆ†æç»“æœè½¬æ¢
            mock_article = StandardNewsArticle(
                id=1,
                title="æµ‹è¯•æ–‡ç« ",
                source_name="æµ‹è¯•æº"
            )
            
            complete_result = self.analysis_converter.convert_complete_analysis(
                mock_article, sentiment_result, investment_result, 2.5
            )
            
            assert complete_result.article_id == 1
            assert complete_result.sentiment_score == 7.8
            assert complete_result.processing_time == 2.5
            assert len(complete_result.recommendations) > 0
            
            logger.info(f"  âœ… å®Œæ•´åˆ†æè½¬æ¢: æ–‡ç« ID{complete_result.article_id}, å¤„ç†æ—¶é—´{complete_result.processing_time}ç§’")
            
            return True
            
        except Exception as e:
            logger.error(f"  âŒ åˆ†æè½¬æ¢æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_api_response_conversion(self) -> bool:
        """æµ‹è¯•APIå“åº”è½¬æ¢"""
        logger.info("ğŸ”„ æµ‹è¯•APIå“åº”è½¬æ¢...")
        
        try:
            # åˆ›å»ºæ¨¡æ‹Ÿåˆ†æç»“æœ
            analysis_result = StandardAnalysisResult(
                article_id=123,
                sentiment_score=6.5,
                sentiment_label="åç§¯æ",
                confidence=0.75,
                key_phrases=["æŠ€æœ¯çªç ´", "ä¸šç»©å¢é•¿"],
                investment_opportunities=[
                    {
                        "type": "æˆé•¿æœºä¼š",
                        "industry": "ç§‘æŠ€",
                        "score": 7.8,
                        "confidence": 0.8
                    }
                ],
                risk_factors=["å¸‚åœºæ³¢åŠ¨", "ç«äº‰åŠ å‰§"],
                recommendations=[
                    {
                        "action": "ä¹°å…¥",
                        "position": "ä¸­ç­‰ä»“ä½ (20-30%)",
                        "timeframe": "ä¸­çº¿æŒæœ‰",
                        "rationale": "åŸºæœ¬é¢å‘å¥½"
                    }
                ],
                analysis_timestamp=datetime.now(timezone.utc),
                processing_time=3.2
            )
            
            # è½¬æ¢å•ä¸ªç»“æœ
            api_response = self.api_converter.convert_analysis_response(analysis_result)
            
            assert api_response["status"] == "success"
            assert api_response["data"]["article_id"] == 123
            assert api_response["data"]["sentiment"]["score"] == 6.5
            assert len(api_response["data"]["investment"]["opportunities"]) > 0
            
            logger.info(f"  âœ… å•ä¸ªAPIå“åº”è½¬æ¢: æ–‡ç« {api_response['data']['article_id']}, çŠ¶æ€{api_response['status']}")
            
            # æµ‹è¯•æ‰¹é‡è½¬æ¢
            batch_results = [analysis_result] * 3
            batch_response = self.api_converter.convert_batch_analysis_response(
                batch_results, 9.6
            )
            
            assert batch_response["status"] == "success"
            assert len(batch_response["data"]["results"]) == 3
            assert batch_response["data"]["metadata"]["total_articles"] == 3
            assert batch_response["data"]["metadata"]["total_processing_time"] == 9.6
            assert "summary" in batch_response["data"]
            
            logger.info(f"  âœ… æ‰¹é‡APIå“åº”è½¬æ¢: {len(batch_response['data']['results'])} æ¡ç»“æœ")
            
            return True
            
        except Exception as e:
            logger.error(f"  âŒ APIå“åº”è½¬æ¢æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_convenience_functions(self) -> bool:
        """æµ‹è¯•ä¾¿æ·å‡½æ•°"""
        logger.info("ğŸ”„ æµ‹è¯•ä¾¿æ·å‡½æ•°...")
        
        try:
            # æµ‹è¯•ä¾¿æ·æ–°é—»è½¬æ¢å‡½æ•°
            raw_news = {
                "title": "ä¾¿æ·å‡½æ•°æµ‹è¯•æ–°é—»",
                "description": "æµ‹è¯•ä¾¿æ·è½¬æ¢å‡½æ•°çš„åŠŸèƒ½",
                "link": "https://test.com/news"
            }
            
            converted_news = convert_news_data(raw_news, "rss", "æµ‹è¯•æº")
            assert isinstance(converted_news, StandardNewsArticle)
            assert converted_news.title == "ä¾¿æ·å‡½æ•°æµ‹è¯•æ–°é—»"
            
            logger.info(f"  âœ… ä¾¿æ·æ–°é—»è½¬æ¢: {converted_news.title}")
            
            # æµ‹è¯•JSONè½¬æ¢
            json_str = convert_to_json(converted_news, indent=2)
            assert isinstance(json_str, str)
            assert "ä¾¿æ·å‡½æ•°æµ‹è¯•æ–°é—»" in json_str
            
            logger.info(f"  âœ… JSONè½¬æ¢: {len(json_str)} å­—ç¬¦")
            
            return True
            
        except Exception as e:
            logger.error(f"  âŒ ä¾¿æ·å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def run_all_tests(self) -> Dict[str, bool]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹ data_converter å®Œæ•´æµ‹è¯•...")
        
        results = {
            "news_conversion": await self.test_news_conversion(),
            "analysis_conversion": await self.test_analysis_conversion(), 
            "api_response_conversion": await self.test_api_response_conversion(),
            "convenience_functions": await self.test_convenience_functions()
        }
        
        # ç»Ÿè®¡ç»“æœ
        passed = sum(results.values())
        total = len(results)
        
        logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
        for test_name, result in results.items():
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            logger.info(f"  {test_name}: {status}")
        
        logger.info(f"ğŸ“ˆ æ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
        
        if passed == total:
            logger.info("ğŸ‰ data_converter æ¨¡å—æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        else:
            logger.warning(f"âš ï¸ æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤")
        
        return results

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    tester = TestDataConverter()
    results = await tester.run_all_tests()
    
    # è¿”å›æˆåŠŸçŠ¶æ€
    return all(results.values())

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success = asyncio.run(main())
    
    if success:
        print("\nâœ… data_converter æ¨¡å—éªŒè¯å®Œæˆ - æ‰€æœ‰åŠŸèƒ½æ­£å¸¸")
        exit(0)
    else:
        print("\nâŒ data_converter æ¨¡å—éªŒè¯å¤±è´¥ - å­˜åœ¨é—®é¢˜éœ€è¦ä¿®å¤") 
        exit(1) 
#!/usr/bin/env python3

"""
æ–°é—»åˆ†ææµç¨‹æµ‹è¯•è„šæœ¬

åŸºäº core/ai_agents/news_analysis_flow/flows.py ä¸­å®šä¹‰çš„ PocketFlow æµç¨‹ï¼Œ
æµ‹è¯•å®Œæ•´çš„æ–°é—»åˆ†æåŠŸèƒ½ï¼ŒéªŒè¯å„ä¸ªèŠ‚ç‚¹çš„å·¥ä½œçŠ¶æ€å’Œæ•°æ®æµè½¬ã€‚

ä¸»è¦åŠŸèƒ½:
    - æµ‹è¯•è‚¡ç¥¨ç‰¹å®šæ–°é—»çš„åˆ†ææµç¨‹
    - æµ‹è¯•è¡Œä¸šå¯¼å‘æ–°é—»çš„åˆ†ææµç¨‹
    - éªŒè¯èŠ‚ç‚¹é—´çš„æ•°æ®ä¼ é€’å’ŒçŠ¶æ€è½¬æ¢
    - æä¾›è¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—å’Œç»“æœå±•ç¤º

ä½¿ç”¨æ–¹æ³•:
    python scripts/test_news_analysis_flow.py
"""

import logging
import os
import sys
import traceback
from datetime import datetime
from typing import Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from core.ai_agents.news_analysis_flow.flows import news_analysis_flow  # noqa: E402
from core.models.news_article import NewsArticle  # noqa: E402

# åˆ›å»ºlogsç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
logs_dir = os.path.join(project_root, 'logs')
os.makedirs(logs_dir, exist_ok=True)

# ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ—¥å¿—æ–‡ä»¶å
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
log_filename = f'test_news_analysis_flow_{timestamp}.log'
log_filepath = os.path.join(logs_dir, log_filename)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(log_filepath, mode='w', encoding='utf-8')
    ],
    force=True  # å¼ºåˆ¶é‡æ–°é…ç½®æ—¥å¿—
)
logger = logging.getLogger(__name__)

# è®°å½•æ—¥å¿—æ–‡ä»¶ä½ç½®
logger.info(f"ğŸ“„ æ—¥å¿—æ–‡ä»¶ä½ç½®: {log_filepath}")

class NewsAnalysisFlowTester:
    """æ–°é—»åˆ†ææµç¨‹æµ‹è¯•å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.test_results = []
        self.flow = None
        self.log_filepath = log_filepath

    def setup_flow(self):
        """è®¾ç½®æ–°é—»åˆ†ææµç¨‹"""
        try:
            logger.info("ğŸš€ åˆå§‹åŒ–æ–°é—»åˆ†ææµç¨‹...")
            self.flow = news_analysis_flow()
            logger.info(f"âœ… æµç¨‹åˆå§‹åŒ–æˆåŠŸï¼Œèµ·å§‹èŠ‚ç‚¹: {self.flow.start_node.__class__.__name__}")
            return True
        except Exception as e:
            logger.error(f"âŒ æµç¨‹åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return False

    def create_test_articles(self) -> list[NewsArticle]:
        """åˆ›å»ºæµ‹è¯•æ–°é—»æ–‡ç« """
        test_articles = [
            # è‚¡ç¥¨ç‰¹å®šæ–°é—»
            NewsArticle(
                id=1,
                title="æ²ªä¸Šé˜¿å§¨(02589)ï¼šæ‚‰æ•°è¡Œä½¿è¶…é¢é…è‚¡æƒã€ç¨³å®šä»·æ ¼è¡ŒåŠ¨åŠç¨³å®šä»·æ ¼æœŸç»“æŸ",
                content="æ²ªä¸Šé˜¿å§¨å…¬å¸å‘å¸ƒå…¬å‘Šï¼Œå®£å¸ƒæ‚‰æ•°è¡Œä½¿è¶…é¢é…è‚¡æƒï¼Œç¨³å®šä»·æ ¼è¡ŒåŠ¨æ­£å¼ç»“æŸã€‚å…¬å¸è¡¨ç¤ºå°†ç»§ç»­ä¸“æ³¨èŒ¶é¥®ä¸šåŠ¡å‘å±•ï¼Œä¸ºè‚¡ä¸œåˆ›é€ æ›´å¤§ä»·å€¼ã€‚",
                url="https://example.com/news1",
                url_hash="hash1",
                source_id=1,
                created_at=datetime.now()
            )
            # å¦ä¸€ä¸ªè‚¡ç¥¨ç‰¹å®šæ–°é—»
            # NewsArticle(
            #     id=2,
            #     title="å¹³å®‰é“¶è¡Œ(000001.SZ)å‘å¸ƒ2024å¹´ç¬¬ä¸‰å­£åº¦ä¸šç»©æŠ¥å‘Š",
            #     content="å¹³å®‰é“¶è¡Œå‘å¸ƒ2024å¹´ç¬¬ä¸‰å­£åº¦è´¢æŠ¥ï¼Œå‡€åˆ©æ¶¦åŒæ¯”å¢é•¿8.5%ï¼Œé›¶å”®ä¸šåŠ¡æŒç»­å¢é•¿ï¼Œèµ„äº§è´¨é‡ä¿æŒç¨³å®šã€‚",
            #     url="https://example.com/news2",
            #     url_hash="hash2",
            #     source_id=1,
            #     created_at=datetime.now()
            # ),
            # # è¡Œä¸šå¯¼å‘æ–°é—»
            # NewsArticle(
            #     id=3,
            #     title="äººå·¥æ™ºèƒ½è¡Œä¸šå‘å±•è¿æ¥æ–°æœºé‡ï¼Œå¤šå®¶å…¬å¸åŠ ç AIæŠ€æœ¯æŠ•å…¥",
            #     content="éšç€ChatGPTç­‰å¤§æ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œäººå·¥æ™ºèƒ½è¡Œä¸šè¿æ¥æ–°ä¸€è½®å‘å±•çƒ­æ½®ã€‚å¤šå®¶ç§‘æŠ€å…¬å¸çº·çº·åŠ å¤§AIæŠ€æœ¯ç ”å‘æŠ•å…¥ï¼ŒæŠ¢å å¸‚åœºå…ˆæœºã€‚",
            #     url="https://example.com/news3",
            #     url_hash="hash3",
            #     source_id=1,
            #     created_at=datetime.now()
            # ),
            # # å¦ä¸€ä¸ªè¡Œä¸šå¯¼å‘æ–°é—»
            # NewsArticle(
            #     id=4,
            #     title="æ–°èƒ½æºæ±½è½¦å¸‚åœºæŒç»­ç«çƒ­ï¼Œæ”¿ç­–åˆ©å¥½æ¨åŠ¨äº§ä¸šå‘å±•",
            #     content="åœ¨æ”¿ç­–åˆ©å¥½å’ŒæŠ€æœ¯è¿›æ­¥åŒé‡æ¨åŠ¨ä¸‹ï¼Œæ–°èƒ½æºæ±½è½¦å¸‚åœºæŒç»­ç«çƒ­ã€‚ç”µæ± æŠ€æœ¯ã€å……ç”µåŸºç¡€è®¾æ–½ã€æ™ºèƒ½é©¾é©¶ç­‰é¢†åŸŸéƒ½è¿æ¥å¿«é€Ÿå‘å±•ã€‚",
            #     url="https://example.com/news4",
            #     url_hash="hash4",
            #     source_id=1,
            #     created_at=datetime.now()
            # ),
            # # åŒ»è¯è¡Œä¸šæ–°é—»
            # NewsArticle(
            #     id=5,
            #     title="ç”Ÿç‰©åŒ»è¯è¡Œä¸šè¿æ¥åˆ›æ–°è¯ç ”å‘çƒ­æ½®ï¼Œå¤šä¸ªæ–°è¯è·æ‰¹ä¸Šå¸‚",
            #     content="è¿‘æœŸå¤šä¸ªåˆ›æ–°è¯è·å¾—è¯ç›‘å±€æ‰¹å‡†ä¸Šå¸‚ï¼Œç”Ÿç‰©åŒ»è¯è¡Œä¸šåˆ›æ–°æ´»åŠ›æŒç»­é‡Šæ”¾ã€‚å…ç–«æ²»ç–—ã€ç²¾å‡†åŒ»ç–—ç­‰é¢†åŸŸæˆä¸ºæŠ•èµ„çƒ­ç‚¹ã€‚",
            #     url="https://example.com/news5",
            #     url_hash="hash5",
            #     source_id=1,
            #     created_at=datetime.now()
            # )
        ]

        logger.info(f"ğŸ“„ åˆ›å»ºäº† {len(test_articles)} ç¯‡æµ‹è¯•æ–°é—»æ–‡ç« ")
        return test_articles

    def test_single_article(self, article: NewsArticle, test_name: str) -> dict[str, Any]:
        """æµ‹è¯•å•ç¯‡æ–‡ç« çš„åˆ†ææµç¨‹"""
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ” å¼€å§‹æµ‹è¯•: {test_name}")
        logger.info(f"ğŸ“° æ–‡ç« æ ‡é¢˜: {article.title}")
        logger.info(f"{'='*80}")

        test_result = {
            'test_name': test_name,
            'article_title': article.title,
            'success': False,
            'execution_time': 0,
            'error': None,
            'shared_store': None,
            'analysis_type': None,
            'mentioned_stocks': [],
            'mentioned_industries': []
        }

        try:
            start_time = datetime.now()

            # å‡†å¤‡å…±äº«å­˜å‚¨
            shared_store = {
                'article': article,
                'title': '',
                'content': '',
                'mentioned_stocks': [],
                'mentioned_industries': []
            }

            logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œæ–°é—»åˆ†ææµç¨‹...")

            # æ‰§è¡Œæµç¨‹
            result = self.flow.run(shared_store)

            end_time = datetime.now()
            execution_time = (end_time - start_time).total_seconds()

            # è®°å½•ç»“æœ
            test_result.update({
                'success': True,
                'execution_time': execution_time,
                'shared_store': shared_store.copy(),
                'analysis_type': self._get_analysis_type_from_store(shared_store),
                'mentioned_stocks': shared_store.get('mentioned_stocks', []),
                'mentioned_industries': shared_store.get('mentioned_industries', [])
            })

            # è¾“å‡ºè¯¦ç»†ç»“æœ
            self._print_test_results(test_result)

            logger.info(f"âœ… æµ‹è¯• '{test_name}' æ‰§è¡ŒæˆåŠŸï¼è€—æ—¶: {execution_time:.2f}ç§’")

        except Exception as e:
            end_time = datetime.now()
            execution_time = (end_time - start_time).total_seconds() if 'start_time' in locals() else 0

            test_result.update({
                'success': False,
                'execution_time': execution_time,
                'error': str(e)
            })

            logger.error(f"âŒ æµ‹è¯• '{test_name}' æ‰§è¡Œå¤±è´¥: {e}")
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

        return test_result

    def _get_analysis_type_from_store(self, shared_store: dict[str, Any]) -> str:
        """ä»å…±äº«å­˜å‚¨ä¸­æ¨æ–­åˆ†æç±»å‹"""
        stocks = shared_store.get('mentioned_stocks', [])
        industries = shared_store.get('mentioned_industries', [])

        if stocks and len(stocks) > 0:
            return 'stock_specific'
        elif industries and len(industries) > 0:
            return 'industry_focused'
        else:
            return 'unknown'

    def _print_test_results(self, test_result: dict[str, Any]):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        logger.info("\nğŸ“Š æµ‹è¯•ç»“æœè¯¦æƒ…:")
        logger.info(f"   ğŸ¯ åˆ†æç±»å‹: {test_result.get('analysis_type', 'unknown')}")
        logger.info(f"   ğŸ“ˆ æåŠè‚¡ç¥¨: {len(test_result.get('mentioned_stocks', []))} åª")

        for i, stock in enumerate(test_result.get('mentioned_stocks', []), 1):
            if isinstance(stock, dict):
                name = stock.get('name', 'æœªçŸ¥')
                code = stock.get('code', 'æœªçŸ¥')
                logger.info(f"      {i}. {name} ({code})")
            else:
                logger.info(f"      {i}. {stock}")

        logger.info(f"   ğŸ­ æåŠè¡Œä¸š: {len(test_result.get('mentioned_industries', []))} ä¸ª")
        for i, industry in enumerate(test_result.get('mentioned_industries', []), 1):
            logger.info(f"      {i}. {industry}")

        shared_store = test_result.get('shared_store', {})
        logger.info(f"   ğŸ“ æ ‡é¢˜æ›´æ–°: {'æ˜¯' if shared_store.get('title') else 'å¦'}")
        logger.info(f"   ğŸ“„ å†…å®¹æ›´æ–°: {'æ˜¯' if shared_store.get('content') else 'å¦'}")

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹æ–°é—»åˆ†ææµç¨‹å®Œæ•´æµ‹è¯•")
        logger.info(f"â° æµ‹è¯•å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # è®¾ç½®æµç¨‹
        if not self.setup_flow():
            logger.error("âŒ æµç¨‹è®¾ç½®å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
            return

        # åˆ›å»ºæµ‹è¯•æ–‡ç« 
        test_articles = self.create_test_articles()

        # å®šä¹‰æµ‹è¯•ç”¨ä¾‹
        test_cases = [
            (test_articles[0], "è‚¡ç¥¨ç‰¹å®šæ–°é—»æµ‹è¯• - æ²ªä¸Šé˜¿å§¨"),
            # (test_articles[1], "è‚¡ç¥¨ç‰¹å®šæ–°é—»æµ‹è¯• - å¹³å®‰é“¶è¡Œ"),
            # (test_articles[2], "è¡Œä¸šå¯¼å‘æ–°é—»æµ‹è¯• - äººå·¥æ™ºèƒ½"),
            # (test_articles[3], "è¡Œä¸šå¯¼å‘æ–°é—»æµ‹è¯• - æ–°èƒ½æºæ±½è½¦"),
            # (test_articles[4], "è¡Œä¸šå¯¼å‘æ–°é—»æµ‹è¯• - ç”Ÿç‰©åŒ»è¯")
        ]

        # æ‰§è¡Œæµ‹è¯•
        for article, test_name in test_cases:
            test_result = self.test_single_article(article, test_name)
            self.test_results.append(test_result)

        # è¾“å‡ºæ€»ç»“
        self._print_summary()

        # è®°å½•æ—¥å¿—æ–‡ä»¶ä¿¡æ¯
        logger.info(f"\nğŸ“„ å®Œæ•´æµ‹è¯•æ—¥å¿—å·²ä¿å­˜åˆ°: {self.log_filepath}")

    def _print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        logger.info(f"\n{'='*100}")
        logger.info("ğŸ“Š æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
        logger.info(f"{'='*100}")

        total_tests = len(self.test_results)
        successful_tests = sum(1 for result in self.test_results if result['success'])
        failed_tests = total_tests - successful_tests

        logger.info("ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        logger.info(f"   æ€»æµ‹è¯•æ•°: {total_tests}")
        logger.info(f"   æˆåŠŸæµ‹è¯•: {successful_tests} âœ…")
        logger.info(f"   å¤±è´¥æµ‹è¯•: {failed_tests} âŒ")
        logger.info(f"   æˆåŠŸç‡: {(successful_tests/total_tests*100):.1f}%")

        if successful_tests > 0:
            avg_time = sum(r['execution_time'] for r in self.test_results if r['success']) / successful_tests
            logger.info(f"   å¹³å‡æ‰§è¡Œæ—¶é—´: {avg_time:.2f}ç§’")

        logger.info("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
        for i, result in enumerate(self.test_results, 1):
            status = "âœ…" if result['success'] else "âŒ"
            time_str = f"{result['execution_time']:.2f}s" if result['success'] else "å¤±è´¥"
            analysis_type = result.get('analysis_type', 'æœªçŸ¥')

            logger.info(f"   {i}. {status} {result['test_name']} ({time_str}) - {analysis_type}")

            if not result['success'] and result['error']:
                logger.info(f"      é”™è¯¯: {result['error']}")

            if result['success']:
                stocks_count = len(result.get('mentioned_stocks', []))
                industries_count = len(result.get('mentioned_industries', []))
                logger.info(f"      è‚¡ç¥¨: {stocks_count}åª, è¡Œä¸š: {industries_count}ä¸ª")

        # åŠŸèƒ½éªŒè¯
        logger.info("\nğŸ” åŠŸèƒ½éªŒè¯:")
        stock_specific_tests = [r for r in self.test_results if r.get('analysis_type') == 'stock_specific' and r['success']]
        industry_focused_tests = [r for r in self.test_results if r.get('analysis_type') == 'industry_focused' and r['success']]

        logger.info(f"   è‚¡ç¥¨ç‰¹å®šåˆ†æ: {len(stock_specific_tests)} é¡¹é€šè¿‡")
        logger.info(f"   è¡Œä¸šå¯¼å‘åˆ†æ: {len(industry_focused_tests)} é¡¹é€šè¿‡")

        if stock_specific_tests:
            total_stocks = sum(len(r.get('mentioned_stocks', [])) for r in stock_specific_tests)
            logger.info(f"   æ£€æµ‹åˆ°è‚¡ç¥¨æ€»æ•°: {total_stocks} åª")

        if industry_focused_tests:
            total_industries = sum(len(r.get('mentioned_industries', [])) for r in industry_focused_tests)
            logger.info(f"   æ£€æµ‹åˆ°è¡Œä¸šæ€»æ•°: {total_industries} ä¸ª")

        logger.info(f"\nâ° æµ‹è¯•å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"ğŸ“„ æ—¥å¿—æ–‡ä»¶: {self.log_filepath}")
        logger.info(f"{'='*100}")


def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºæµ‹è¯•å™¨
        tester = NewsAnalysisFlowTester()

        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        tester.run_all_tests()

        # æ ¹æ®æµ‹è¯•ç»“æœç¡®å®šé€€å‡ºç 
        failed_count = sum(1 for result in tester.test_results if not result['success'])
        if failed_count > 0:
            logger.warning(f"âš ï¸  æœ‰ {failed_count} ä¸ªæµ‹è¯•å¤±è´¥")
            sys.exit(1)
        else:
            logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½æˆåŠŸé€šè¿‡ï¼")
            sys.exit(0)

    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
        logger.error(traceback.format_exc())
        sys.exit(1)


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ–°é—»åˆ†ææµæ°´çº¿æµ‹è¯•è„šæœ¬

æµ‹è¯•åŸºäºPocketFlowæ¡†æ¶çš„å¤šAgentåä½œæ–°é—»åˆ†æç³»ç»Ÿã€‚
é€šè¿‡æ¨¡æ‹Ÿæ–°é—»æ•°æ®ï¼Œæ¼”ç¤ºä»æ–°é—»å†…å®¹åˆ°æŠ•èµ„å»ºè®®çš„å®Œæ•´æµç¨‹ã€‚
"""

import asyncio
import json
import logging
import sys
import os
from datetime import datetime
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.ai_agents.flow_definitions.news_analysis_flow import NewsAnalysisFlow, analyze_single_news
from core.ai_agents.llm_clients.qwen_client import QwenLLMClient
from core.models.news_source import NewsSource, NewsSourceType, NewsSourceStatus

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('news_analysis_test.log', encoding='utf-8')
    ]
)

logger = logging.getLogger(__name__)

class NewsAnalysisTestSuite:
    """æ–°é—»åˆ†ææµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å¥—ä»¶"""
        self.qwen_client = None
        self.analysis_flow = None
        
        # æµ‹è¯•æ–°é—»æ•°æ®
        self.test_news_samples = [
            {
                "id": "test_001",
                "title": "å¤®è¡Œé™å‡†é‡Šæ”¾æµåŠ¨æ€§ é“¶è¡Œæ¿å—æœ‰æœ›å—ç›Š",
                "content": """å¤®è¡Œä»Šæ—¥å®£å¸ƒå…¨é¢é™å‡†0.5ä¸ªç™¾åˆ†ç‚¹ï¼Œé‡Šæ”¾é•¿æœŸèµ„é‡‘çº¦5000äº¿å…ƒã€‚æ­¤æ¬¡é™å‡†ä¸»è¦ç›®çš„æ˜¯ä¼˜åŒ–é“¶è¡Œèµ„é‡‘ç»“æ„ï¼Œå¢å¼ºé“¶è¡Œä¿¡è´·æŠ•æ”¾èƒ½åŠ›ï¼Œæ”¯æŒå®ä½“ç»æµå‘å±•ã€‚

åˆ†æå¸ˆè®¤ä¸ºï¼Œæ­¤æ¬¡é™å‡†å¯¹é“¶è¡Œä¸šæ˜¯æ˜æ˜¾åˆ©å¥½ï¼Œæœ‰åŠ©äºé™ä½é“¶è¡Œèµ„é‡‘æˆæœ¬ï¼Œæå‡å‡€æ¯å·®ï¼Œæ”¹å–„ç›ˆåˆ©èƒ½åŠ›ã€‚åŒæ—¶ï¼Œå……è£•çš„æµåŠ¨æ€§ä¹Ÿå°†å¸¦åŠ¨æ•´ä¸ªé‡‘èå¸‚åœºæ´»è·ƒåº¦æå‡ã€‚

ä¸šå†…é¢„è®¡ï¼Œå¤§å‹é“¶è¡Œå’Œè‚¡ä»½åˆ¶é“¶è¡Œå°†æ˜¯æœ¬æ¬¡é™å‡†çš„ä¸»è¦å—ç›Šè€…ï¼Œç‰¹åˆ«æ˜¯é‚£äº›èµ„äº§è´¨é‡ä¼˜è‰¯ã€é£æ§èƒ½åŠ›å¼ºçš„é“¶è¡Œè‚¡å€¼å¾—å…³æ³¨ã€‚""",
                "source": "ç¬¬ä¸€è´¢ç»",
                "expected_impact": ["é‡‘è", "é“¶è¡Œ"],
                "expected_sentiment": "æ­£é¢"
            },
            {
                "id": "test_002", 
                "title": "æ–°èƒ½æºæ±½è½¦é”€é‡å¤§å¢ äº§ä¸šé“¾ä¼ä¸šä¸šç»©é£™å‡",
                "content": """æœ€æ–°æ•°æ®æ˜¾ç¤ºï¼Œ11æœˆæ–°èƒ½æºæ±½è½¦é”€é‡è¾¾åˆ°95ä¸‡è¾†ï¼ŒåŒæ¯”å¢é•¿39.2%ï¼Œæ¸—é€ç‡è¾¾åˆ°37.8%ã€‚å¤´éƒ¨æ–°èƒ½æºè½¦ä¼æ¯”äºšè¿ªã€ç†æƒ³æ±½è½¦ç­‰é”€é‡å‡åˆ›å†å²æ–°é«˜ã€‚

å—ç›Šäºé”€é‡å¤§å¢ï¼Œæ–°èƒ½æºæ±½è½¦äº§ä¸šé“¾ä¸Šä¸‹æ¸¸ä¼ä¸šä¸šç»©æ™®éå‘å¥½ã€‚åŠ¨åŠ›ç”µæ± é¾™å¤´å®å¾·æ—¶ä»£ç¬¬ä¸‰å­£åº¦å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿40%ï¼Œé”‚ç”µæ± ææ–™ä¼ä¸šä¸šç»©æ›´æ˜¯å‘ˆç°çˆ†å‘å¼å¢é•¿ã€‚

æœºæ„è®¤ä¸ºï¼Œåœ¨æ”¿ç­–æ”¯æŒå’ŒæŠ€æœ¯è¿›æ­¥åŒè½®é©±åŠ¨ä¸‹ï¼Œæ–°èƒ½æºæ±½è½¦è¡Œä¸šä»å°†ä¿æŒé«˜é€Ÿå¢é•¿æ€åŠ¿ï¼Œç›¸å…³äº§ä¸šé“¾å…¬å¸å…·å¤‡é•¿æœŸæŠ•èµ„ä»·å€¼ã€‚""",
                "source": "è¯åˆ¸æ—¶æŠ¥",
                "expected_impact": ["æ–°èƒ½æº", "æ±½è½¦", "åˆ¶é€ "],
                "expected_sentiment": "æ­£é¢"
            },
            {
                "id": "test_003",
                "title": "æˆ¿åœ°äº§è¡Œä¸šæ”¿ç­–æ”¶ç´§ å¤šå®¶æˆ¿ä¼é¢ä¸´èµ„é‡‘å‹åŠ›", 
                "content": """è¿‘æœŸå¤šåœ°å‡ºå°æˆ¿åœ°äº§è°ƒæ§æ”¿ç­–ï¼Œè¿›ä¸€æ­¥æ”¶ç´§æˆ¿åœ°äº§å¸‚åœºã€‚åŒæ—¶ï¼Œå¤®è¡Œå’Œé“¶ä¿ç›‘ä¼šè”åˆå‘å¸ƒé€šçŸ¥ï¼Œè¦æ±‚é“¶è¡Œä¸¥æ ¼æ§åˆ¶æˆ¿åœ°äº§è´·æ¬¾é›†ä¸­åº¦ã€‚

å—æ”¿ç­–å½±å“ï¼Œå¤šå®¶æˆ¿åœ°äº§ä¼ä¸šé¢ä¸´èµ„é‡‘é“¾ç´§å¼ é—®é¢˜ã€‚éƒ¨åˆ†ä¸­å°æˆ¿ä¼å·²å‡ºç°å€ºåˆ¸è¿çº¦é£é™©ï¼Œè¡Œä¸šæ´—ç‰ŒåŠ é€Ÿã€‚è¯„çº§æœºæ„çº·çº·ä¸‹è°ƒæˆ¿åœ°äº§è¡Œä¸šè¯„çº§å±•æœ›ã€‚

åˆ†æäººå£«æŒ‡å‡ºï¼Œæˆ¿åœ°äº§è¡Œä¸šæ­£è¿›å…¥æ·±åº¦è°ƒæ•´æœŸï¼ŒæŠ•èµ„è€…åº”è°¨æ…å¯¹å¾…æˆ¿åœ°äº§ç›¸å…³èµ„äº§ï¼Œå…³æ³¨è¡Œä¸šé£é™©ã€‚""",
                "source": "è´¢ç»ç½‘",
                "expected_impact": ["åœ°äº§", "é‡‘è"],
                "expected_sentiment": "è´Ÿé¢"
            },
            {
                "id": "test_004",
                "title": "äººå·¥æ™ºèƒ½èŠ¯ç‰‡æŠ€æœ¯çªç ´ å›½äº§æ›¿ä»£åŠ é€Ÿ",
                "content": """å›½å†…äººå·¥æ™ºèƒ½èŠ¯ç‰‡ä¼ä¸šåœ¨GPUå’ŒAIåŠ é€ŸèŠ¯ç‰‡é¢†åŸŸå–å¾—é‡å¤§æŠ€æœ¯çªç ´ï¼Œæ€§èƒ½æŒ‡æ ‡å·²æ¥è¿‘å›½é™…å…ˆè¿›æ°´å¹³ã€‚å¤šå®¶ç§‘æŠ€å…¬å¸è¡¨ç¤ºå°†é‡‡ç”¨å›½äº§AIèŠ¯ç‰‡æ›¿ä»£è¿›å£äº§å“ã€‚

å·¥ä¿¡éƒ¨è¡¨ç¤ºå°†åŠ å¤§å¯¹äººå·¥æ™ºèƒ½èŠ¯ç‰‡äº§ä¸šçš„æ”¯æŒåŠ›åº¦ï¼Œæ¨åŠ¨äº§ä¸šé“¾ååŒå‘å±•ã€‚ç›¸å…³ä¼ä¸šæœ‰æœ›åœ¨æ”¿ç­–æ”¯æŒä¸‹å®ç°å¿«é€Ÿå‘å±•ã€‚

åˆ¸å•†ç ”æŠ¥è®¤ä¸ºï¼ŒAIèŠ¯ç‰‡å›½äº§åŒ–è¿›ç¨‹åŠ é€Ÿï¼Œå°†å¸¦åŠ¨æ•´ä¸ªåŠå¯¼ä½“äº§ä¸šé“¾å‡çº§ï¼Œç›¸å…³ä¸Šå¸‚å…¬å¸è¿æ¥é‡å¤§å‘å±•æœºé‡ã€‚""",
                "source": "ç§‘æŠ€æ—¥æŠ¥", 
                "expected_impact": ["ç§‘æŠ€", "èŠ¯ç‰‡", "äººå·¥æ™ºèƒ½"],
                "expected_sentiment": "æ­£é¢"
            },
            {
                "id": "test_005",
                "title": "ç”Ÿç‰©åŒ»è¯å…¬å¸æ–°è¯è·æ‰¹ è¡Œä¸šåˆ›æ–°æ´»åŠ›æ˜¾ç°",
                "content": """å›½å®¶è¯ç›‘å±€ä»Šæ—¥æ‰¹å‡†æŸç”Ÿç‰©åŒ»è¯å…¬å¸çš„åˆ›æ–°è¯ç‰©ä¸Šå¸‚ï¼Œè¿™æ˜¯ä»Šå¹´ç¬¬15ä¸ªè·æ‰¹çš„1ç±»æ–°è¯ã€‚è¯¥è¯ç‰©é’ˆå¯¹ç½•è§ç—…æ²»ç–—ï¼Œå¡«è¡¥äº†å›½å†…å¸‚åœºç©ºç™½ã€‚

åŒ»è¯è¡Œä¸šåˆ†æå¸ˆè®¤ä¸ºï¼Œéšç€è¯å®¡æ”¿ç­–æ”¹é©æ·±åŒ–ï¼Œå›½å†…åŒ»è¯ä¼ä¸šåˆ›æ–°èƒ½åŠ›ä¸æ–­æå‡ï¼Œæ–°è¯ç ”å‘ç®¡çº¿æ—¥ç›Šä¸°å¯Œã€‚åˆ›æ–°è¯ä¼ä¸šæœ‰æœ›è¿æ¥æ”¶è·æœŸã€‚

æœºæ„å»ºè®®å…³æ³¨ç ”å‘å®åŠ›å¼ºã€ç®¡çº¿ä¸°å¯Œçš„åˆ›æ–°è¯ä¼ï¼Œä»¥åŠCROã€CDMOç­‰åŒ»è¯æœåŠ¡ä¼ä¸šçš„æŠ•èµ„æœºä¼šã€‚""",
                "source": "åŒ»è¯ç»æµæŠ¥",
                "expected_impact": ["åŒ»è¯", "ç”Ÿç‰©åŒ»è¯"],
                "expected_sentiment": "æ­£é¢"
            }
        ]
    
    def setup(self):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        logger.info("ğŸš€ åˆå§‹åŒ–æ–°é—»åˆ†ææµ‹è¯•ç¯å¢ƒ...")
        
        try:
            # åˆå§‹åŒ–åƒé—®å®¢æˆ·ç«¯
            self.qwen_client = QwenLLMClient()
            
            # æµ‹è¯•è¿æ¥ï¼ˆä½¿ç”¨åŒæ­¥æ–¹å¼ï¼‰
            import asyncio
            async def test_connection():
                async with self.qwen_client as client:
                    test_response = await client.chat_completion(
                        messages=[{"role": "user", "content": "ä½ å¥½ï¼Œè¯·å›å¤'è¿æ¥æ­£å¸¸'"}],
                        max_tokens=10
                    )
                    return test_response.content
            
            response_content = asyncio.run(test_connection())
            
            if "è¿æ¥æ­£å¸¸" in response_content:
                logger.info("âœ… åƒé—®å®¢æˆ·ç«¯è¿æ¥æ­£å¸¸")
            else:
                logger.warning("âš ï¸ åƒé—®å®¢æˆ·ç«¯è¿æ¥å¼‚å¸¸")
            
            # åˆå§‹åŒ–åˆ†ææµæ°´çº¿
            self.analysis_flow = NewsAnalysisFlow(self.qwen_client)
            logger.info("âœ… æ–°é—»åˆ†ææµæ°´çº¿åˆå§‹åŒ–å®Œæˆ")
            
            return True
        
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def test_single_news_analysis(self, news_sample: Dict[str, Any]) -> Dict[str, Any]:
        """æµ‹è¯•å•æ¡æ–°é—»åˆ†æ"""
        logger.info(f"ğŸ“° å¼€å§‹åˆ†ææ–°é—»: {news_sample['title']}")
        
        try:
            # æ‰§è¡Œæ–°é—»åˆ†æ
            result = self.analysis_flow.analyze_news(
                news_content=f"{news_sample['title']}\n\n{news_sample['content']}",
                news_id=news_sample['id']
            )
            
            # åˆ†æç»“æœè¯„ä¼°
            evaluation = self._evaluate_analysis_result(result, news_sample)
            
            logger.info(f"âœ… æ–°é—»åˆ†æå®Œæˆ: {news_sample['id']}, è€—æ—¶: {result.processing_time:.2f}ç§’")
            
            return {
                "news_id": news_sample['id'],
                "result": result,
                "evaluation": evaluation,
                "success": True
            }
        
        except Exception as e:
            logger.error(f"âŒ æ–°é—»åˆ†æå¤±è´¥: {news_sample['id']} - {e}")
            return {
                "news_id": news_sample['id'],
                "error": str(e),
                "success": False
            }
    
    def _evaluate_analysis_result(self, result, expected: Dict) -> Dict[str, Any]:
        """è¯„ä¼°åˆ†æç»“æœè´¨é‡"""
        evaluation = {
            "accuracy_score": 0.0,
            "completeness_score": 0.0,
            "quality_score": 0.0,
            "details": {}
        }
        
        try:
            # æƒ…æ„Ÿå€¾å‘å‡†ç¡®æ€§
            predicted_sentiment = result.classification.get("sentiment", "ä¸­æ€§")
            expected_sentiment = expected.get("expected_sentiment", "ä¸­æ€§")
            sentiment_match = predicted_sentiment == expected_sentiment
            evaluation["details"]["sentiment_match"] = sentiment_match
            
            # è¡Œä¸šå½±å“å‡†ç¡®æ€§
            predicted_industries = [
                ind.get("industry", "") for ind in 
                result.industry_analysis.get("affected_industries", [])
            ]
            expected_industries = expected.get("expected_impact", [])
            industry_overlap = len(set(predicted_industries) & set(expected_industries))
            industry_accuracy = industry_overlap / max(len(expected_industries), 1)
            evaluation["details"]["industry_accuracy"] = industry_accuracy
            
            # å®Œæ•´æ€§è¯„åˆ†
            has_classification = bool(result.classification)
            has_industry_analysis = bool(result.industry_analysis.get("affected_industries"))
            has_stocks = bool(result.related_stocks)
            has_advice = bool(result.investment_advice.get("recommendation"))
            
            completeness_score = sum([has_classification, has_industry_analysis, has_stocks, has_advice]) / 4
            evaluation["completeness_score"] = completeness_score
            
            # å‡†ç¡®æ€§è¯„åˆ†
            accuracy_score = (sentiment_match + industry_accuracy) / 2
            evaluation["accuracy_score"] = accuracy_score
            
            # è´¨é‡è¯„åˆ†
            importance_score = result.classification.get("importance_score", 0) / 10
            confidence_level = result.investment_advice.get("confidence_level", 0) / 10
            quality_score = (importance_score + confidence_level + result.confidence_score) / 3
            evaluation["quality_score"] = quality_score
            
        except Exception as e:
            logger.error(f"ç»“æœè¯„ä¼°å¤±è´¥: {e}")
        
        return evaluation
    
    def run_batch_test(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰¹é‡æµ‹è¯•"""
        logger.info("ğŸ“Š å¼€å§‹æ‰¹é‡æ–°é—»åˆ†ææµ‹è¯•...")
        
        batch_results = {
            "total_count": len(self.test_news_samples),
            "success_count": 0,
            "failed_count": 0,
            "total_time": 0.0,
            "results": []
        }
        
        start_time = datetime.now()
        
        for news_sample in self.test_news_samples:
            test_result = self.test_single_news_analysis(news_sample)
            batch_results["results"].append(test_result)
            
            if test_result["success"]:
                batch_results["success_count"] += 1
            else:
                batch_results["failed_count"] += 1
        
        batch_results["total_time"] = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"ğŸ“ˆ æ‰¹é‡æµ‹è¯•å®Œæˆ: {batch_results['success_count']}/{batch_results['total_count']} æˆåŠŸ")
        
        return batch_results
    
    def print_detailed_result(self, test_result: Dict[str, Any]):
        """æ‰“å°è¯¦ç»†çš„æµ‹è¯•ç»“æœ"""
        if not test_result["success"]:
            print(f"âŒ åˆ†æå¤±è´¥: {test_result['news_id']} - {test_result['error']}")
            return
        
        result = test_result["result"]
        evaluation = test_result["evaluation"]
        
        print(f"\nğŸ“° æ–°é—»åˆ†æç»“æœ: {result.news_id}")
        print("=" * 60)
        
        # æ–°é—»åˆ†ç±»
        classification = result.classification
        print(f"ğŸ“Š æ–°é—»åˆ†ç±»:")
        print(f"  ç±»å‹: {classification.get('news_type', 'æœªçŸ¥')}")
        print(f"  é‡è¦æ€§: {classification.get('importance_score', 0)}/10")
        print(f"  æƒ…æ„Ÿ: {classification.get('sentiment', 'ä¸­æ€§')}")
        print(f"  å€¼å¾—åˆ†æ: {classification.get('worth_analysis', False)}")
        
        # è¡Œä¸šå½±å“
        industry_analysis = result.industry_analysis
        print(f"\nğŸ­ è¡Œä¸šå½±å“:")
        for industry in industry_analysis.get("affected_industries", []):
            print(f"  â€¢ {industry.get('industry', '')} - {industry.get('impact_type', '')} ({industry.get('impact_degree', 0)}/10)")
        
        # ç›¸å…³è‚¡ç¥¨
        print(f"\nğŸ“ˆ ç›¸å…³è‚¡ç¥¨ (å‰5åª):")
        for stock in result.related_stocks[:5]:
            print(f"  â€¢ {stock.get('code', '')} {stock.get('name', '')} - å…³è”åº¦: {stock.get('relevance_score', 0)}/10")
        
        # æŠ•èµ„å»ºè®®
        advice = result.investment_advice
        print(f"\nğŸ’° æŠ•èµ„å»ºè®®:")
        print(f"  å»ºè®®: {advice.get('recommendation', 'è§‚æœ›')}")
        print(f"  æ—¶é—´: {advice.get('time_horizon', 'çŸ­æœŸ')}")
        print(f"  ä¿¡å¿ƒ: {advice.get('confidence_level', 0)}/10")
        print(f"  ç†ç”±: {advice.get('rationale', 'æ— ')[:100]}...")
        
        # è¯„ä¼°ç»“æœ
        print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
        print(f"  å‡†ç¡®æ€§: {evaluation['accuracy_score']:.2f}")
        print(f"  å®Œæ•´æ€§: {evaluation['completeness_score']:.2f}")
        print(f"  è´¨é‡: {evaluation['quality_score']:.2f}")
        print(f"  ä¿¡å¿ƒè¯„åˆ†: {result.confidence_score:.2f}")
        print(f"  å¤„ç†æ—¶é—´: {result.processing_time:.2f}ç§’")
        
        print("=" * 60)
    
    def test_with_mock_news_source(self):
        """ä½¿ç”¨æ¨¡æ‹Ÿæ–°é—»æºè¿›è¡Œæµ‹è¯•"""
        logger.info("ğŸ” åˆ›å»ºæ¨¡æ‹Ÿæ–°é—»æºè¿›è¡Œæµ‹è¯•...")
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ–°é—»æº
        mock_source = NewsSource(
            id=1,
            name="æµ‹è¯•æ–°é—»æº",
            source_type=NewsSourceType.RSS,
            url="https://example.com/rss.xml",
            status=NewsSourceStatus.ACTIVE
        )
        
        logger.info(f"ğŸ“„ æ¨¡æ‹Ÿæ–°é—»æº: {mock_source.name}")
        
        # é€‰æ‹©ä¸€ä¸ªç¤ºä¾‹æ–°é—»è¿›è¡Œè¯¦ç»†åˆ†æ
        sample_news = self.test_news_samples[0]
        
        print(f"\nğŸ¯ è¯¦ç»†åˆ†æç¤ºä¾‹æ–°é—»:")
        print(f"æ ‡é¢˜: {sample_news['title']}")
        print(f"æ¥æº: {sample_news['source']}")
        print("-" * 50)
        
        # æ‰§è¡Œè¯¦ç»†åˆ†æ
        result = self.test_single_news_analysis(sample_news)
        
        # æ‰“å°è¯¦ç»†ç»“æœ
        self.print_detailed_result(result)
        
        return result

def main():
    """ä¸»å‡½æ•° - æ”¹ä¸ºåŒæ­¥æ‰§è¡Œ"""
    logger.info("ğŸŒŸ æ–°é—»åˆ†ææµæ°´çº¿æµ‹è¯•å¼€å§‹")
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = NewsAnalysisTestSuite()
    
    # åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ
    if not test_suite.setup():
        logger.error("âŒ æµ‹è¯•ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡º")
        return
    
    print("\n" + "=" * 60)
    logger.info("ğŸ“‹ ç¬¬ä¸€é˜¶æ®µ: å•æ¡æ–°é—»è¯¦ç»†åˆ†ææµ‹è¯•")
    print("=" * 60)
    
    # æ‰§è¡Œæ¨¡æ‹Ÿæ–°é—»æºæµ‹è¯•
    test_suite.test_with_mock_news_source()
    
    logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main() 
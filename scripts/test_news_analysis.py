#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æµ‹è¯•å¢å¼ºç‰ˆæ–°é—»åˆ†æç³»ç»Ÿä¿®å¤æ•ˆæœ
éªŒè¯é—®é¢˜1-4çš„ä¿®å¤æƒ…å†µï¼š
1. NewsArticleæ¨¡å‹é€‚é…çœŸå®æ•°æ®åº“
2. è‚¡ç¥¨æ£€æµ‹é€»è¾‘ä¿®å¤  
3. AKShareè¡Œä¸šè‚¡ç¥¨ç­›é€‰ä¿®å¤
4. æ€§èƒ½ä¼˜åŒ–ï¼ˆ0åªè‚¡ç¥¨æ—¶è·³è¿‡LLMï¼‰
"""

import asyncio
import logging
import sys
import os
import json
from datetime import datetime
from typing import List, Dict, Any

from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, project_root)

from core.models.news_article import NewsArticle
from core.ai_agents.llm_clients.qwen_client import QwenLLMClient
from core.ai_agents.flow_definitions.news_analysis_flow import NewsAnalysisFlow

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æµ‹è¯•ç”¨ä¾‹ - åŒ…å«ä¹‹å‰å¯¼è‡´é—®é¢˜çš„æ–°é—»
TEST_CASES = [
    {
        "name": "æµ‹è¯•æ¡ˆä¾‹1: é¦™æ¸¯è‚¡ç¥¨æ£€æµ‹",
        "title": "æ²ªä¸Šé˜¿å§¨(02589)ï¼šæ‚‰æ•°è¡Œä½¿è¶…é¢é…è‚¡æƒã€ç¨³å®šä»·æ ¼è¡ŒåŠ¨åŠç¨³å®šä»·æ ¼æœŸç»“æŸ", 
        "content": None,
        "expected_type": "stock_specific",
        "expected_stocks": ["02589"],
        "test_problems": [1, 2]  # æµ‹è¯•é—®é¢˜2ï¼šè‚¡ç¥¨æ£€æµ‹é€»è¾‘
    }
    # {
    #     "name": "æµ‹è¯•æ¡ˆä¾‹1: é¦™æ¸¯è‚¡ç¥¨æ£€æµ‹",
    #     "title": "å‹è°Šæ—¶å…‰(06820)è‚¡ä»·å¼‚åŠ¨", 
    #     "content": "å‹è°Šæ—¶å…‰(06820)ä»Šæ—¥è‚¡ä»·å¤§æ¶¨ï¼Œå¸‚åœºå…³æ³¨åº¦è¾ƒé«˜ã€‚è¯¥å…¬å¸ä¸»è¦ä»äº‹é¤é¥®ä¸šåŠ¡ã€‚",
    #     "expected_type": "stock_specific",
    #     "expected_stocks": ["06820"],
    #     "test_problems": [2]  # æµ‹è¯•é—®é¢˜2ï¼šè‚¡ç¥¨æ£€æµ‹é€»è¾‘
    # },
    # {
    #     "name": "æµ‹è¯•æ¡ˆä¾‹2: Aè‚¡è‚¡ç¥¨æ£€æµ‹",
    #     "title": "å¹³å®‰é“¶è¡Œ(000001)å‘å¸ƒä¸šç»©é¢„å‘Š",
    #     "content": "å¹³å®‰é“¶è¡Œ(000001)å‘å¸ƒ2024å¹´ä¸šç»©é¢„å‘Šï¼Œé¢„è®¡å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿5%-10%ã€‚",
    #     "expected_type": "stock_specific", 
    #     "expected_stocks": ["000001"],
    #     "test_problems": [2]
    # },
    # {
    #     "name": "æµ‹è¯•æ¡ˆä¾‹3: è¡Œä¸šæ–°é—»ï¼ˆæ–°èƒ½æºï¼‰",
    #     "title": "æ–°èƒ½æºæ±½è½¦è¡Œä¸šæ”¿ç­–åˆ©å¥½",
    #     "content": "å›½å®¶å‘æ”¹å§”å‘å¸ƒæ–°èƒ½æºæ±½è½¦äº§ä¸šå‘å±•è§„åˆ’ï¼Œæ˜ç¡®2025å¹´æ–°èƒ½æºæ±½è½¦é”€é‡ç›®æ ‡ã€‚æ¶‰åŠåŠ¨åŠ›ç”µæ± ã€å……ç”µæ¡©ç­‰å¤šä¸ªç»†åˆ†é¢†åŸŸã€‚",
    #     "expected_type": "industry_focused",
    #     "expected_industries": ["æ–°èƒ½æºæ±½è½¦", "æ–°èƒ½æº"],
    #     "test_problems": [3, 4]  # æµ‹è¯•é—®é¢˜3å’Œ4ï¼šAKShareç­›é€‰å’Œæ€§èƒ½ä¼˜åŒ–
    # },
    # {
    #     "name": "æµ‹è¯•æ¡ˆä¾‹4: è¡Œä¸šæ–°é—»ï¼ˆåŒ»è¯ï¼‰",
    #     "title": "åŒ»è¯è¡Œä¸šç›‘ç®¡æ–°è§„å‡ºå°",
    #     "content": "å›½å®¶è¯ç›‘å±€å‘å¸ƒåŒ»è¯è¡Œä¸šæ–°è§„ï¼Œå¯¹ç”Ÿç‰©åˆ¶è¯ã€åŒ»ç–—å™¨æ¢°ç­‰é¢†åŸŸæå‡ºæ–°è¦æ±‚ã€‚",
    #     "expected_type": "industry_focused",
    #     "expected_industries": ["åŒ»è¯", "ç”Ÿç‰©åŒ»è¯"],
    #     "test_problems": [3, 4]
    # },
    # {
    #     "name": "æµ‹è¯•æ¡ˆä¾‹5: ç©ºå†…å®¹æµ‹è¯•ï¼ˆæµ‹è¯•é—®é¢˜1ï¼‰",
    #     "title": "å¤–éƒ¨æ–°é—»é“¾æ¥æ ‡é¢˜",
    #     "content": None,  # æ¨¡æ‹Ÿæ•°æ®åº“ä¸­contentä¸ºNULLçš„æƒ…å†µ
    #     "url": "https://example.com/news/123",
    #     "test_problems": [1],  # æµ‹è¯•é—®é¢˜1ï¼šåŠ¨æ€å†…å®¹è·å–
    #     "expected_type": "unknown"
    # }
]

class NewsAnalysisFixTester:
    """æ–°é—»åˆ†æä¿®å¤éªŒè¯æµ‹è¯•å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        # ğŸ”§ å¯ç”¨æµ‹è¯•æ¨¡å¼ï¼Œé¿å…æ•°æ®åº“è¿æ¥é—®é¢˜
        self.test_mode = True
        logger.info("ğŸ§ª å¯åŠ¨æµ‹è¯•æ¨¡å¼ï¼Œé¿å…æ•°æ®åº“è¿æ¥é—®é¢˜")
        
        # åˆå§‹åŒ–åƒé—®å®¢æˆ·ç«¯
        self.llm_client = QwenLLMClient()
        
        # ğŸ”§ ä½¿ç”¨æµ‹è¯•æ¨¡å¼åˆå§‹åŒ–åˆ†ææµç¨‹ï¼Œé¿å…æ•°æ®åº“è¿æ¥
        self.analysis_flow = NewsAnalysisFlow(self.llm_client, test_mode=self.test_mode)
        self.test_results = []
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹"""
        logger.info("ğŸš€ å¼€å§‹æ–°é—»åˆ†æä¿®å¤æ•ˆæœæµ‹è¯•")
        logger.info(f"ğŸ“‹ æµ‹è¯•ç”¨ä¾‹æ€»æ•°: {len(TEST_CASES)}")
        
        for i, test_case in enumerate(TEST_CASES, 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ§ª æµ‹è¯• {i}/{len(TEST_CASES)}: {test_case['name']}")
            logger.info(f"ğŸ¯ æµ‹è¯•é—®é¢˜: {test_case.get('test_problems', [])}")
            
            try:
                result = await self.test_single_case(test_case)
                self.test_results.append(result)
                
                # æ˜¾ç¤ºæµ‹è¯•ç»“æœ
                self.print_test_result(result)
                
            except Exception as e:
                logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
                self.test_results.append({
                    "test_name": test_case['name'],
                    "success": False,
                    "error": str(e)
                })
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        await self.generate_test_report()
    
    async def test_single_case(self, test_case: Dict[str, Any]) -> Dict[str, Any]:
        """æµ‹è¯•å•ä¸ªç”¨ä¾‹"""
        
        # ğŸ”¥ æµ‹è¯•é—®é¢˜1: åˆ›å»ºçœŸå®çš„NewsArticleå¯¹è±¡ï¼ˆå¯èƒ½contentä¸ºç©ºï¼‰
        test_id = int(datetime.now().timestamp() * 1000)  # è½¬æ¢ä¸ºæ•´æ•°æ¯«ç§’æ—¶é—´æˆ³
        test_url = test_case.get("url", "https://example.com")
        url_hash = f"hash_{test_id}"  # ç”Ÿæˆç®€å•çš„hash
        
        article = NewsArticle(
            id=test_id,
            title=test_case["title"],
            content=test_case.get("content"),  # å¯èƒ½ä¸ºNone
            url=test_url,
            url_hash=url_hash,
            source_id=1,
            created_at=datetime.now()
        )
        
        start_time = datetime.now()
        
        # æ‰§è¡Œåˆ†æ
        analysis_result = await self.analysis_flow.analyze_news_with_article_async(article)
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # åˆ†ææµ‹è¯•ç»“æœ
        test_result = {
            "test_name": test_case["name"],
            "test_problems": test_case.get("test_problems", []),
            "processing_time": processing_time,
            "success": True,
            "issues_found": [],
            "fixes_verified": [],
            "analysis_details": {
                "analysis_type": analysis_result.analysis_type,
                "mentioned_stocks_count": len(analysis_result.mentioned_stocks),
                "related_stocks_count": len(analysis_result.related_stocks),
                "mentioned_stocks": analysis_result.mentioned_stocks,
                "related_stocks": analysis_result.related_stocks[:3],  # åªæ˜¾ç¤ºå‰3ä¸ª
                "investment_advice": analysis_result.investment_advice
            }
        }
        
        # éªŒè¯ä¿®å¤æ•ˆæœ
        await self.verify_fixes(test_case, analysis_result, test_result)
        
        return test_result
    
    async def verify_fixes(self, test_case: Dict, analysis_result, test_result: Dict):
        """éªŒè¯å„ä¸ªé—®é¢˜çš„ä¿®å¤æ•ˆæœ"""
        test_problems = test_case.get("test_problems", [])
        
        for problem_id in test_problems:
            if problem_id == 1:
                # ğŸ”¥ éªŒè¯é—®é¢˜1: NewsArticleæ¨¡å‹é€‚é…
                await self.verify_problem_1(test_case, analysis_result, test_result)
            elif problem_id == 2:
                # ğŸ”¥ éªŒè¯é—®é¢˜2: è‚¡ç¥¨æ£€æµ‹é€»è¾‘
                await self.verify_problem_2(test_case, analysis_result, test_result)
            elif problem_id == 3:
                # ğŸ”¥ éªŒè¯é—®é¢˜3: AKShareè¡Œä¸šè‚¡ç¥¨ç­›é€‰
                await self.verify_problem_3(test_case, analysis_result, test_result)
            elif problem_id == 4:
                # ğŸ”¥ éªŒè¯é—®é¢˜4: æ€§èƒ½ä¼˜åŒ–
                await self.verify_problem_4(test_case, analysis_result, test_result)
    
    async def verify_problem_1(self, test_case: Dict, analysis_result, test_result: Dict):
        """éªŒè¯é—®é¢˜1: NewsArticleæ¨¡å‹é€‚é…çœŸå®æ•°æ®åº“"""
        if test_case.get("content") is None:
            # éªŒè¯æ˜¯å¦æ­£ç¡®å¤„ç†äº†ç©ºcontentçš„æƒ…å†µ
            if hasattr(analysis_result.article, 'get_analysis_content'):
                content = analysis_result.article.get_analysis_content()
                if content and len(content) > 0:
                    test_result["fixes_verified"].append("é—®é¢˜1: âœ… æˆåŠŸè·å–åŠ¨æ€å†…å®¹")
                else:
                    test_result["issues_found"].append("é—®é¢˜1: âŒ æœªèƒ½è·å–åŠ¨æ€å†…å®¹")
            else:
                test_result["issues_found"].append("é—®é¢˜1: âŒ ç¼ºå°‘get_analysis_contentæ–¹æ³•")
        else:
            test_result["fixes_verified"].append("é—®é¢˜1: âœ… æœ‰å†…å®¹çš„æƒ…å†µæ­£å¸¸å¤„ç†")
    
    async def verify_problem_2(self, test_case: Dict, analysis_result, test_result: Dict):
        """éªŒè¯é—®é¢˜2: è‚¡ç¥¨æ£€æµ‹é€»è¾‘ä¿®å¤"""
        expected_type = test_case.get("expected_type")
        expected_stocks = test_case.get("expected_stocks", [])
        
        # æ£€æŸ¥åˆ†æç±»å‹æ˜¯å¦æ­£ç¡®
        if analysis_result.analysis_type == expected_type:
            test_result["fixes_verified"].append(f"é—®é¢˜2: âœ… åˆ†æç±»å‹æ­£ç¡® ({expected_type})")
        else:
            test_result["issues_found"].append(
                f"é—®é¢˜2: âŒ åˆ†æç±»å‹é”™è¯¯ï¼ŒæœŸæœ›: {expected_type}, å®é™…: {analysis_result.analysis_type}"
            )
        
        # æ£€æŸ¥æ˜¯å¦æ­£ç¡®è¯†åˆ«äº†è‚¡ç¥¨
        mentioned_codes = [stock.get("code", "") for stock in analysis_result.mentioned_stocks]
        for expected_code in expected_stocks:
            if any(expected_code in code for code in mentioned_codes):
                test_result["fixes_verified"].append(f"é—®é¢˜2: âœ… æ­£ç¡®è¯†åˆ«è‚¡ç¥¨ {expected_code}")
            else:
                test_result["issues_found"].append(f"é—®é¢˜2: âŒ æœªè¯†åˆ«è‚¡ç¥¨ {expected_code}")
    
    async def verify_problem_3(self, test_case: Dict, analysis_result, test_result: Dict):
        """éªŒè¯é—®é¢˜3: AKShareè¡Œä¸šè‚¡ç¥¨ç­›é€‰ä¿®å¤"""
        related_stocks_count = len(analysis_result.related_stocks)
        
        if related_stocks_count > 0:
            test_result["fixes_verified"].append(f"é—®é¢˜3: âœ… AKShareæˆåŠŸè·å– {related_stocks_count} åªç›¸å…³è‚¡ç¥¨")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«AKShareæ•°æ®æºæ ‡è¯†
            akshare_stocks = [
                stock for stock in analysis_result.related_stocks 
                if "akshare" in stock.get("analysis_source", "").lower()
            ]
            if akshare_stocks:
                test_result["fixes_verified"].append(f"é—®é¢˜3: âœ… å«æœ‰ {len(akshare_stocks)} åªAKShareæ¥æºè‚¡ç¥¨")
            else:
                test_result["issues_found"].append("é—®é¢˜3: âŒ æœªå‘ç°AKShareæ¥æºçš„è‚¡ç¥¨")
        else:
            test_result["issues_found"].append("é—®é¢˜3: âŒ AKShareæœªè¿”å›ä»»ä½•è‚¡ç¥¨ï¼ˆå¯èƒ½ä»æœ‰é—®é¢˜ï¼‰")
    
    async def verify_problem_4(self, test_case: Dict, analysis_result, test_result: Dict):
        """éªŒè¯é—®é¢˜4: æ€§èƒ½ä¼˜åŒ–ï¼ˆ0åªè‚¡ç¥¨æ—¶è·³è¿‡LLMï¼‰"""
        related_stocks_count = len(analysis_result.related_stocks)
        mentioned_stocks_count = len(analysis_result.mentioned_stocks)
        
        investment_advice = analysis_result.investment_advice
        token_saved = investment_advice.get("token_saved", False)
        
        if related_stocks_count == 0 and mentioned_stocks_count == 0:
            if token_saved:
                test_result["fixes_verified"].append("é—®é¢˜4: âœ… 0åªè‚¡ç¥¨æ—¶æˆåŠŸè·³è¿‡LLMåˆ†æï¼ŒèŠ‚çœtoken")
            else:
                test_result["issues_found"].append("é—®é¢˜4: âŒ 0åªè‚¡ç¥¨æ—¶ä»ç„¶è°ƒç”¨äº†LLM")
        else:
            if not token_saved:
                test_result["fixes_verified"].append("é—®é¢˜4: âœ… æœ‰è‚¡ç¥¨æ•°æ®æ—¶æ­£å¸¸ä½¿ç”¨LLMåˆ†æ")
            else:
                test_result["issues_found"].append("é—®é¢˜4: âŒ æœ‰è‚¡ç¥¨æ•°æ®æ—¶é”™è¯¯è·³è¿‡äº†LLM")
    
    def print_test_result(self, result: Dict):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {result['test_name']}")
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {result['processing_time']:.2f}ç§’")
        
        if result["fixes_verified"]:
            print("âœ… ä¿®å¤éªŒè¯é€šè¿‡:")
            for fix in result["fixes_verified"]:
                print(f"   {fix}")
        
        if result["issues_found"]:
            print("âŒ å‘ç°é—®é¢˜:")
            for issue in result["issues_found"]:
                print(f"   {issue}")
        
        details = result["analysis_details"]
        print(f"ğŸ“ˆ åˆ†æè¯¦æƒ…:")
        print(f"   - åˆ†æç±»å‹: {details['analysis_type']}")
        print(f"   - æåŠè‚¡ç¥¨: {details['mentioned_stocks_count']}åª")
        print(f"   - ç›¸å…³è‚¡ç¥¨: {details['related_stocks_count']}åª")
        
        if details["mentioned_stocks"]:
            stocks_info = [f"{s['code']}({s.get('name', '')})" for s in details['mentioned_stocks']]
            print(f"   - æåŠçš„è‚¡ç¥¨: {stocks_info}")
        
        if details["related_stocks"]:
            stocks_info = [f"{s['code']}({s.get('name', '')})-{s.get('current_score', 0)}åˆ†" for s in details['related_stocks']]
            print(f"   - ç›¸å…³è‚¡ç¥¨(å‰3): {stocks_info}")
        
        advice = details["investment_advice"]
        print(f"   - æŠ•èµ„å»ºè®®: {advice.get('recommendation', 'N/A')}")
        if advice.get("token_saved"):
            print(f"   - TokenèŠ‚çœ: âœ… (è·³è¿‡LLMåˆ†æ)")
        else:
            print(f"   - LLMåˆ†æ: âœ… (æ­£å¸¸è°ƒç”¨)")
    
    async def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        logger.info(f"\n{'='*80}")
        logger.info("ğŸ“ æµ‹è¯•æŠ¥å‘Šæ±‡æ€»")
        logger.info(f"{'='*80}")
        
        total_tests = len(self.test_results)
        successful_tests = sum(1 for r in self.test_results if r["success"])
        total_fixes = sum(len(r.get("fixes_verified", [])) for r in self.test_results)
        total_issues = sum(len(r.get("issues_found", [])) for r in self.test_results)
        
        logger.info(f"ğŸ“Š æµ‹è¯•ç»Ÿè®¡:")
        logger.info(f"   - æ€»æµ‹è¯•æ•°: {total_tests}")
        logger.info(f"   - æˆåŠŸæµ‹è¯•: {successful_tests}")
        logger.info(f"   - ä¿®å¤éªŒè¯: {total_fixes}é¡¹")
        logger.info(f"   - å‘ç°é—®é¢˜: {total_issues}é¡¹")
        
        # æŒ‰é—®é¢˜åˆ†ç±»ç»Ÿè®¡
        problem_stats = {1: {"fixed": 0, "issues": 0}, 2: {"fixed": 0, "issues": 0}, 
                        3: {"fixed": 0, "issues": 0}, 4: {"fixed": 0, "issues": 0}}
        
        for result in self.test_results:
            for fix in result.get("fixes_verified", []):
                for p in range(1, 5):
                    if f"é—®é¢˜{p}" in fix:
                        problem_stats[p]["fixed"] += 1
            
            for issue in result.get("issues_found", []):
                for p in range(1, 5):
                    if f"é—®é¢˜{p}" in issue:
                        problem_stats[p]["issues"] += 1
        
        logger.info(f"\nğŸ“‹ é—®é¢˜ä¿®å¤ç»Ÿè®¡:")
        problem_names = {
            1: "NewsArticleæ¨¡å‹é€‚é…",
            2: "è‚¡ç¥¨æ£€æµ‹é€»è¾‘ä¿®å¤", 
            3: "AKShareè¡Œä¸šç­›é€‰",
            4: "æ€§èƒ½ä¼˜åŒ–"
        }
        
        for p in range(1, 5):
            fixed = problem_stats[p]["fixed"]
            issues = problem_stats[p]["issues"]
            status = "âœ… ä¿®å¤æˆåŠŸ" if fixed > issues else "âŒ ä»æœ‰é—®é¢˜" if issues > 0 else "âšª æœªæµ‹è¯•"
            logger.info(f"   é—®é¢˜{p} ({problem_names[p]}): {status} (éªŒè¯{fixed}é¡¹, é—®é¢˜{issues}é¡¹)")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = f"test_fix_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    tester = NewsAnalysisFixTester()
    await tester.run_all_tests()

if __name__ == "__main__":
    asyncio.run(main()) 
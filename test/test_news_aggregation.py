#!/usr/bin/env python3
"""
æ–°é—»èšåˆåŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•è‹±ä¸ºè´¢æƒ…ç­‰RSSæºçš„æ•°æ®æŠ“å–åŠŸèƒ½
"""

import asyncio
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from core.database.news_db_init import NewsDBInitializer
from core.news_aggregator.rss_aggregator import RSSAggregator
from core.news_aggregator.news_aggregator_manager import NewsAggregatorManager
from core.models.news_source import NewsSource, NewsSourceType, NewsSourceStatus

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def test_investing_rss_sources():
    """æµ‹è¯•è‹±ä¸ºè´¢æƒ…ç­‰RSSæº"""
    logger.info("å¼€å§‹æµ‹è¯•è‹±ä¸ºè´¢æƒ…RSSæº...")
    
    # è‹±ä¸ºè´¢æƒ…çš„RSSæºåˆ—è¡¨ï¼ˆä»å®é™…å¯ç”¨çš„æºä¸­é€‰æ‹©ï¼‰
    test_sources = [
        {
            "name": "è‹±ä¸ºè´¢æƒ…-ç»¼åˆæ–°é—»",
            "url": "https://cn.investing.com/rss/news.rss",
            "description": "è‹±ä¸ºè´¢æƒ…ç»¼åˆè´¢ç»æ–°é—»"
        },
        {
            "name": "è‹±ä¸ºè´¢æƒ…-è‚¡ç¥¨æ–°é—»", 
            "url": "https://cn.investing.com/rss/news_285.rss",
            "description": "è‹±ä¸ºè´¢æƒ…è‚¡ç¥¨æ–°é—»"
        },
        {
            "name": "æ–°æµªè´¢ç»-è¦é—»",
            "url": "https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=1686&k=&num=50&page=1",
            "description": "æ–°æµªè´¢ç»è¦é—»"
        }
    ]
    
    async with RSSAggregator() as aggregator:
        for source_config in test_sources:
            try:
                logger.info(f"\næµ‹è¯•RSSæº: {source_config['name']}")
                logger.info(f"URL: {source_config['url']}")
                
                # åˆ›å»ºä¸´æ—¶æ–°é—»æºå¯¹è±¡
                news_source = NewsSource(
                    name=source_config['name'],
                    description=source_config['description'],
                    source_type=NewsSourceType.RSS,
                    url=source_config['url'],
                    max_articles_per_fetch=5,  # æµ‹è¯•æ—¶åªæŠ“å–5ç¯‡
                    language='zh',
                    region='CN',
                    status=NewsSourceStatus.ACTIVE
                )
                
                # æŠ“å–æ•°æ®
                articles = await aggregator.fetch_rss_feed(news_source)
                
                logger.info(f"âœ… æˆåŠŸæŠ“å– {len(articles)} ç¯‡æ–‡ç« ")
                
                # æ˜¾ç¤ºå‰3ç¯‡æ–‡ç« çš„æ ‡é¢˜
                for i, article in enumerate(articles[:3]):
                    logger.info(f"  {i+1}. {article.get('title', 'æ— æ ‡é¢˜')[:100]}")
                    logger.info(f"     URL: {article.get('url', 'æ— URL')}")
                    logger.info(f"     æ—¶é—´: {article.get('published_at', 'æ— æ—¶é—´')}")
                    logger.info(f"     å†…å®¹é•¿åº¦: {article.get('word_count', 0)} å­—")
                
            except Exception as e:
                logger.error(f"âŒ æŠ“å–å¤±è´¥ {source_config['name']}: {e}")

async def test_database_initialization():
    """æµ‹è¯•æ•°æ®åº“åˆå§‹åŒ–"""
    logger.info("å¼€å§‹æµ‹è¯•æ•°æ®åº“åˆå§‹åŒ–...")
    
    try:
        initializer = NewsDBInitializer("sqlite+aiosqlite:///./test_news.db")
        
        # æ¸…ç†å¹¶é‡æ–°åˆå§‹åŒ–
        await initializer.clean_and_reinitialize()
        
        logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        
        # è·å–åˆå§‹åŒ–çš„æ–°é—»æºæ•°é‡
        async with initializer.SessionLocal() as session:
            from sqlalchemy import select
            query = select(NewsSource)
            result = await session.execute(query)
            sources = result.scalars().all()
            
            logger.info(f"ğŸ“Š å·²é…ç½® {len(sources)} ä¸ªé»˜è®¤æ–°é—»æº:")
            for source in sources:
                logger.info(f"  - {source.name} ({source.source_type.value}) - {source.status.value}")
        
        await initializer.close()
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        raise

async def test_news_aggregator_manager():
    """æµ‹è¯•æ–°é—»èšåˆç®¡ç†å™¨"""
    logger.info("å¼€å§‹æµ‹è¯•æ–°é—»èšåˆç®¡ç†å™¨...")
    
    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        initializer = NewsDBInitializer("sqlite+aiosqlite:///./test_news.db")
        await initializer.initialize_all()
        
        # åˆ›å»ºèšåˆç®¡ç†å™¨
        manager = NewsAggregatorManager(initializer.SessionLocal)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = await manager.get_aggregation_stats()
        logger.info(f"ğŸ“Š èšåˆç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"  æ–°é—»æºæ€»æ•°: {stats['source_stats']['total']}")
        logger.info(f"  æ´»è·ƒæºæ•°é‡: {stats['source_stats']['active']}")
        logger.info(f"  æ–‡ç« æ€»æ•°: {stats['article_stats']['total']}")
        
        # æµ‹è¯•å•ä¸ªæºçš„è¿é€šæ€§ï¼ˆè‹±ä¸ºè´¢æƒ…ï¼‰
        async with initializer.SessionLocal() as session:
            from sqlalchemy import select
            query = select(NewsSource).where(NewsSource.name.contains("è‹±ä¸ºè´¢æƒ…"))
            result = await session.execute(query)
            investing_source = result.scalar_one_or_none()
            
            if investing_source:
                logger.info(f"\næµ‹è¯•è‹±ä¸ºè´¢æƒ…æºè¿é€šæ€§: {investing_source.name}")
                test_result = await manager.test_source_connectivity(investing_source.id)
                
                if test_result['success']:
                    logger.info(f"âœ… è¿é€šæ€§æµ‹è¯•æˆåŠŸï¼ŒæŠ“å–åˆ° {test_result['articles_count']} ç¯‡æ–‡ç« ")
                    for article in test_result.get('sample_articles', []):
                        logger.info(f"  - {article['title'][:80]}...")
                else:
                    logger.error(f"âŒ è¿é€šæ€§æµ‹è¯•å¤±è´¥: {test_result['error']}")
        
        await initializer.close()
        
    except Exception as e:
        logger.error(f"âŒ èšåˆç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        raise

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æ–°é—»èšåˆåŠŸèƒ½å…¨é¢æµ‹è¯•")
    
    try:
        # 1. æµ‹è¯•RSSæºç›´æ¥æŠ“å–
        await test_investing_rss_sources()
        
        # 2. æµ‹è¯•æ•°æ®åº“åˆå§‹åŒ–
        await test_database_initialization()
        
        # 3. æµ‹è¯•èšåˆç®¡ç†å™¨
        await test_news_aggregator_manager()
        
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        logger.error(f"ğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main()) 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ–°é—»åˆ†ææµæ°´çº¿

åŸºäºPocketFlowæ¡†æ¶çš„å¤šAgentåä½œæ–°é—»åˆ†æç³»ç»Ÿã€‚
é€šè¿‡å››ä¸ªä¸“ä¸šAgentåä½œï¼Œå®ç°ä»æ–°é—»å†…å®¹åˆ°æŠ•èµ„å»ºè®®çš„å®Œæ•´åˆ†ææµç¨‹ã€‚
"""

import json
import logging
import asyncio
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from datetime import datetime

# PocketFlowæ¡†æ¶å¯¼å…¥
from pocketflow import Flow, Node

# é¡¹ç›®å†…éƒ¨æ¨¡å—å¯¼å…¥
from ..llm_clients.qwen_client import QwenLLMClient
from ..llm_clients.silicon_flow_client import SiliconFlowClient
from ...data_providers.stock_data_factory import StockDataFactory
from ...models.news_source import NewsSource
from ..utils.akshare_industry_provider import get_industry_stocks_from_akshare

logger = logging.getLogger(__name__)

@dataclass
class NewsAnalysisResult:
    """æ–°é—»åˆ†æç»“æœ"""
    news_id: str
    news_content: str
    classification: Dict[str, Any]
    industry_analysis: Dict[str, Any]
    related_stocks: List[Dict[str, Any]]
    investment_advice: Dict[str, Any]
    analysis_time: datetime
    confidence_score: float
    processing_time: float

class NewsClassifierAgent(Node):
    """æ–°é—»åˆ†ç±»å™¨Agent - å¿«é€Ÿåˆ¤æ–­æ–°é—»æ€§è´¨å’Œé‡è¦æ€§"""
    
    def __init__(self, llm_client: QwenLLMClient):
        super().__init__()
        self.llm_client = llm_client
    
    def prep(self, shared_store: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡åˆ†ç±»æ‰€éœ€çš„æ•°æ®"""
        return {
            "news_content": shared_store.get("news_content", ""),
            "shared_store": shared_store  # ä¼ é€’å…±äº«å­˜å‚¨çš„å¼•ç”¨
        }
    
    def exec(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ–°é—»åˆ†ç±» - åŒæ­¥æ–¹æ³•"""
        return asyncio.run(self._exec_async(prep_data))
    
    async def _exec_async(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œæ–°é—»åˆ†ç±»"""
        news_content = prep_data.get("news_content", "")
        
        if not news_content:
            logger.error("æ–°é—»å†…å®¹ä¸ºç©º")
            return {"error": "æ–°é—»å†…å®¹ä¸ºç©º", "action": "error"}
        
        prompt = self._build_classification_prompt(news_content)
        
        try:
            async with self.llm_client as client:
                response = await client.chat_completion(
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3,
                    max_tokens=500
                )
            
            # è§£æåˆ†ç±»ç»“æœ
            classification = self._parse_classification_response(response.content)
            
            # åˆ¤æ–­æ˜¯å¦å€¼å¾—è¿›ä¸€æ­¥åˆ†æ
            if classification.get("worth_analysis", False):
                logger.info(f"æ–°é—»åˆ†ç±»å®Œæˆï¼Œé‡è¦æ€§è¯„åˆ†: {classification.get('importance_score', 0)}")
                action = "analyze_industry"
            else:
                logger.info("æ–°é—»è¢«åˆ¤å®šä¸ºä¸å€¼å¾—æŠ•èµ„åˆ†æï¼Œè·³è¿‡åç»­æ­¥éª¤")
                action = "skip"
            
            return {
                "classification": classification,
                "action": action
            }
        
        except Exception as e:
            logger.error(f"æ–°é—»åˆ†ç±»å¤±è´¥: {e}")
            return {
                "error": str(e),
                "action": "error"
            }
    
    def post(self, shared_store: Dict[str, Any], prep_data: Dict[str, Any], exec_result: Dict[str, Any]) -> str:
        """åå¤„ç† - ä¿å­˜ç»“æœåˆ°å…±äº«å­˜å‚¨å¹¶è¿”å›ä¸‹ä¸€æ­¥åŠ¨ä½œ"""
        if "classification" in exec_result:
            shared_store["classification"] = exec_result["classification"]
        
        if "error" in exec_result:
            shared_store["error"] = exec_result["error"]
        
        return exec_result.get("action", "error")
    
    def _build_classification_prompt(self, news_content: str) -> str:
        """æ„å»ºæ–°é—»åˆ†ç±»Prompt"""
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èæ–°é—»åˆ†ç±»å™¨ã€‚è¯·åˆ†æä»¥ä¸‹æ–°é—»å¹¶æä¾›ç»“æ„åŒ–è¾“å‡ºï¼š

æ–°é—»å†…å®¹ï¼š
{news_content[:2000]}  # é™åˆ¶é•¿åº¦é¿å…tokenè¶…é™

è¯·ä»ä»¥ä¸‹ç»´åº¦åˆ†æï¼š
1. æ–°é—»ç±»å‹ï¼š[æ”¿ç­–/è´¢æŠ¥/å¸‚åœº/æŠ€æœ¯/äººäº‹/å¹¶è´­/IPO/å…¶ä»–]
2. é‡è¦æ€§è¯„åˆ†ï¼š1-10åˆ†ï¼ˆ10åˆ†æœ€é‡è¦ï¼Œè€ƒè™‘å¯¹è‚¡å¸‚çš„æ½œåœ¨å½±å“ï¼‰
3. æ¶‰åŠå®ä½“ï¼šæå–å…¬å¸åã€è¡Œä¸šåã€äº§å“åï¼ˆæœ€å¤š5ä¸ªï¼‰
4. æƒ…æ„Ÿå€¾å‘ï¼š[æ­£é¢/è´Ÿé¢/ä¸­æ€§]
5. æ˜¯å¦å€¼å¾—æŠ•èµ„åˆ†æï¼š[true/false]

è¿”å›JSONæ ¼å¼ï¼š
{{
  "news_type": "ç±»å‹",
  "importance_score": åˆ†æ•°,
  "entities": ["å®ä½“1", "å®ä½“2"],
  "sentiment": "å€¾å‘",
  "worth_analysis": true/false,
  "reason": "åˆ¤æ–­ç†ç”±"
}}"""
    
    def _parse_classification_response(self, response_text: str) -> Dict[str, Any]:
        """è§£æåˆ†ç±»å“åº”"""
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            
            if start_idx >= 0 and end_idx > start_idx:
                json_str = response_text[start_idx:end_idx]
                return json.loads(json_str)
            else:
                raise ValueError("æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„JSONå†…å®¹")
        
        except Exception as e:
            logger.error(f"è§£æåˆ†ç±»ç»“æœå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ç»“æœ
            return {
                "news_type": "å…¶ä»–",
                "importance_score": 5,
                "entities": [],
                "sentiment": "ä¸­æ€§",
                "worth_analysis": True,
                "reason": "è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼"
            }

class IndustryAnalyzerAgent(Node):
    """è¡Œä¸šåˆ†æå™¨Agent - ç¡®å®šæ–°é—»åˆ©å¥½/åˆ©ç©ºçš„è¡Œä¸šé¢†åŸŸ"""
    
    def __init__(self, llm_client: QwenLLMClient):
        super().__init__()
        self.llm_client = llm_client
    
    def prep(self, shared_store: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡è¡Œä¸šåˆ†ææ‰€éœ€çš„æ•°æ®"""
        return {
            "news_content": shared_store.get("news_content", ""),
            "classification": shared_store.get("classification", {}),
            "shared_store": shared_store
        }
    
    def exec(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè¡Œä¸šå½±å“åˆ†æ - åŒæ­¥æ–¹æ³•"""
        return asyncio.run(self._exec_async(prep_data))
    
    async def _exec_async(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œè¡Œä¸šå½±å“åˆ†æ"""
        news_content = prep_data.get("news_content", "")
        classification = prep_data.get("classification", {})
        
        prompt = self._build_industry_analysis_prompt(news_content, classification)
        
        try:
            async with self.llm_client as client:
                response = await client.chat_completion(
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3,
                    max_tokens=800
                )
            
            # è§£æè¡Œä¸šåˆ†æç»“æœ
            industry_analysis = self._parse_industry_response(response.content)
            
            logger.info(f"è¡Œä¸šåˆ†æå®Œæˆï¼Œå½±å“ {len(industry_analysis.get('affected_industries', []))} ä¸ªè¡Œä¸š")
            
            return {
                "industry_analysis": industry_analysis,
                "action": "relate_stocks"
            }
        
        except Exception as e:
            logger.error(f"è¡Œä¸šåˆ†æå¤±è´¥: {e}")
            return {
                "error": str(e),
                "action": "error"
            }
    
    def post(self, shared_store: Dict[str, Any], prep_data: Dict[str, Any], exec_result: Dict[str, Any]) -> str:
        """åå¤„ç† - ä¿å­˜ç»“æœåˆ°å…±äº«å­˜å‚¨å¹¶è¿”å›ä¸‹ä¸€æ­¥åŠ¨ä½œ"""
        if "industry_analysis" in exec_result:
            shared_store["industry_analysis"] = exec_result["industry_analysis"]
        
        if "error" in exec_result:
            shared_store["error"] = exec_result["error"]
        
        return exec_result.get("action", "error")
    
    def _build_industry_analysis_prompt(self, news_content: str, classification: Dict) -> str:
        """æ„å»ºè¡Œä¸šåˆ†æPrompt"""
        return f"""ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„è¡Œä¸šåˆ†æå¸ˆã€‚è¯·åˆ†ææ–°é—»å¯¹å„è¡Œä¸šçš„å½±å“ï¼š

æ–°é—»å†…å®¹ï¼š
{news_content[:2000]}

æ–°é—»åˆ†ç±»ä¿¡æ¯ï¼š
- ç±»å‹ï¼š{classification.get('news_type', 'æœªçŸ¥')}
- é‡è¦æ€§ï¼š{classification.get('importance_score', 0)}åˆ†
- æ¶‰åŠå®ä½“ï¼š{', '.join(classification.get('entities', []))}
- æƒ…æ„Ÿå€¾å‘ï¼š{classification.get('sentiment', 'ä¸­æ€§')}

è¯·åˆ†æï¼š
1. ä¸»è¦å½±å“è¡Œä¸šï¼šæœ€å¤š3ä¸ªæœ€ç›¸å…³çš„è¡Œä¸š
2. å½±å“ç±»å‹ï¼š[åˆ©å¥½/åˆ©ç©º/ä¸­æ€§]
3. å½±å“ç¨‹åº¦ï¼š1-10åˆ†ï¼ˆ10åˆ†å½±å“æœ€å¤§ï¼‰
4. å½±å“æ—¶é—´ï¼š[çŸ­æœŸ/ä¸­æœŸ/é•¿æœŸ]
5. ä¼ å¯¼è·¯å¾„ï¼šå½±å“å¦‚ä½•ä¼ é€’åˆ°è¯¥è¡Œä¸š

ä¸­å›½è‚¡å¸‚ä¸»è¦è¡Œä¸šåˆ†ç±»ï¼š
- ç§‘æŠ€ï¼šäººå·¥æ™ºèƒ½ã€èŠ¯ç‰‡åŠå¯¼ä½“ã€è½¯ä»¶ã€äº’è”ç½‘ã€é€šä¿¡
- é‡‘èï¼šé“¶è¡Œã€ä¿é™©ã€è¯åˆ¸ã€æ”¯ä»˜ã€é‡‘èç§‘æŠ€
- åŒ»è¯ï¼šç”Ÿç‰©åŒ»è¯ã€åŒ»ç–—å™¨æ¢°ã€åŒ–å­¦åˆ¶è¯ã€ä¸­è¯
- æ¶ˆè´¹ï¼šé£Ÿå“é¥®æ–™ã€å®¶ç”µã€é›¶å”®ã€æ±½è½¦ã€æ•™è‚²
- åˆ¶é€ ï¼šæœºæ¢°è®¾å¤‡ã€åŒ–å·¥ã€å»ºæã€é’¢é“ã€æœ‰è‰²é‡‘å±
- èƒ½æºï¼šçŸ³æ²¹çŸ³åŒ–ã€ç…¤ç‚­ã€æ–°èƒ½æºã€ç”µåŠ›ã€ç¯ä¿
- åœ°äº§ï¼šæˆ¿åœ°äº§å¼€å‘ã€å»ºç­‘å·¥ç¨‹ã€è£…ä¿®è£…é¥°
- å†œä¸šï¼šå†œæ—ç‰§æ¸”ã€ç§ä¸šã€å†œä¸šæœºæ¢°

è¿”å›JSONæ ¼å¼ï¼š
{{
  "affected_industries": [
    {{
      "industry": "è¡Œä¸šåç§°",
      "impact_type": "åˆ©å¥½/åˆ©ç©º/ä¸­æ€§",
      "impact_degree": åˆ†æ•°,
      "time_horizon": "çŸ­æœŸ/ä¸­æœŸ/é•¿æœŸ",
      "reasoning": "å½±å“é€»è¾‘è¯´æ˜"
    }}
  ],
  "overall_market_impact": "å¯¹æ•´ä½“å¸‚åœºçš„å½±å“è¯„ä¼°"
}}"""
    
    def _parse_industry_response(self, response_text: str) -> Dict[str, Any]:
        """è§£æè¡Œä¸šåˆ†æå“åº”"""
        try:
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            
            if start_idx >= 0 and end_idx > start_idx:
                json_str = response_text[start_idx:end_idx]
                return json.loads(json_str)
            else:
                raise ValueError("æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„JSONå†…å®¹")
        
        except Exception as e:
            logger.error(f"è§£æè¡Œä¸šåˆ†æç»“æœå¤±è´¥: {e}")
            return {
                "affected_industries": [],
                "overall_market_impact": "å½±å“æœªæ˜"
            }

class StockRelatorAgent(Node):
    """è‚¡ç¥¨å…³è”Agent - æ ¹æ®è¡Œä¸šå½±å“åˆ†ææ‰¾å‡ºç›¸å…³è‚¡ç¥¨"""
    
    def __init__(self, llm_client: QwenLLMClient):
        super().__init__()
        self.llm_client = llm_client
        self.use_akshare = True  # ğŸ†• é»˜è®¤ä½¿ç”¨AKShareæ•°æ®æº
        self.use_vector_db = False  # ğŸ†• å‘é‡æ•°æ®åº“æ”¯æŒï¼ˆå¾…å®ç°ï¼‰
    
    def prep(self, shared_store: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡è‚¡ç¥¨å…³è”æ‰€éœ€çš„æ•°æ®"""
        return {
            "classification": shared_store.get("classification", {}),
            "industry_analysis": shared_store.get("industry_analysis", {}),
            "shared_store": shared_store
        }
    
    def exec(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè‚¡ç¥¨å…³è” - åŒæ­¥æ–¹æ³•"""
        return asyncio.run(self._exec_async(prep_data))
    
    async def _exec_async(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œè‚¡ç¥¨å…³è”"""
        industry_analysis = prep_data.get("industry_analysis", {})
        
        try:
            # è§£æè¡Œä¸šå½±å“ä¿¡æ¯
            affected_industries = industry_analysis.get("affected_industries", [])
            if not affected_industries:
                logger.warning("æœªæ‰¾åˆ°å—å½±å“çš„è¡Œä¸šä¿¡æ¯")
                return {
                    "related_stocks": [],
                    "action": "generate_advice"
                }
            
            # è·å–ç›¸å…³è‚¡ç¥¨
            all_stocks = []
            
            for industry_info in affected_industries:
                industry = industry_info.get("industry", "")
                impact_type = industry_info.get("impact_type", "æ­£é¢")
                impact_degree = industry_info.get("impact_degree", 5)
                
                if not industry:
                    continue
                
                # ğŸ†• ä½¿ç”¨AKShareè·å–è¡Œä¸šè‚¡ç¥¨
                if self.use_akshare:
                    stocks = await self._get_industry_stocks_akshare(
                        industry, impact_type, impact_degree
                    )
                else:
                    # ä¿ç•™LLMæ–¹å¼ä½œä¸ºå¤‡ç”¨
                    stocks = await self._get_industry_stocks_llm(
                        industry, impact_type, impact_degree
                    )
                
                if stocks:
                    all_stocks.extend(stocks)
                    logger.info(f"è¡Œä¸š {industry} è·å–åˆ° {len(stocks)} åªè‚¡ç¥¨")
            
            # å»é‡å¹¶æ’åº
            final_stocks = self._deduplicate_and_rank_stocks(all_stocks)
            
            # ğŸ†• å¦‚æœå¯ç”¨å‘é‡æ•°æ®åº“ï¼Œæ·»åŠ æ ‡ç­¾ä¿¡æ¯
            if self.use_vector_db:
                final_stocks = await self._add_vector_tags(final_stocks)
            
            logger.info(f"è‚¡ç¥¨å…³è”å®Œæˆï¼Œå…±è·å– {len(final_stocks)} åªè‚¡ç¥¨")
            
            return {
                "related_stocks": final_stocks,
                "action": "generate_advice"
            }
        
        except Exception as e:
            logger.error(f"è‚¡ç¥¨å…³è”å¤±è´¥: {e}")
            return {
                "error": str(e),
                "action": "error"
            }
    
    def post(self, shared_store: Dict[str, Any], prep_data: Dict[str, Any], exec_result: Dict[str, Any]) -> str:
        """åå¤„ç† - ä¿å­˜ç»“æœåˆ°å…±äº«å­˜å‚¨å¹¶è¿”å›ä¸‹ä¸€æ­¥åŠ¨ä½œ"""
        if "related_stocks" in exec_result:
            shared_store["related_stocks"] = exec_result["related_stocks"]
        
        if "error" in exec_result:
            shared_store["error"] = exec_result["error"]
        
        return exec_result.get("action", "generate_advice")
    
    async def _get_industry_stocks_akshare(self, industry: str, impact_type: str, impact_degree: int) -> List[Dict]:
        """ğŸ†• ä½¿ç”¨AKShareè·å–è¡Œä¸šè‚¡ç¥¨"""
        try:
            logger.info(f"ä½¿ç”¨AKShareè·å–è¡Œä¸šè‚¡ç¥¨: {industry}")
            stocks = await get_industry_stocks_from_akshare(industry, impact_type, impact_degree)
            
            if stocks:
                logger.info(f"AKShareè·å–åˆ° {len(stocks)} åª {industry} è¡Œä¸šè‚¡ç¥¨")
                return stocks
            else:
                logger.warning(f"AKShareæœªè·å–åˆ° {industry} è¡Œä¸šè‚¡ç¥¨ï¼Œåˆ‡æ¢åˆ°LLMæ–¹å¼")
                # å¦‚æœAKShareå¤±è´¥ï¼Œè‡ªåŠ¨é™çº§åˆ°LLMæ–¹å¼
                return await self._get_industry_stocks_llm(industry, impact_type, impact_degree)
                
        except Exception as e:
            logger.error(f"AKShareè·å– {industry} è¡Œä¸šè‚¡ç¥¨å¤±è´¥: {e}")
            return []
    
    async def _add_vector_tags(self, stocks: List[Dict]) -> List[Dict]:
        """ğŸ†• ä½¿ç”¨å‘é‡æ•°æ®åº“ä¸ºè‚¡ç¥¨æ·»åŠ æ ‡ç­¾ä¿¡æ¯"""
        try:
            # TODO: å®ç°å‘é‡æ•°æ®åº“æ ‡ç­¾åŠŸèƒ½
            # 1. æ ¹æ®è‚¡ç¥¨ä»£ç æŸ¥è¯¢å‘é‡æ•°æ®åº“
            # 2. è·å–ç›¸å…³æ ‡ç­¾å’Œç›¸ä¼¼è‚¡ç¥¨
            # 3. æ·»åŠ åˆ°è‚¡ç¥¨ä¿¡æ¯ä¸­
            
            logger.info("å‘é‡æ•°æ®åº“æ ‡ç­¾åŠŸèƒ½å°šæœªå®ç°ï¼Œè·³è¿‡")
            
            # ç°åœ¨å…ˆæ·»åŠ å ä½ç¬¦æ ‡ç­¾
            for stock in stocks:
                stock["vector_tags"] = []
                stock["similar_stocks"] = []
                stock["vector_similarity"] = 0.0
            
            return stocks
            
        except Exception as e:
            logger.error(f"æ·»åŠ å‘é‡æ ‡ç­¾å¤±è´¥: {e}")
            return stocks
    
    def _parse_stocks_response(self, response_text: str) -> Dict[str, Any]:
        """è§£æè‚¡ç¥¨æ¨èå“åº”"""
        try:
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            
            if start_idx >= 0 and end_idx > start_idx:
                json_str = response_text[start_idx:end_idx]
                return json.loads(json_str)
            else:
                raise ValueError("æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„JSONå†…å®¹")
        
        except Exception as e:
            logger.error(f"è§£æè‚¡ç¥¨æ¨èå¤±è´¥: {e}")
            return {"stocks": []}
    
    def _deduplicate_and_rank_stocks(self, stocks: List[Dict]) -> List[Dict]:
        """å»é‡å¹¶æŒ‰å½±å“ç¨‹åº¦æ’åºè‚¡ç¥¨"""
        # æŒ‰è‚¡ç¥¨ä»£ç å»é‡
        unique_stocks = {}
        for stock in stocks:
            code = stock.get("code", "")
            if code and (code not in unique_stocks or 
                        stock.get("impact_degree", 0) > unique_stocks[code].get("impact_degree", 0)):
                unique_stocks[code] = stock
        
        # æŒ‰å½±å“ç¨‹åº¦å’Œå…³è”åº¦æ’åº
        sorted_stocks = sorted(
            unique_stocks.values(),
            key=lambda x: (x.get("impact_degree", 0) * x.get("relevance_score", 0)),
            reverse=True
        )
        
        # é™åˆ¶è¿”å›æ•°é‡
        return sorted_stocks[:10]

class InvestmentAdvisorAgent(Node):
    """æŠ•èµ„å»ºè®®Agent - ç»¼åˆåˆ†æå¹¶æä¾›æœ€ç»ˆæŠ•èµ„å»ºè®®"""
    
    def __init__(self, llm_client: QwenLLMClient):
        super().__init__()
        self.llm_client = llm_client
    
    def prep(self, shared_store: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡æŠ•èµ„å»ºè®®ç”Ÿæˆæ‰€éœ€çš„æ•°æ®"""
        return {
            "classification": shared_store.get("classification", {}),
            "industry_analysis": shared_store.get("industry_analysis", {}),
            "related_stocks": shared_store.get("related_stocks", []),
            "shared_store": shared_store
        }
    
    def exec(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”ŸæˆæŠ•èµ„å»ºè®® - åŒæ­¥æ–¹æ³•"""
        return asyncio.run(self._exec_async(prep_data))
    
    async def _exec_async(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¼‚æ­¥ç”ŸæˆæŠ•èµ„å»ºè®®"""
        classification = prep_data.get("classification", {})
        industry_analysis = prep_data.get("industry_analysis", {})
        related_stocks = prep_data.get("related_stocks", [])
        
        prompt = self._build_investment_advice_prompt(
            classification, industry_analysis, related_stocks
        )
        
        try:
            async with self.llm_client as client:
                response = await client.chat_completion(
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.4,
                    max_tokens=1000
                )
            
            # è§£ææŠ•èµ„å»ºè®®
            investment_advice = self._parse_advice_response(response.content)
            
            logger.info("æŠ•èµ„å»ºè®®ç”Ÿæˆå®Œæˆ")
            
            return {
                "investment_advice": investment_advice,
                "action": "done"
            }
        
        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ•èµ„å»ºè®®å¤±è´¥: {e}")
            return {
                "error": str(e),
                "action": "error"
            }
    
    def post(self, shared_store: Dict[str, Any], prep_data: Dict[str, Any], exec_result: Dict[str, Any]) -> str:
        """åå¤„ç† - ä¿å­˜ç»“æœåˆ°å…±äº«å­˜å‚¨å¹¶è¿”å›ä¸‹ä¸€æ­¥åŠ¨ä½œ"""
        if "investment_advice" in exec_result:
            shared_store["investment_advice"] = exec_result["investment_advice"]
        
        if "error" in exec_result:
            shared_store["error"] = exec_result["error"]
        
        return exec_result.get("action", "done")
    
    def _build_investment_advice_prompt(self, classification: Dict, 
                                      industry_analysis: Dict, 
                                      related_stocks: List[Dict]) -> str:
        """æ„å»ºæŠ•èµ„å»ºè®®Prompt"""
        stocks_info = "\n".join([
            f"- {stock.get('code', '')} {stock.get('name', '')}: {stock.get('reason', '')}"
            for stock in related_stocks[:5]
        ])
        
        return f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ•èµ„é¡¾é—®ã€‚è¯·åŸºäºä»¥ä¸‹åˆ†æç»“æœæä¾›ä¸“ä¸šçš„æŠ•èµ„å»ºè®®ï¼š

æ–°é—»åˆ†ç±»ï¼š
- ç±»å‹ï¼š{classification.get('news_type', 'æœªçŸ¥')}
- é‡è¦æ€§ï¼š{classification.get('importance_score', 0)}åˆ†
- æƒ…æ„Ÿå€¾å‘ï¼š{classification.get('sentiment', 'ä¸­æ€§')}

è¡Œä¸šå½±å“åˆ†æï¼š
{json.dumps(industry_analysis, ensure_ascii=False, indent=2)}

ç›¸å…³è‚¡ç¥¨ï¼š
{stocks_info}

è¯·æä¾›ï¼š
1. æŠ•èµ„å»ºè®®ï¼š[ä¹°å…¥/æŒæœ‰/å–å‡º/è§‚æœ›]
2. æŠ•èµ„é€»è¾‘ï¼šè¯¦ç»†è¯´æ˜æŠ•èµ„ç†ç”±
3. é£é™©è¯„ä¼°ï¼šä¸»è¦é£é™©ç‚¹å’Œæ³¨æ„äº‹é¡¹
4. æ—¶é—´å»ºè®®ï¼š[çŸ­æœŸ/ä¸­æœŸ/é•¿æœŸ]æŒæœ‰å»ºè®®
5. ä»“ä½å»ºè®®ï¼šå»ºè®®çš„ä»“ä½æ¯”ä¾‹
6. æ­¢æŸå»ºè®®ï¼šé£é™©æ§åˆ¶æªæ–½
7. ä¿¡å¿ƒæŒ‡æ•°ï¼š1-10åˆ†ï¼ˆå¯¹è¿™ä¸ªå»ºè®®çš„ä¿¡å¿ƒç¨‹åº¦ï¼‰

è¿”å›JSONæ ¼å¼ï¼š
{{
  "recommendation": "ä¹°å…¥/æŒæœ‰/å–å‡º/è§‚æœ›",
  "rationale": "æŠ•èµ„é€»è¾‘è¯¦ç»†è¯´æ˜",
  "risk_assessment": "é£é™©è¯„ä¼°å†…å®¹",
  "time_horizon": "çŸ­æœŸ/ä¸­æœŸ/é•¿æœŸ",
  "position_size": "ä»“ä½å»ºè®®",
  "stop_loss": "æ­¢æŸå»ºè®®",
  "confidence_level": åˆ†æ•°,
  "key_factors": ["å…³é”®å› ç´ 1", "å…³é”®å› ç´ 2"],
  "alternative_scenarios": "å…¶ä»–å¯èƒ½æƒ…å†µåˆ†æ"
}}

æ³¨æ„ï¼š
- å»ºè®®è¦å…·ä½“å¯æ“ä½œ
- å¿…é¡»åŒ…å«é£é™©æç¤º
- è€ƒè™‘å½“å‰å¸‚åœºç¯å¢ƒ
- æä¾›å®¢è§‚ç†æ€§çš„åˆ†æ"""
    
    def _parse_advice_response(self, response_text: str) -> Dict[str, Any]:
        """è§£ææŠ•èµ„å»ºè®®å“åº”"""
        try:
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            
            if start_idx >= 0 and end_idx > start_idx:
                json_str = response_text[start_idx:end_idx]
                return json.loads(json_str)
            else:
                raise ValueError("æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„JSONå†…å®¹")
        
        except Exception as e:
            logger.error(f"è§£ææŠ•èµ„å»ºè®®å¤±è´¥: {e}")
            return {
                "recommendation": "è§‚æœ›",
                "rationale": "åˆ†æç»“æœè§£æå¤±è´¥",
                "risk_assessment": "å­˜åœ¨ä¸ç¡®å®šæ€§",
                "time_horizon": "çŸ­æœŸ",
                "position_size": "è°¨æ…å‚ä¸",
                "stop_loss": "åŠæ—¶æ­¢æŸ",
                "confidence_level": 3,
                "key_factors": [],
                "alternative_scenarios": "éœ€è¦è¿›ä¸€æ­¥åˆ†æ"
            }

class NewsAnalysisFlow:
    """æ–°é—»åˆ†ææµæ°´çº¿ä¸»ç±»"""
    
    def __init__(self, llm_client: QwenLLMClient):
        """
        åˆå§‹åŒ–æ–°é—»åˆ†ææµæ°´çº¿
        
        Args:
            llm_client: åƒé—®LLMå®¢æˆ·ç«¯
        """
        self.llm_client = llm_client
        
        # åˆå§‹åŒ–å„ä¸ªAgent
        self.classifier_agent = NewsClassifierAgent(self.llm_client)
        self.industry_agent = IndustryAnalyzerAgent(self.llm_client)
        self.stock_agent = StockRelatorAgent(self.llm_client)
        self.advisor_agent = InvestmentAdvisorAgent(self.llm_client)
        
        # æ„å»ºPocketFlowæµç¨‹
        self.flow = self._build_flow()
    
    def _build_flow(self) -> Flow:
        """æ„å»ºPocketFlowå·¥ä½œæµç¨‹"""
        # åˆ›å»ºAgentå®ä¾‹
        self.classifier_agent = NewsClassifierAgent(self.llm_client)
        self.industry_agent = IndustryAnalyzerAgent(self.llm_client)
        self.stock_agent = StockRelatorAgent(self.llm_client)
        self.advisor_agent = InvestmentAdvisorAgent(self.llm_client)
        
        # è®¾ç½®èŠ‚ç‚¹è¿æ¥å…³ç³» - æ ¹æ®actionå†³å®šä¸‹ä¸€æ­¥
        # PocketFlowä½¿ç”¨å­—å…¸æ–¹å¼å®šä¹‰è·¯å¾„è§„åˆ™
        self.classifier_agent.successors = {
            "analyze_industry": self.industry_agent,
            "skip": None,  # è·³è¿‡åˆ†æ
            "error": None  # é”™è¯¯ç»ˆæ­¢
        }
        
        self.industry_agent.successors = {
            "relate_stocks": self.stock_agent,
            "error": None
        }
        
        self.stock_agent.successors = {
            "generate_advice": self.advisor_agent,
            "error": None
        }
        
        self.advisor_agent.successors = {
            "done": None,  # æµç¨‹å®Œæˆ
            "error": None
        }
        
        # åˆ›å»ºFlowï¼Œä»åˆ†ç±»å™¨å¼€å§‹
        flow = Flow(start=self.classifier_agent)
        
        return flow
    
    def analyze_news(self, news_content: str, news_id: str = None) -> NewsAnalysisResult:
        """
        åˆ†æå•æ¡æ–°é—»
        
        Args:
            news_content: æ–°é—»å†…å®¹
            news_id: æ–°é—»IDï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ–°é—»åˆ†æç»“æœ
        """
        start_time = datetime.now()
        news_id = news_id or f"news_{int(start_time.timestamp())}"
        
        # åˆå§‹åŒ–å…±äº«å­˜å‚¨
        shared_store = {
            "news_content": news_content,
            "news_id": news_id,
            "start_time": start_time
        }
        
        try:
            # æ‰§è¡Œæµæ°´çº¿
            self.flow.run(shared_store)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # è®¡ç®—ä¿¡å¿ƒè¯„åˆ†
            confidence_score = self._calculate_confidence_score(shared_store)
            
            # æ„å»ºç»“æœå¯¹è±¡
            result = NewsAnalysisResult(
                news_id=news_id,
                news_content=news_content,
                classification=shared_store.get("classification", {}),
                industry_analysis=shared_store.get("industry_analysis", {}),
                related_stocks=shared_store.get("related_stocks", []),
                investment_advice=shared_store.get("investment_advice", {}),
                analysis_time=start_time,
                confidence_score=confidence_score,
                processing_time=processing_time
            )
            
            logger.info(f"æ–°é—»åˆ†æå®Œæˆ: {news_id}, è€—æ—¶: {processing_time:.2f}ç§’")
            return result
        
        except Exception as e:
            logger.error(f"æ–°é—»åˆ†ææµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
            # è¿”å›é”™è¯¯ç»“æœ
            return NewsAnalysisResult(
                news_id=news_id,
                news_content=news_content,
                classification={},
                industry_analysis={},
                related_stocks=[],
                investment_advice={"recommendation": "è§‚æœ›", "rationale": f"åˆ†æå¤±è´¥: {str(e)}"},
                analysis_time=start_time,
                confidence_score=0.0,
                processing_time=(datetime.now() - start_time).total_seconds()
            )
    
    def _calculate_confidence_score(self, shared_store: Dict[str, Any]) -> float:
        """è®¡ç®—åˆ†æç»“æœçš„ä¿¡å¿ƒè¯„åˆ†"""
        try:
            # åŸºç¡€åˆ†æ•°
            base_score = 0.5
            
            # åˆ†ç±»è´¨é‡è¯„åˆ†
            classification = shared_store.get("classification", {})
            if classification.get("importance_score", 0) >= 7:
                base_score += 0.2
            
            # è¡Œä¸šåˆ†æè´¨é‡è¯„åˆ†
            industry_analysis = shared_store.get("industry_analysis", {})
            affected_industries = industry_analysis.get("affected_industries", [])
            if len(affected_industries) > 0:
                avg_impact = sum(ind.get("impact_degree", 0) for ind in affected_industries) / len(affected_industries)
                if avg_impact >= 7:
                    base_score += 0.2
            
            # è‚¡ç¥¨å…³è”è´¨é‡è¯„åˆ†
            related_stocks = shared_store.get("related_stocks", [])
            if len(related_stocks) >= 3:
                base_score += 0.1
            
            # æŠ•èµ„å»ºè®®è´¨é‡è¯„åˆ†
            investment_advice = shared_store.get("investment_advice", {})
            advice_confidence = investment_advice.get("confidence_level", 0)
            if advice_confidence >= 7:
                base_score += 0.2
            
            return min(1.0, base_score)
        
        except Exception:
            return 0.5

# ä¾¿æ·å‡½æ•°
def analyze_single_news(news_content: str, news_id: str = None) -> NewsAnalysisResult:
    """
    å¿«é€Ÿåˆ†æå•æ¡æ–°é—»çš„ä¾¿æ·å‡½æ•°
    
    Args:
        news_content: æ–°é—»å†…å®¹
        news_id: æ–°é—»IDï¼ˆå¯é€‰ï¼‰
        
    Returns:
        æ–°é—»åˆ†æç»“æœ
    """
    flow = NewsAnalysisFlow()
    return flow.analyze_news(news_content, news_id) 
#!/usr/bin/env python3

"""
æ–°é—»åˆ†ææµæ°´çº¿ (é‡æ„ç‰ˆ)

åŸºäºPocketFlowæ¡†æ¶çš„å¤šAgentåä½œæ–°é—»åˆ†æç³»ç»Ÿã€‚
é‡æ„åçš„ç‰ˆæœ¬ä½¿ç”¨ç‹¬ç«‹çš„èŠ‚ç‚¹æ–‡ä»¶ï¼Œæé«˜ä»£ç ç»„ç»‡æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚
"""

import asyncio
import logging
from dataclasses import dataclass
from datetime import datetime
from typing import Any

from ...models.news_article import NewsArticle

# é¡¹ç›®å†…éƒ¨æ¨¡å—å¯¼å…¥
from ..llm_clients.qwen_client import QwenLLMClient

# é‡æ„åçš„èŠ‚ç‚¹å¯¼å…¥
from ..nodes.analysis.news_classifier_node import NewsClassifierNode
from ..nodes.analysis.stock_analyzer_node import StockAnalyzerNode
from ..nodes.decision.investment_advisor_node import InvestmentAdvisorNode

logger = logging.getLogger(__name__)


@dataclass
class EnhancedNewsAnalysisResult:
    """æ–°é—»åˆ†æç»“æœ - ä¿æŒä¸åŸç‰ˆä¸€è‡´"""

    news_id: str
    article: NewsArticle  # ä½¿ç”¨çœŸå®çš„NewsArticleå¯¹è±¡
    analysis_type: str  # "stock_specific" æˆ– "industry_focused"
    mentioned_stocks: list[dict[str, Any]]  # æ–°é—»ä¸­æåˆ°çš„å…·ä½“è‚¡ç¥¨
    classification: dict[str, Any]
    industry_analysis: dict[str, Any]
    related_stocks: list[dict[str, Any]]  # é«˜è¯„åˆ†ç›¸å…³è‚¡ç¥¨
    investment_advice: dict[str, Any]
    analysis_time: datetime
    confidence_score: float
    processing_time: float


class NewsAnalysisFlow:
    """æ–°é—»åˆ†ææµæ°´çº¿ä¸»ç±» - é‡æ„ç‰ˆï¼Œä¸“æ³¨æµç¨‹ç¼–æ’"""

    def __init__(self, llm_client: QwenLLMClient, test_mode: bool = False):
        """
        åˆå§‹åŒ–æ–°é—»åˆ†ææµæ°´çº¿

        Args:
            llm_client: åƒé—®LLMå®¢æˆ·ç«¯
            test_mode: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼ï¼Œé¿å…æ•°æ®åº“è¿æ¥
        """
        self.llm_client = llm_client
        self.test_mode = test_mode

        # ğŸ”„ ä½¿ç”¨é‡æ„åçš„ç‹¬ç«‹èŠ‚ç‚¹ï¼Œä¼ é€’æµ‹è¯•æ¨¡å¼æ ‡å¿—
        self.classifier_node = NewsClassifierNode(self.llm_client, test_mode=test_mode)
        self.stock_analyzer_node = StockAnalyzerNode(self.llm_client)
        self.advisor_node = InvestmentAdvisorNode(self.llm_client)

        if test_mode:
            logger.info("ğŸ§ª æ–°é—»åˆ†ææµæ°´çº¿å·²åˆå§‹åŒ– (æµ‹è¯•æ¨¡å¼ï¼Œæ— æ•°æ®åº“è¿æ¥)")
        else:
            logger.info("ğŸ—ï¸ æ–°é—»åˆ†ææµæ°´çº¿å·²åˆå§‹åŒ– (ç”Ÿäº§æ¨¡å¼)")

    def analyze_news_with_article(
        self, article: NewsArticle
    ) -> EnhancedNewsAnalysisResult:
        """
        åˆ†æNewsArticleå¯¹è±¡ - ä¿æŒä¸åŸç‰ˆæ¥å£ä¸€è‡´

        Args:
            article: NewsArticleæ¨¡å‹å¯¹è±¡

        Returns:
            æ–°é—»åˆ†æç»“æœ
        """
        # æ£€æŸ¥æ˜¯å¦åœ¨è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ä¸­
        try:
            loop = asyncio.get_running_loop()
            if loop.is_running():
                # åœ¨è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ä¸­ï¼Œä½¿ç”¨åŒæ­¥è°ƒç”¨å¼‚æ­¥æ–¹æ³•çš„æ–¹å¼
                import concurrent.futures

                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(
                        asyncio.run, self.analyze_news_with_article_async(article)
                    )
                    return future.result()
        except RuntimeError:
            # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨asyncio.run
            pass

        return asyncio.run(self.analyze_news_with_article_async(article))

    async def analyze_news_with_article_async(
        self, article: NewsArticle
    ) -> EnhancedNewsAnalysisResult:
        """
        åˆ†æNewsArticleå¯¹è±¡ - å¼‚æ­¥ç‰ˆæœ¬ï¼Œä¿æŒåŸæœ‰é€»è¾‘

        Args:
            article: NewsArticleæ¨¡å‹å¯¹è±¡

        Returns:
            æ–°é—»åˆ†æç»“æœ
        """
        start_time = datetime.now()

        # åˆå§‹åŒ–å…±äº«å­˜å‚¨ï¼Œä¼ å…¥çœŸå®çš„NewsArticleå¯¹è±¡
        shared_store = {"article": article, "start_time": start_time}

        try:
            # ğŸ”„ ç¬¬ä¸€æ­¥ï¼šæ–°é—»åˆ†ç±» (ä½¿ç”¨é‡æ„åçš„èŠ‚ç‚¹)
            classifier_prep = self.classifier_node.prep(shared_store)
            classifier_result = self.classifier_node.work(classifier_prep)
            action = self.classifier_node.post(
                shared_store, classifier_prep, classifier_result
            )

            if action == "error":
                raise Exception(f"åˆ†ç±»å¤±è´¥: {shared_store.get('error', 'æœªçŸ¥é”™è¯¯')}")

            # ğŸ”„ ç¬¬äºŒæ­¥ï¼šæ ¹æ®åˆ†æç±»å‹æ‰§è¡Œè‚¡ç¥¨åˆ†æ (ä½¿ç”¨é‡æ„åçš„èŠ‚ç‚¹)
            if action in ["analyze_stocks", "analyze_industry"]:
                stock_prep = self.stock_analyzer_node.prep(shared_store)
                stock_result = await self.stock_analyzer_node._exec_async(stock_prep)
                action = self.stock_analyzer_node.post(
                    shared_store, stock_prep, stock_result
                )

                if action == "error":
                    raise Exception(f"è‚¡ç¥¨åˆ†æå¤±è´¥: {shared_store.get('error', 'æœªçŸ¥é”™è¯¯')}")

            # ğŸ”„ ç¬¬ä¸‰æ­¥ï¼šç”ŸæˆæŠ•èµ„å»ºè®® (ä½¿ç”¨é‡æ„åçš„èŠ‚ç‚¹)
            if action == "generate_advice":
                advisor_prep = self.advisor_node.prep(shared_store)
                advisor_result = await self.advisor_node._exec_async(advisor_prep)
                self.advisor_node.post(shared_store, advisor_prep, advisor_result)

            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = (datetime.now() - start_time).total_seconds()

            # è®¡ç®—ä¿¡å¿ƒè¯„åˆ†
            confidence_score = self._calculate_confidence_score(shared_store)

            # ğŸ”„ æ„å»ºç»“æœå¯¹è±¡ (ä¿æŒä¸åŸç‰ˆä¸€è‡´çš„ç»“æ„)
            result = EnhancedNewsAnalysisResult(
                news_id=str(article.id),
                article=article,
                analysis_type=shared_store.get("analysis_type", "industry_focused"),
                mentioned_stocks=shared_store.get("mentioned_stocks", []),
                classification=shared_store.get("classification", {}),
                industry_analysis=shared_store.get("industry_analysis", {}),
                related_stocks=shared_store.get("related_stocks", []),
                investment_advice=shared_store.get("investment_advice", {}),
                analysis_time=start_time,
                confidence_score=confidence_score,
                processing_time=processing_time,
            )

            logger.info(f"âœ… æ–°é—»åˆ†æå®Œæˆ (é‡æ„ç‰ˆ): {article.id}, è€—æ—¶: {processing_time:.2f}ç§’")
            return result

        except Exception as e:
            logger.error(f"âŒ æ–°é—»åˆ†ææµæ°´çº¿æ‰§è¡Œå¤±è´¥ (é‡æ„ç‰ˆ): {e}")
            # è¿”å›é”™è¯¯ç»“æœ
            return EnhancedNewsAnalysisResult(
                news_id=str(article.id),
                article=article,
                analysis_type="industry_focused",
                mentioned_stocks=[],
                classification={},
                industry_analysis={},
                related_stocks=[],
                investment_advice={
                    "recommendation": "è§‚æœ›",
                    "rationale": f"åˆ†æå¤±è´¥: {str(e)}",
                },
                analysis_time=start_time,
                confidence_score=0.0,
                processing_time=(datetime.now() - start_time).total_seconds(),
            )

    def analyze_news(
        self, news_content: str, news_id: str = None
    ) -> EnhancedNewsAnalysisResult:
        """
        åˆ†æå•æ¡æ–°é—»å†…å®¹ï¼ˆå‘åå…¼å®¹ï¼‰- ä¿æŒä¸åŸç‰ˆæ¥å£ä¸€è‡´

        Args:
            news_content: æ–°é—»å†…å®¹
            news_id: æ–°é—»IDï¼ˆå¯é€‰ï¼‰

        Returns:
            æ–°é—»åˆ†æç»“æœ
        """
        # åˆ›å»ºä¸´æ—¶NewsArticleå¯¹è±¡
        temp_article = NewsArticle(
            id=int(news_id) if news_id and news_id.isdigit() else 0,
            title=news_content[:100] + "..."
            if len(news_content) > 100
            else news_content,
            url="",
            url_hash="",
            content=news_content,
            source_id=0,
            created_at=datetime.now(),
            updated_at=datetime.now(),
        )

        return self.analyze_news_with_article(temp_article)

    def _calculate_confidence_score(self, shared_store: dict[str, Any]) -> float:
        """è®¡ç®—åˆ†æç»“æœçš„ä¿¡å¿ƒè¯„åˆ† - ä¿æŒä¸åŸç‰ˆä¸€è‡´çš„é€»è¾‘"""
        try:
            # åŸºç¡€åˆ†æ•°
            base_score = 0.5

            # åˆ†ç±»è´¨é‡è¯„åˆ†
            classification = shared_store.get("classification", {})
            if classification.get("importance_score", 0) >= 7:
                base_score += 0.2

            # è¡Œä¸šåˆ†æè´¨é‡è¯„åˆ†
            industry_analysis = shared_store.get("industry_analysis", {})
            affected_industries = industry_analysis.get("affected_industries", [])
            if len(affected_industries) > 0:
                avg_impact = sum(
                    ind.get("impact_degree", 0) for ind in affected_industries
                ) / len(affected_industries)
                if avg_impact >= 7:
                    base_score += 0.2

            # è‚¡ç¥¨å…³è”è´¨é‡è¯„åˆ†
            related_stocks = shared_store.get("related_stocks", [])
            if len(related_stocks) >= 3:
                base_score += 0.1

            # æŠ•èµ„å»ºè®®è´¨é‡è¯„åˆ†
            investment_advice = shared_store.get("investment_advice", {})
            advice_confidence = investment_advice.get("confidence_level", 0)
            if advice_confidence >= 7:
                base_score += 0.2

            return min(1.0, base_score)

        except Exception as e:
            logger.error(f"è®¡ç®—ä¿¡å¿ƒè¯„åˆ†å¤±è´¥: {e}")
            return 0.5


# ğŸ”„ ä¾¿æ·å‡½æ•° - ä¿æŒä¸åŸç‰ˆæ¥å£ä¸€è‡´
def analyze_single_news(
    news_content: str, news_id: str = None, test_mode: bool = False
) -> EnhancedNewsAnalysisResult:
    """
    å¿«é€Ÿåˆ†æå•æ¡æ–°é—»çš„ä¾¿æ·å‡½æ•° - ä½¿ç”¨é‡æ„åçš„æµç¨‹

    Args:
        news_content: æ–°é—»å†…å®¹
        news_id: æ–°é—»IDï¼ˆå¯é€‰ï¼‰
        test_mode: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼ï¼Œé¿å…æ•°æ®åº“è¿æ¥

    Returns:
        æ–°é—»åˆ†æç»“æœ
    """
    # ä¸´æ—¶åˆ›å»ºå®¢æˆ·ç«¯
    qwen_client = QwenLLMClient()
    analysis_flow = NewsAnalysisFlow(qwen_client, test_mode)

    return analysis_flow.analyze_news(news_content, news_id)

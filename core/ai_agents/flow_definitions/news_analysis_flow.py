#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ–°é—»åˆ†ææµæ°´çº¿ (å¢å¼ºç‰ˆ)

åŸºäºPocketFlowæ¡†æ¶çš„å¤šAgentåä½œæ–°é—»åˆ†æç³»ç»Ÿã€‚
é€‚é…çœŸå®æ•°æ®åº“ç»“æ„ï¼Œæ”¯æŒæ™ºèƒ½åˆ†æè·¯å¾„é€‰æ‹©å’Œé«˜è¯„åˆ†è‚¡ç¥¨ç­›é€‰ã€‚
"""

import json
import logging
import asyncio
import re
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from datetime import datetime

# PocketFlowæ¡†æ¶å¯¼å…¥
from pocketflow import Flow, Node

# é¡¹ç›®å†…éƒ¨æ¨¡å—å¯¼å…¥
from ..llm_clients.qwen_client import QwenLLMClient
from ..llm_clients.silicon_flow_client import SiliconFlowClient
from ...data_providers.stock_data_factory import StockDataFactory
from ...models.news_article import NewsArticle
from ...models.news_source import NewsSource
from ..utils.akshare_industry_provider import get_industry_stocks_from_akshare
from ...handler.ticker_handler import TickerHandler

logger = logging.getLogger(__name__)

@dataclass
class EnhancedNewsAnalysisResult:
    """å¢å¼ºç‰ˆæ–°é—»åˆ†æç»“æœ"""
    news_id: str
    article: NewsArticle  # ä½¿ç”¨çœŸå®çš„NewsArticleå¯¹è±¡
    analysis_type: str  # "stock_specific" æˆ– "industry_focused" 
    mentioned_stocks: List[Dict[str, Any]]  # æ–°é—»ä¸­æåˆ°çš„å…·ä½“è‚¡ç¥¨
    classification: Dict[str, Any]
    industry_analysis: Dict[str, Any]
    related_stocks: List[Dict[str, Any]]  # é«˜è¯„åˆ†ç›¸å…³è‚¡ç¥¨
    investment_advice: Dict[str, Any]
    analysis_time: datetime
    confidence_score: float
    processing_time: float

class EnhancedNewsClassifierAgent(Node):
    """å¢å¼ºç‰ˆæ–°é—»åˆ†ç±»å™¨Agent - è¯†åˆ«å…·ä½“è‚¡ç¥¨æåŠå¹¶å†³å®šåˆ†æè·¯å¾„"""
    
    def __init__(self, llm_client: QwenLLMClient):
        super().__init__()
        self.llm_client = llm_client
        self.ticker_handler = TickerHandler()
        
        # ğŸ”¥ å¢å¼ºçš„è‚¡ç¥¨åŒ¹é…æ¨¡å¼ - ä¼˜åŒ–åŒ¹é…ç²¾åº¦
        self.stock_patterns = [
            # ğŸ”¥ ä¿®å¤ï¼šæ ‡å‡†æ ¼å¼ï¼šè‚¡ç¥¨å(ä»£ç ) - æé«˜ä¼˜å…ˆçº§å’Œå‡†ç¡®æ€§
            r'([\u4e00-\u9fa5A-Za-z&]{2,15})[ï¼ˆ\(](\d{6})[ï¼‰\)]',  # ä¸­æ–‡åç§°(6ä½ä»£ç )
            # ğŸ”¥ ä¿®å¤ï¼šæ¸¯è‚¡æ ¼å¼ï¼šè‚¡ç¥¨å(05ä½ä»£ç ) - æ”¯æŒ0å¼€å¤´çš„5ä½ä»£ç 
            r'([\u4e00-\u9fa5A-Za-z&]{2,15})[ï¼ˆ\(](0\d{4})[ï¼‰\)]',  # æ¸¯è‚¡ä»£ç 
            # è‚¡ç¥¨å+ç©ºæ ¼+ä»£ç æ ¼å¼
            r'([\u4e00-\u9fa5A-Za-z&]{2,15})\s+(\d{6})',
            # ç›´æ¥ä»£ç æ ¼å¼ï¼šSH600000, SZ000001  
            r'([SZ|SH])(\d{6})',
            # 6ä½æ•°å­—ä»£ç ï¼ˆéœ€è¦ä¸Šä¸‹æ–‡åˆ¤æ–­ï¼‰
            r'(?<![0-9])(\d{6})(?![0-9])',
            # æ¸¯è‚¡5ä½ä»£ç ï¼ˆ0å¼€å¤´ï¼‰
            r'(?<![0-9])(0\d{4})(?![0-9])',
            # ç¾è‚¡ä»£ç æ ¼å¼ï¼šå¤§å†™å­—æ¯ç»„åˆ
            r'\b([A-Z]{1,5})\b(?=.*(?:è‚¡ç¥¨|å…¬å¸|è‚¡ä»·|æ¶¨|è·Œ))',
        ]
        
        # ğŸ”¥ å¢å¼ºæŠ•èµ„ç›¸å…³å…³é”®è¯
        self.investment_keywords = [
            'è‚¡ç¥¨', 'è‚¡ä»·', 'æ¶¨', 'è·Œ', 'æ¶¨å¹…', 'è·Œå¹…', 'æ¶¨åœ', 'è·Œåœ',
            'ä¹°å…¥', 'å–å‡º', 'æŒæœ‰', 'å»ºä»“', 'å‡ä»“', 'æ­¢æŸ', 'ç›ˆåˆ©', 'äºæŸ', 
            'æŠ•èµ„', 'åˆ†æå¸ˆ', 'è¯„çº§', 'ç›®æ ‡ä»·', 'ä¸šç»©', 'è´¢æŠ¥', 'åˆ©æ¶¦',
            'è¥æ”¶', 'å¸‚å€¼', 'å¸‚ç›ˆç‡', 'å¸‚å‡€ç‡', 'è‚¡æ¯', 'åˆ†çº¢', 'ä¸Šæ¶¨',
            'ä¸‹è·Œ', 'äº¤æ˜“', 'æˆäº¤é‡', 'æ¢æ‰‹ç‡', 'ä¸»åŠ›', 'æœºæ„', 'æ•£æˆ·',
            'ç‰›å¸‚', 'ç†Šå¸‚', 'è¡Œæƒ…', 'é¢˜æ', 'æ¦‚å¿µ', 'æ¿å—', 'é¾™å¤´'
        ]
    
    def prep(self, shared_store: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡åˆ†ç±»æ‰€éœ€çš„æ•°æ®"""
        article = shared_store.get("article")
        if not article:
            return {"error": "ç¼ºå°‘NewsArticleå¯¹è±¡"}
        
        # ğŸ”¥ ä½¿ç”¨æ–°çš„get_analysis_contentæ–¹æ³•
        news_content = article.get_analysis_content()
        
        # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
        context_info = {
            "source_name": article.source_name or "æœªçŸ¥æ¥æº",
            "published_at": article.published_at.isoformat() if article.published_at else "æœªçŸ¥æ—¶é—´",
            "category": article.category or "æœªåˆ†ç±»",
            "importance_score": article.importance_score,
            "market_relevance_score": article.market_relevance_score,
            "sentiment_score": article.sentiment_score,
            "has_content": bool(article.content and article.content.strip())
        }
        
        return {
            "article": article,
            "news_content": news_content,
            "context_info": context_info,
            "shared_store": shared_store
        }
    
    def exec(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå¢å¼ºæ–°é—»åˆ†ç±» - åŒæ­¥æ–¹æ³•"""
        # ä¿®å¤: å¦‚æœå·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œç›´æ¥è¿”å›åç¨‹è®©ä¸Šå±‚å¤„ç†
        try:
            loop = asyncio.get_running_loop()
            if loop.is_running():
                # åœ¨å·²è¿è¡Œçš„äº‹ä»¶å¾ªç¯ä¸­ï¼Œä¸èƒ½ä½¿ç”¨asyncio.run()
                import warnings
                warnings.warn("execæ–¹æ³•åœ¨è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ä¸­è¢«è°ƒç”¨ï¼Œå»ºè®®ä½¿ç”¨asyncç‰ˆæœ¬", RuntimeWarning)
                return {}
        except RuntimeError:
            # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œå¯ä»¥ä½¿ç”¨asyncio.run()
            pass
        
        return asyncio.run(self._exec_async(prep_data))
    
    async def _exec_async(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œå¢å¼ºæ–°é—»åˆ†ç±»"""
        if "error" in prep_data:
            return {"error": prep_data["error"], "action": "error"}
            
        article = prep_data.get("article")
        news_content = prep_data.get("news_content", "")
        context_info = prep_data.get("context_info", {})
        
        if not news_content:
            logger.error("æ–°é—»å†…å®¹ä¸ºç©º")
            return {"error": "æ–°é—»å†…å®¹ä¸ºç©º", "action": "error"}
        
        try:
            # 1. å¢å¼ºçš„è‚¡ç¥¨æå–é€»è¾‘
            mentioned_stocks = await self._extract_mentioned_stocks_enhanced(news_content, article)
            
            # 2. æŠ•èµ„ç›¸å…³æ€§æ£€æµ‹
            investment_relevance = self._check_investment_relevance(news_content)
            
            # 3. LLMæ·±åº¦åˆ†ç±»åˆ†æ
            classification = await self._classify_news_with_llm(news_content, mentioned_stocks, context_info)
            
            # 4. ğŸ”¥ æ™ºèƒ½è·¯å¾„å†³ç­–å¢å¼º
            analysis_decision = self._make_intelligent_path_decision(
                mentioned_stocks, investment_relevance, classification, context_info
            )
            
            analysis_type = analysis_decision["analysis_type"]
            action = analysis_decision["action"]
            reasoning = analysis_decision["reasoning"]
            
            logger.info(f"ğŸ“Š åˆ†æè·¯å¾„å†³ç­–: {analysis_type} | ç†ç”±: {reasoning}")
            logger.info(f"ğŸ“ˆ æ£€æµ‹åˆ° {len(mentioned_stocks)} åªè‚¡ç¥¨ï¼ŒæŠ•èµ„ç›¸å…³æ€§: {investment_relevance:.2f}")
            
            return {
                "classification": classification,
                "mentioned_stocks": mentioned_stocks,
                "analysis_type": analysis_type,
                "action": action,
                "reasoning": reasoning,
                "investment_relevance": investment_relevance,
                "context_info": context_info
            }
        
        except Exception as e:
            logger.error(f"å¢å¼ºæ–°é—»åˆ†ç±»å¤±è´¥: {e}")
            return {
                "error": str(e),
                "action": "error"
            }
    
    async def _extract_mentioned_stocks_enhanced(self, news_content: str, article: NewsArticle) -> List[Dict[str, Any]]:
        """ğŸ”¥ å¢å¼ºçš„è‚¡ç¥¨æå–é€»è¾‘ - ä¿®å¤æ¸¯è‚¡è¯†åˆ«é—®é¢˜"""
        mentioned_stocks = []
        confidence_scores = {}
        
        # ğŸ”¥ æ–¹æ³•1: æ”¹è¿›çš„æ­£åˆ™åŒ¹é…
        for i, pattern in enumerate(self.stock_patterns):
            matches = re.finditer(pattern, news_content, re.IGNORECASE)
            for match in matches:
                stock_code, stock_name = None, None
                confidence = 0.6  # åŸºç¡€ç½®ä¿¡åº¦
                
                groups = match.groups()
                if len(groups) == 2:
                    # è‚¡ç¥¨å(ä»£ç ) æ ¼å¼
                    name_or_market, code = groups
                    
                    # ğŸ”¥ ä¿®å¤æ¸¯è‚¡ä»£ç è¯†åˆ«
                    if re.match(r'0\d{4}', code):  # æ¸¯è‚¡5ä½ä»£ç ï¼ˆ0å¼€å¤´ï¼‰
                        stock_code = code
                        if re.match(r'[\u4e00-\u9fa5]', name_or_market):
                            stock_name = name_or_market
                            confidence = 0.95  # æ¸¯è‚¡åç§°+ä»£ç æ ¼å¼ç½®ä¿¡åº¦æœ€é«˜
                            logger.debug(f"ğŸ¯ è¯†åˆ«æ¸¯è‚¡: {stock_name}({stock_code}), ç½®ä¿¡åº¦: {confidence}")
                    elif re.match(r'\d{6}', code):  # Aè‚¡6ä½ä»£ç 
                        stock_code = code
                        if re.match(r'[\u4e00-\u9fa5]', name_or_market):
                            stock_name = name_or_market
                            confidence = 0.9  # Aè‚¡åç§°+ä»£ç æ ¼å¼ç½®ä¿¡åº¦é«˜
                            logger.debug(f"ğŸ¯ è¯†åˆ«Aè‚¡: {stock_name}({stock_code}), ç½®ä¿¡åº¦: {confidence}")
                    elif re.match(r'[A-Z]{2}', name_or_market) and re.match(r'\d{6}', code):
                        # SH600000 æ ¼å¼
                        stock_code = code
                        confidence = 0.8
                        logger.debug(f"ğŸ¯ è¯†åˆ«å¸‚åœºä»£ç : {name_or_market}{stock_code}, ç½®ä¿¡åº¦: {confidence}")
                elif len(groups) == 1:
                    # å•ç‹¬ä»£ç æ ¼å¼
                    code = groups[0]
                    if re.match(r'0\d{4}', code):  # æ¸¯è‚¡ä»£ç 
                        stock_code = code
                        confidence = 0.7  # æ¸¯è‚¡å•ç‹¬ä»£ç ä¸­ç­‰ç½®ä¿¡åº¦
                        logger.debug(f"ğŸ¯ è¯†åˆ«æ¸¯è‚¡ä»£ç : {stock_code}, ç½®ä¿¡åº¦: {confidence}")
                    elif re.match(r'\d{6}', code):  # Aè‚¡ä»£ç 
                        stock_code = code
                        confidence = 0.5  # Aè‚¡å•ç‹¬ä»£ç è¾ƒä½ç½®ä¿¡åº¦
                        logger.debug(f"ğŸ¯ è¯†åˆ«Aè‚¡ä»£ç : {stock_code}, ç½®ä¿¡åº¦: {confidence}")
                
                if stock_code:
                    # ğŸ”¥ ä¼˜å…ˆä¿ç•™æœ€é«˜ç½®ä¿¡åº¦ï¼Œä½†è®°å½•æ‰€æœ‰åŒ¹é…
                    match_key = f"{stock_code}_{i}"  # åŠ å…¥æ¨¡å¼ç´¢å¼•é¿å…å†²çª
                    if match_key not in confidence_scores or confidence > confidence_scores[match_key]:
                        confidence_scores[match_key] = confidence
                        
                    # ç‹¬ç«‹è®°å½•æœ€ä½³åŒ¹é…
                    if stock_code not in confidence_scores or confidence > confidence_scores[stock_code]:
                        confidence_scores[stock_code] = confidence
        
        # ğŸ”¥ æ–¹æ³•2: æ•°æ®åº“éªŒè¯å’Œè¯¦ç»†ä¿¡æ¯è·å–
        for stock_code, confidence in confidence_scores.items():
            # è·³è¿‡å¸¦æ¨¡å¼ç´¢å¼•çš„key
            if '_' in stock_code and not stock_code.replace('_', '').isdigit():
                continue
                
            try:
                # ğŸ”¥ ä¿®å¤ï¼šæ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼ˆä¿æŒæ¸¯è‚¡5ä½æ ¼å¼ï¼‰
                normalized_code = self._normalize_stock_code_enhanced(stock_code)
                
                # ä»æ•°æ®åº“éªŒè¯è‚¡ç¥¨å­˜åœ¨æ€§
                ticker = await self.ticker_handler.get_ticker_by_code(normalized_code)
                if ticker:
                    # å¢å¼ºç½®ä¿¡åº¦åˆ¤æ–­
                    enhanced_confidence = self._calculate_enhanced_confidence_v2(
                        stock_code, ticker.name, news_content, confidence
                    )
                    
                    mentioned_stocks.append({
                        "code": normalized_code,
                        "original_code": stock_code,
                        "name": ticker.name,
                        "market": self._determine_market(normalized_code),
                        "confidence": enhanced_confidence,
                        "ticker_id": ticker.id,
                        "group_id": ticker.group_id
                    })
                    
                    logger.info(f"âœ… éªŒè¯è‚¡ç¥¨: {ticker.name}({normalized_code}), ç½®ä¿¡åº¦: {enhanced_confidence:.2f}")
                else:
                    logger.debug(f"âŒ è‚¡ç¥¨ä»£ç æ— æ•ˆ: {stock_code}")
                    
            except Exception as e:
                logger.warning(f"è‚¡ç¥¨éªŒè¯å¤±è´¥ {stock_code}: {e}")
        
        # ğŸ”¥ æ–¹æ³•3: åˆ©ç”¨é¢„å­˜çš„entitieså’Œkeywords
        if article.entities:
            mentioned_stocks.extend(await self._extract_from_entities(article.entities))
        
        # å»é‡å¹¶æ’åº
        unique_stocks = self._deduplicate_stocks(mentioned_stocks)
        return sorted(unique_stocks, key=lambda x: x["confidence"], reverse=True)
    
    def _normalize_stock_code_enhanced(self, code: str) -> str:
        """ğŸ”¥ å¢å¼ºçš„è‚¡ç¥¨ä»£ç æ ‡å‡†åŒ– - æ­£ç¡®å¤„ç†æ¸¯è‚¡ä»£ç """
        # ç§»é™¤å¯èƒ½çš„å‰ç¼€
        code = re.sub(r'^(SH|SZ)', '', code)
        
        # ğŸ”¥ ä¿®å¤ï¼šæ¸¯è‚¡ä»£ç ä¿æŒ5ä½æ ¼å¼
        if len(code) == 5 and code.startswith('0') and code.isdigit():
            return code  # æ¸¯è‚¡ä»£ç ï¼Œä¿æŒ5ä½
        elif len(code) == 6 and code.isdigit():
            return code  # Aè‚¡ä»£ç ï¼Œä¿æŒ6ä½
        else:
            return code  # ä¿æŒåŸæ ·ï¼Œç”±åç»­éªŒè¯
    
    def _calculate_enhanced_confidence_v2(self, original_code: str, stock_name: str, content: str, base_confidence: float) -> float:
        """ğŸ”¥ è®¡ç®—å¢å¼ºç½®ä¿¡åº¦v2 - æ”¹è¿›ç®—æ³•"""
        confidence = base_confidence
        
        # ğŸ”¥ å¦‚æœæ–°é—»æ ‡é¢˜ä¸­åŒ…å«è‚¡ç¥¨ä»£ç ï¼Œå¤§å¹…å¢åŠ ç½®ä¿¡åº¦
        title_section = content[:200]  # æ ‡é¢˜å’Œå¼€å¤´éƒ¨åˆ†
        if original_code in title_section:
            confidence += 0.3
            logger.debug(f"æ ‡é¢˜åŒ…å«ä»£ç  {original_code}ï¼Œç½®ä¿¡åº¦+0.3")
        
        # ğŸ”¥ å¦‚æœæ–°é—»ä¸­åŒæ—¶å‡ºç°è‚¡ç¥¨åç§°ï¼Œå¢åŠ ç½®ä¿¡åº¦
        if stock_name and stock_name in content:
            confidence += 0.25
            logger.debug(f"å†…å®¹åŒ…å«è‚¡ç¥¨åç§° {stock_name}ï¼Œç½®ä¿¡åº¦+0.25")
        
        # ğŸ”¥ å¦‚æœå‘¨å›´æœ‰å¼ºæŠ•èµ„ç›¸å…³è¯æ±‡ï¼Œå¢åŠ ç½®ä¿¡åº¦
        code_pos = content.find(original_code)
        if code_pos >= 0:
            surrounding_text = content[max(0, code_pos-50):code_pos+100]
            strong_keywords = ['æ¶¨è¶…', 'æ¶¨å¹…', 'è·Œå¹…', 'æ¶¨åœ', 'è·Œåœ', 'å¤§æ¶¨', 'å¤§è·Œ', 'ä¸Šæ¶¨', 'ä¸‹è·Œ']
            for keyword in strong_keywords:
                if keyword in surrounding_text:
                    confidence += 0.15
                    logger.debug(f"å‘¨å›´åŒ…å«å¼ºæŠ•èµ„è¯æ±‡ {keyword}ï¼Œç½®ä¿¡åº¦+0.15")
                    break
            
            # ä¸€èˆ¬æŠ•èµ„è¯æ±‡
            general_keywords = ['è‚¡ä»·', 'å¸‚å€¼', 'ä¸šç»©', 'è‚¡ç¥¨', 'æŠ•èµ„']
            for keyword in general_keywords:
                if keyword in surrounding_text:
                    confidence += 0.05
                    break
        
        # ğŸ”¥ æ¸¯è‚¡ä»£ç é¢å¤–åŠ åˆ†
        if len(original_code) == 5 and original_code.startswith('0'):
            confidence += 0.1
            logger.debug(f"æ¸¯è‚¡ä»£ç æ ¼å¼ {original_code}ï¼Œç½®ä¿¡åº¦+0.1")
        
        return min(confidence, 1.0)  # ç¡®ä¿ä¸è¶…è¿‡1.0
    
    async def _extract_from_entities(self, entities: List[Dict]) -> List[Dict[str, Any]]:
        """ä»é¢„å­˜çš„å®ä½“ä¿¡æ¯ä¸­æå–è‚¡ç¥¨"""
        entity_stocks = []
        
        for entity in entities:
            if isinstance(entity, dict):
                entity_name = entity.get('name', '')
                entity_type = entity.get('type', '')
                
                # å¦‚æœå®ä½“ç±»å‹æ˜¯è‚¡ç¥¨æˆ–å…¬å¸
                if entity_type in ['STOCK', 'COMPANY', 'ORG'] or 'è‚¡ç¥¨' in entity_type:
                    # å°è¯•ä»å®ä½“åç§°ä¸­æå–è‚¡ç¥¨ä»£ç 
                    code_match = re.search(r'(\d{5,6})', entity_name)
                    if code_match:
                        stock_code = code_match.group(1)
                        try:
                            ticker = await self.ticker_handler.get_ticker_by_code(stock_code)
                            if ticker:
                                entity_stocks.append({
                                    "code": stock_code,
                                    "original_code": stock_code,
                                    "name": ticker.name,
                                    "market": self._determine_market(stock_code),
                                    "confidence": 0.7,  # æ¥è‡ªå®ä½“è¯†åˆ«çš„ç½®ä¿¡åº¦
                                    "ticker_id": ticker.id,
                                    "group_id": ticker.group_id,
                                    "source": "entities"
                                })
                        except Exception as e:
                            logger.warning(f"å®ä½“è‚¡ç¥¨éªŒè¯å¤±è´¥ {stock_code}: {e}")
        
        return entity_stocks
    
    def _check_investment_relevance(self, content: str) -> float:
        """æ£€æµ‹æŠ•èµ„ç›¸å…³æ€§å¾—åˆ†"""
        relevance_score = 0.0
        total_keywords = len(self.investment_keywords)
        
        for keyword in self.investment_keywords:
            if keyword in content:
                relevance_score += 1.0
        
        # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        return min(relevance_score / total_keywords * 2, 1.0)  # ä¹˜ä»¥2å¢åŠ æ•æ„Ÿåº¦
    
    def _make_intelligent_path_decision(self, mentioned_stocks: List[Dict], 
                                      investment_relevance: float, 
                                      classification: Dict[str, Any],
                                      context_info: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ”¥ æ™ºèƒ½åˆ†æè·¯å¾„å†³ç­–"""
        
        # å†³ç­–å› å­
        stock_count = len(mentioned_stocks)
        avg_confidence = sum(s["confidence"] for s in mentioned_stocks) / max(stock_count, 1)
        market_relevance = context_info.get("market_relevance_score", 0)
        importance = context_info.get("importance_score", 0)
        
        # å†³ç­–é€»è¾‘
        reasoning_parts = []
        
        # æ¡ä»¶1: æ˜ç¡®æåŠé«˜ç½®ä¿¡åº¦è‚¡ç¥¨
        if stock_count >= 1 and avg_confidence >= 0.7:
            reasoning_parts.append(f"æ£€æµ‹åˆ°{stock_count}åªé«˜ç½®ä¿¡åº¦è‚¡ç¥¨(avg={avg_confidence:.2f})")
            return {
                "analysis_type": "stock_specific",
                "action": "analyze_stocks",
                "reasoning": "; ".join(reasoning_parts),
                "confidence": avg_confidence
            }
        
        # æ¡ä»¶2: å¤šåªè‚¡ç¥¨ä½†ç½®ä¿¡åº¦ä¸­ç­‰
        if stock_count >= 2 and avg_confidence >= 0.5:
            reasoning_parts.append(f"æ£€æµ‹åˆ°{stock_count}åªä¸­ç­‰ç½®ä¿¡åº¦è‚¡ç¥¨ï¼Œè¿›è¡Œä¸ªè‚¡åˆ†æ")
            return {
                "analysis_type": "stock_specific",
                "action": "analyze_stocks", 
                "reasoning": "; ".join(reasoning_parts),
                "confidence": avg_confidence
            }
        
        # æ¡ä»¶3: å•åªè‚¡ç¥¨ä½†ä¸Šä¸‹æ–‡å¼ºç›¸å…³
        if stock_count == 1 and (investment_relevance >= 0.3 or market_relevance >= 0.5):
            reasoning_parts.append(f"å•åªè‚¡ç¥¨ä½†æŠ•èµ„ç›¸å…³æ€§é«˜({investment_relevance:.2f})")
            return {
                "analysis_type": "stock_specific",
                "action": "analyze_stocks",
                "reasoning": "; ".join(reasoning_parts),
                "confidence": mentioned_stocks[0]["confidence"]
            }
        
        # é»˜è®¤: è¡Œä¸šåˆ†æ
        if investment_relevance >= 0.2:
            reasoning_parts.append(f"æ— æ˜ç¡®ä¸ªè‚¡æˆ–æŠ•èµ„ä¸»é¢˜æ€§å†…å®¹ï¼Œè¿›è¡Œè¡Œä¸šåˆ†æ(æŠ•èµ„ç›¸å…³æ€§={investment_relevance:.2f})")
        else:
            reasoning_parts.append("é€šç”¨æ–°é—»å†…å®¹ï¼Œè¿›è¡Œä¸»é¢˜è¡Œä¸šåˆ†æ")
            
        return {
            "analysis_type": "industry_focused",
            "action": "analyze_industry",
            "reasoning": "; ".join(reasoning_parts),
            "confidence": investment_relevance
        }
    
    def _deduplicate_stocks(self, stocks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å»é‡è‚¡ç¥¨åˆ—è¡¨ï¼Œä¿ç•™æœ€é«˜ç½®ä¿¡åº¦"""
        unique_stocks = {}
        
        for stock in stocks:
            code = stock["code"]
            if code not in unique_stocks or stock["confidence"] > unique_stocks[code]["confidence"]:
                unique_stocks[code] = stock
        
        return list(unique_stocks.values())

    def _determine_market(self, stock_code: str) -> str:
        """æ ¹æ®è‚¡ç¥¨ä»£ç ç¡®å®šå¸‚åœº"""
        if stock_code.startswith(('60', '68')):
            return "SH"  # ä¸Šæµ·
        elif stock_code.startswith(('00', '30')):
            return "SZ"  # æ·±åœ³
        else:
            return "CN"  # é»˜è®¤ä¸­å›½å¸‚åœº

    async def _classify_news_with_llm(self, news_content: str, mentioned_stocks: List[Dict], context_info: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè¿›è¡Œæ–°é—»åˆ†ç±»"""
        prompt = self._build_enhanced_classification_prompt(news_content, mentioned_stocks, context_info)
        
        try:
            async with self.llm_client as client:
                response = await client.chat_completion(
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3,
                    max_tokens=500
                )
            
            return self._parse_classification_response(response.content)
        
        except Exception as e:
            logger.error(f"LLMåˆ†ç±»å¤±è´¥: {e}")
            return self._get_default_classification()
    
    def _build_enhanced_classification_prompt(self, news_content: str, mentioned_stocks: List[Dict], context_info: Dict[str, Any]) -> str:
        """æ„å»ºå¢å¼ºç‰ˆæ–°é—»åˆ†ç±»Prompt"""
        stock_info = ""
        if mentioned_stocks:
            stock_list = [f"{s['name']}({s['code']})" for s in mentioned_stocks[:5]]
            stock_info = f"\nç›¸å…³è‚¡ç¥¨: {', '.join(stock_list)}"
        
        # å¢åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
        context_str = ""
        if context_info:
            source = context_info.get("source_name", "")
            category = context_info.get("category", "")
            if source:
                context_str += f"\næ–°é—»æ¥æº: {source}"
            if category:
                context_str += f"\næ–‡ç« åˆ†ç±»: {category}"
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–°é—»å†…å®¹çš„æŠ•èµ„ä»·å€¼å’Œå¸‚åœºå½±å“ï¼š

{news_content}{stock_info}{context_str}

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{{
    "industry": ["ç›¸å…³è¡Œä¸š1", "ç›¸å…³è¡Œä¸š2"],
    "sentiment": "æ­£é¢|è´Ÿé¢|ä¸­æ€§",
    "impact_level": "é«˜|ä¸­|ä½",
    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"],
    "market_impact": "å¯¹å¸‚åœºçš„å½±å“åˆ†æ",
    "investment_theme": "æŠ•èµ„ä¸»é¢˜"
}}"""
        
        return prompt
    
    def post(self, shared_store: Dict[str, Any], prep_data: Dict[str, Any], exec_result: Dict[str, Any]) -> str:
        """åå¤„ç†ï¼šå°†åˆ†ç±»ç»“æœå­˜å‚¨åˆ°å…±äº«å­˜å‚¨"""
        if "error" not in exec_result:
            shared_store.update({
                "classification": exec_result.get("classification", {}),
                "mentioned_stocks": exec_result.get("mentioned_stocks", []),
                "analysis_type": exec_result.get("analysis_type"),
                "reasoning": exec_result.get("reasoning", ""),
                "investment_relevance": exec_result.get("investment_relevance", 0.0),
                "context_info": exec_result.get("context_info", {})
            })
            return exec_result.get("action", "error")
        else:
            shared_store["error"] = exec_result["error"]
            return "error"
    
    def _parse_classification_response(self, response_text: str) -> Dict[str, Any]:
        """è§£æLLMåˆ†ç±»å“åº”"""
        try:
            # å°è¯•æå–JSONå†…å®¹
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                return json.loads(json_str)
            else:
                return self._get_default_classification()
        except (json.JSONDecodeError, Exception) as e:
            logger.warning(f"åˆ†ç±»å“åº”è§£æå¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤åˆ†ç±»")
            return self._get_default_classification()
    
    def _get_default_classification(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤åˆ†ç±»ç»“æœ"""
        return {
            "industry": ["ç»¼åˆ"],
            "sentiment": "ä¸­æ€§",
            "impact_level": "ä¸­",
            "key_points": ["å¾…åˆ†æ"],
            "market_impact": "å¸‚åœºå½±å“å¾…è¯„ä¼°",
            "investment_theme": "ç»¼åˆæŠ•èµ„ä¸»é¢˜"
        }

class EnhancedStockAnalyzerAgent(Node):
    """å¢å¼ºç‰ˆè‚¡ç¥¨åˆ†æå™¨Agent - é›†æˆå®æ—¶è¯„åˆ†å’Œæ™ºèƒ½ç­›é€‰"""
    
    def __init__(self, llm_client: QwenLLMClient, max_industries: int = 3, top_stocks_per_industry: int = 10):
        super().__init__()
        self.llm_client = llm_client
        self.max_industries = max_industries
        self.top_stocks_per_industry = top_stocks_per_industry
        self.ticker_handler = TickerHandler()
        self.stock_data_factory = StockDataFactory()
    
    def prep(self, shared_store: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡è‚¡ç¥¨åˆ†ææ‰€éœ€çš„æ•°æ®"""
        return {
            "mentioned_stocks": shared_store.get("mentioned_stocks", []),
            "analysis_type": shared_store.get("analysis_type"),
            "classification": shared_store.get("classification", {}),
            "context_info": shared_store.get("context_info", {}),
            "article": shared_store.get("article"),
            "shared_store": shared_store
        }
    
    def exec(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå¢å¼ºè‚¡ç¥¨åˆ†æ - åŒæ­¥æ–¹æ³•"""
        # ä¿®å¤: å¦‚æœå·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œç›´æ¥è¿”å›åç¨‹è®©ä¸Šå±‚å¤„ç†
        try:
            loop = asyncio.get_running_loop()
            if loop.is_running():
                # åœ¨å·²è¿è¡Œçš„äº‹ä»¶å¾ªç¯ä¸­ï¼Œä¸èƒ½ä½¿ç”¨asyncio.run()
                import warnings
                warnings.warn("execæ–¹æ³•åœ¨è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ä¸­è¢«è°ƒç”¨ï¼Œå»ºè®®ä½¿ç”¨asyncç‰ˆæœ¬", RuntimeWarning)
                return {}
        except RuntimeError:
            # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œå¯ä»¥ä½¿ç”¨asyncio.run()
            pass
        
        return asyncio.run(self._exec_async(prep_data))
    
    async def _exec_async(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œå¢å¼ºè‚¡ç¥¨åˆ†æ"""
        analysis_type = prep_data.get("analysis_type")
        mentioned_stocks = prep_data.get("mentioned_stocks", [])
        classification = prep_data.get("classification", {})
        
        if analysis_type == "stock_specific":
            logger.info(f"ğŸ” æ‰§è¡Œä¸ªè‚¡åˆ†æè·¯å¾„ï¼Œè‚¡ç¥¨æ•°é‡: {len(mentioned_stocks)}")
            
            # ğŸ”¥ ä¸ªè‚¡åˆ†æè·¯å¾„ï¼šè·å–å…·ä½“è‚¡ç¥¨çš„å®æ—¶è¯„åˆ†
            analyzed_stocks = await self._analyze_specific_stocks_with_scores(mentioned_stocks)
            industry_analysis = await self._derive_industry_from_stocks(analyzed_stocks)
            
            return {
                "industry_analysis": industry_analysis,
                "related_stocks": analyzed_stocks,
                "analysis_approach": "stock_specific",
                "stock_count": len(analyzed_stocks)
            }
            
        else:  # industry_focused
            logger.info("ğŸ­ æ‰§è¡Œè¡Œä¸šåˆ†æè·¯å¾„")
            
            # ğŸ”¥ è¡Œä¸šåˆ†æè·¯å¾„ï¼šè¯†åˆ«è¡Œä¸šåè·å–é«˜è¯„åˆ†è‚¡ç¥¨
            industry_analysis = await self._analyze_industries_from_news(prep_data)
            related_stocks = await self._get_top_rated_stocks_by_industries(industry_analysis)
            
            return {
                "industry_analysis": industry_analysis,
                "related_stocks": related_stocks,
                "analysis_approach": "industry_focused", 
                "stock_count": len(related_stocks)
            }

    async def _analyze_specific_stocks_with_scores(self, mentioned_stocks: List[Dict]) -> List[Dict[str, Any]]:
        """ğŸ”¥ åˆ†æå…·ä½“è‚¡ç¥¨å¹¶è·å–å®æ—¶è¯„åˆ†"""
        analyzed_stocks = []
        
        for stock in mentioned_stocks:
            try:
                stock_code = stock["code"]
                stock_name = stock["name"]
                
                # è·å–30å¤©çš„è‚¡ç¥¨æ•°æ®å’Œè¯„åˆ†
                ticker_data = await self.ticker_handler.get_ticker_data(stock_code, days=30)
                
                if ticker_data:
                    # è®¡ç®—è¯„åˆ†ç»Ÿè®¡
                    scores = [data.get("score", 0) for data in ticker_data if data.get("score")]
                    
                    if scores:
                        current_score = scores[-1] if scores else 0  # æœ€æ–°è¯„åˆ†
                        avg_score = sum(scores) / len(scores)  # å¹³å‡è¯„åˆ†
                        score_trend = self._calculate_score_trend(scores)  # è¯„åˆ†è¶‹åŠ¿
                        
                        analyzed_stocks.append({
                            "code": stock_code,
                            "name": stock_name,
                            "market": stock.get("market", "CN"),
                            "confidence": stock.get("confidence", 0.8),
                            "current_score": current_score,
                            "avg_score_30d": round(avg_score, 2),
                            "score_trend": score_trend,
                            "score_count": len(scores),
                            "ticker_id": stock.get("ticker_id"),
                            "group_id": stock.get("group_id"),
                            "analysis_source": "mentioned_direct"
                        })
                        
                        logger.info(f"ğŸ“Š {stock_name}({stock_code}): å½“å‰è¯„åˆ†={current_score}, 30æ—¥å‡åˆ†={avg_score:.2f}, è¶‹åŠ¿={score_trend}")
                    else:
                        # æ²¡æœ‰è¯„åˆ†æ•°æ®ï¼Œä½†è‚¡ç¥¨å­˜åœ¨
                        analyzed_stocks.append({
                            "code": stock_code,
                            "name": stock_name,
                            "market": stock.get("market", "CN"),
                            "confidence": stock.get("confidence", 0.8),
                            "current_score": 0,
                            "avg_score_30d": 0,
                            "score_trend": "æ— æ•°æ®",
                            "score_count": 0,
                            "ticker_id": stock.get("ticker_id"),
                            "group_id": stock.get("group_id"),
                            "analysis_source": "mentioned_direct"
                        })
                        
                        logger.warning(f"âš ï¸ {stock_name}({stock_code}): æ— è¯„åˆ†æ•°æ®")
                
            except Exception as e:
                logger.error(f"è‚¡ç¥¨åˆ†æå¤±è´¥ {stock.get('name', 'N/A')}({stock.get('code', 'N/A')}): {e}")
        
        # æŒ‰å½“å‰è¯„åˆ†æ’åº
        analyzed_stocks.sort(key=lambda x: x["current_score"], reverse=True)
        return analyzed_stocks
    
    def _calculate_score_trend(self, scores: List[float]) -> str:
        """è®¡ç®—è¯„åˆ†è¶‹åŠ¿"""
        if len(scores) < 2:
            return "æ•°æ®ä¸è¶³"
        
        # ç®€å•è¶‹åŠ¿è®¡ç®—ï¼šæ¯”è¾ƒæœ€è¿‘1/3å’Œå‰1/3çš„å¹³å‡å€¼
        third = len(scores) // 3
        if third == 0:
            return "æ•°æ®ä¸è¶³"
        
        recent_avg = sum(scores[-third:]) / third
        early_avg = sum(scores[:third]) / third
        
        diff = recent_avg - early_avg
        
        if diff > 0.5:
            return "ä¸Šå‡"
        elif diff < -0.5:
            return "ä¸‹é™"
        else:
            return "å¹³ç¨³"

    async def _derive_industry_from_stocks(self, mentioned_stocks: List[Dict]) -> Dict[str, Any]:
        """ä»è‚¡ç¥¨æ¨å¯¼è¡Œä¸šåˆ†æ"""
        if not mentioned_stocks:
            return {"affected_industries": [], "analysis": "æ— å…·ä½“è‚¡ç¥¨ä¿¡æ¯"}
        
        # æ ¹æ®è‚¡ç¥¨åˆ†ç»„ä¿¡æ¯æ¨å¯¼è¡Œä¸š
        group_ids = [stock.get("group_id", 0) for stock in mentioned_stocks]
        unique_groups = list(set(group_ids))
        
        # è¿™é‡Œå¯ä»¥æ ¹æ®group_idæ˜ å°„åˆ°å…·ä½“è¡Œä¸š
        # æš‚æ—¶ä½¿ç”¨ç®€åŒ–é€»è¾‘
        industry_mapping = {
            1: "é“¶è¡Œ",
            2: "è¯åˆ¸", 
            3: "ä¿é™©",
            4: "æˆ¿åœ°äº§",
            5: "åˆ¶é€ ä¸š",
            6: "ç§‘æŠ€",
            7: "åŒ»è¯",
            8: "æ¶ˆè´¹",
            9: "èƒ½æº",
            10: "ææ–™"
        }
        
        affected_industries = []
        for group_id in unique_groups:
            if group_id in industry_mapping:
                affected_industries.append({
                    "industry": industry_mapping[group_id],
                    "group_id": group_id,
                    "stock_count": len([s for s in mentioned_stocks if s.get("group_id") == group_id])
                })
        
        return {
            "affected_industries": affected_industries,
            "analysis": f"åŸºäº{len(mentioned_stocks)}åªå…·ä½“è‚¡ç¥¨çš„è¡Œä¸šåˆ†æ",
            "total_stocks": len(mentioned_stocks)
        }

    async def _analyze_industries_from_news(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ”¥ ä»æ–°é—»å†…å®¹åˆ†æç›¸å…³è¡Œä¸š"""
        classification = prep_data.get("classification", {})
        context_info = prep_data.get("context_info", {})
        article = prep_data.get("article")
        
        # ä»åˆ†ç±»ç»“æœæå–è¡Œä¸šä¿¡æ¯
        classified_industries = classification.get("industry", [])
        investment_theme = classification.get("investment_theme", "")
        
        # è¡Œä¸šå…³é”®è¯æ˜ å°„
        industry_keywords = {
            "é“¶è¡Œ": ["é“¶è¡Œ", "é™å‡†", "å­˜æ¬¾", "è´·æ¬¾", "åˆ©ç‡", "å¤®è¡Œ"],
            "ç§‘æŠ€": ["ç§‘æŠ€", "AI", "äººå·¥æ™ºèƒ½", "èŠ¯ç‰‡", "åŠå¯¼ä½“", "è½¯ä»¶"],
            "åŒ»è¯": ["åŒ»è¯", "åˆ¶è¯", "æ–°è¯", "ç”Ÿç‰©", "ç–«è‹—", "åŒ»ç–—"],
            "æ–°èƒ½æº": ["æ–°èƒ½æº", "ç”µåŠ¨è½¦", "é”‚ç”µ", "å…‰ä¼", "é£ç”µ", "å……ç”µ"],
            "æˆ¿åœ°äº§": ["æˆ¿åœ°äº§", "åœ°äº§", "ä½æˆ¿", "æ¥¼å¸‚", "æˆ¿ä»·"],
            "æ¶ˆè´¹": ["æ¶ˆè´¹", "é›¶å”®", "ç”µå•†", "é£Ÿå“", "é¥®æ–™"],
            "åˆ¶é€ ": ["åˆ¶é€ ", "å·¥ä¸š", "æœºæ¢°", "æ±½è½¦", "é’¢é“"],
            "é‡‘è": ["é‡‘è", "è¯åˆ¸", "ä¿é™©", "åŸºé‡‘", "ä¿¡æ‰˜"]
        }
        
        # å†…å®¹åŒ¹é…å¾—åˆ†
        content = f"{article.title} {article.content}" if article else ""
        industry_scores = {}
        
        for industry, keywords in industry_keywords.items():
            score = 0
            for keyword in keywords:
                if keyword in content:
                    score += 1
            industry_scores[industry] = score
        
        # åˆå¹¶åˆ†ç±»ç»“æœå’Œå…³é”®è¯åŒ¹é…
        affected_industries = []
        
        # æ·»åŠ åˆ†ç±»è¯†åˆ«çš„è¡Œä¸š
        for industry in classified_industries[:self.max_industries]:
            affected_industries.append({
                "industry": industry,
                "confidence": 0.8,
                "source": "llm_classification",
                "keyword_score": industry_scores.get(industry, 0)
            })
        
        # æ·»åŠ å…³é”®è¯åŒ¹é…åº¦é«˜çš„è¡Œä¸š
        sorted_industries = sorted(industry_scores.items(), key=lambda x: x[1], reverse=True)
        for industry, score in sorted_industries[:self.max_industries]:
            if score > 0 and not any(ai["industry"] == industry for ai in affected_industries):
                affected_industries.append({
                    "industry": industry, 
                    "confidence": min(score * 0.2, 1.0),
                    "source": "keyword_matching",
                    "keyword_score": score
                })
        
        return {
            "affected_industries": affected_industries[:self.max_industries],
            "analysis": f"åŸºäºå†…å®¹åˆ†æè¯†åˆ«{len(affected_industries)}ä¸ªç›¸å…³è¡Œä¸š",
            "investment_theme": investment_theme
        }

    async def _get_top_rated_stocks_by_industries(self, industry_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ğŸ”¥ æ ¹æ®è¡Œä¸šè·å–é«˜è¯„åˆ†è‚¡ç¥¨ - ä½¿ç”¨AKShareçœŸå®æ•°æ®"""
        affected_industries = industry_analysis.get("affected_industries", [])
        all_related_stocks = []
        
        logger.info(f"ğŸ” å¼€å§‹åˆ†æ {len(affected_industries)} ä¸ªè¡Œä¸šçš„è‚¡ç¥¨")
        
        for industry_info in affected_industries:
            industry = industry_info["industry"]
            confidence = industry_info.get("confidence", 0.5)
            impact_type = industry_info.get("impact_type", "positive")
            impact_degree = min(int(confidence * 10), 10)  # è½¬æ¢ä¸º1-10çš„å½±å“ç¨‹åº¦
            
            try:
                logger.info(f"ğŸ“Š è·å–è¡Œä¸š '{industry}' çš„è‚¡ç¥¨ (å½±å“åº¦: {impact_degree}/10)")
                
                # ğŸ”¥ ä¿®å¤é—®é¢˜3: ä½¿ç”¨çœŸæ­£çš„AKShareæ¥å£è€Œä¸æ˜¯ç¡¬ç¼–ç æ˜ å°„
                industry_stocks = await get_industry_stocks_from_akshare(
                    industry=industry,
                    impact_type=impact_type, 
                    impact_degree=impact_degree
                )
                
                if not industry_stocks:
                    logger.warning(f"âš ï¸  è¡Œä¸š '{industry}' æœªè·å–åˆ°AKShareæ•°æ®ï¼Œè·³è¿‡")
                    continue
                
                logger.info(f"âœ… è¡Œä¸š '{industry}' è·å–åˆ° {len(industry_stocks)} åªå€™é€‰è‚¡ç¥¨")
                
                # è·å–è¿™äº›è‚¡ç¥¨çš„è¯„åˆ†æ•°æ®å¹¶ç­›é€‰é«˜åˆ†è‚¡ç¥¨
                high_score_stocks = []
                for stock_info in industry_stocks[:20]:  # é™åˆ¶æ¯ä¸ªè¡Œä¸šæœ€å¤šå¤„ç†20åªè‚¡ç¥¨
                    stock_code = stock_info.get("code", "")
                    stock_name = stock_info.get("name", "")
                    relevance_score = stock_info.get("relevance_score", 5)
                    
                    if not stock_code:
                        continue
                        
                    try:
                        # ä»AKShareè·å–çš„è‚¡ç¥¨ç›´æ¥ä½¿ç”¨å…¶ç›¸å…³æ€§è¯„åˆ†
                        # è¿™æ¯”æ•°æ®åº“ä¸­å¯èƒ½è¿‡æ—¶çš„è¯„åˆ†æ›´å‡†ç¡®
                        akshare_score = relevance_score  # AKShareæä¾›çš„ç›¸å…³æ€§è¯„åˆ†
                        market_data = {
                            "latest_price": stock_info.get("latest_price", 0),
                            "change_pct": stock_info.get("change_pct", 0),
                            "market_cap": stock_info.get("market_cap", 0),
                            "turnover_rate": stock_info.get("turnover_rate", 0)
                        }
                        
                        # åªé€‰æ‹©è¯„åˆ†è¾ƒé«˜çš„è‚¡ç¥¨ (AKShareç›¸å…³æ€§è¯„åˆ† >= 6)
                        if akshare_score >= 6.0:
                            ticker = await self.ticker_handler.get_ticker_by_code(stock_code)
                            
                            stock_data = {
                                "code": stock_code,
                                "name": stock_name,
                                "market": self._determine_market(stock_code),
                                "current_score": akshare_score,
                                "avg_recent_score": akshare_score,
                                "industry": industry,
                                "industry_confidence": confidence,
                                "analysis_source": f"akshare_{industry}",
                                "reason": stock_info.get("reason", f"{industry}æ¿å—ç›¸å…³"),
                                "board_name": stock_info.get("board_name", industry),
                                **market_data
                            }
                            
                            # å¦‚æœæ‰¾åˆ°äº†tickerä¿¡æ¯ï¼Œæ·»åŠ ticker_id
                            if ticker:
                                stock_data.update({
                                    "ticker_id": ticker.id,
                                    "group_id": ticker.group_id
                                })
                            
                            high_score_stocks.append(stock_data)
                            logger.debug(f"ğŸ“ˆ é«˜åˆ†è‚¡ç¥¨: {stock_name}({stock_code}) - {industry} - AKShareè¯„åˆ†: {akshare_score}")
                        else:
                            logger.debug(f"âšª ä½åˆ†è‚¡ç¥¨: {stock_name}({stock_code}) - è¯„åˆ†: {akshare_score} < 6.0")
                            
                    except Exception as e:
                        logger.warning(f"âš ï¸  å¤„ç†è‚¡ç¥¨ {stock_code} å¤±è´¥: {e}")
                        continue
                
                all_related_stocks.extend(high_score_stocks)
                logger.info(f"âœ… è¡Œä¸š '{industry}' ç­›é€‰å‡º {len(high_score_stocks)} åªé«˜è¯„åˆ†è‚¡ç¥¨")
                
            except Exception as e:
                logger.error(f"âŒ è¡Œä¸šè‚¡ç¥¨è·å–å¤±è´¥ {industry}: {e}")
        
        # å»é‡ã€æ’åºå’Œé™åˆ¶æ•°é‡
        unique_stocks = self._deduplicate_stocks(all_related_stocks)
        
        # æŒ‰è¯„åˆ†æ’åºï¼Œå–top 20
        top_stocks = sorted(unique_stocks, key=lambda x: x["current_score"], reverse=True)[:20]
        
        logger.info(f"ğŸ† ä»{len(affected_industries)}ä¸ªè¡Œä¸šç­›é€‰å‡º{len(top_stocks)}åªé«˜è¯„åˆ†è‚¡ç¥¨")
        
        # ğŸ”¥ ä¿®å¤é—®é¢˜4: å¦‚æœæ‰¾åˆ°0åªè‚¡ç¥¨ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯ä¾¿äºè°ƒè¯•
        if len(top_stocks) == 0:
            logger.warning(f"âš ï¸  æœªæ‰¾åˆ°é«˜è¯„åˆ†è‚¡ç¥¨ - è°ƒè¯•ä¿¡æ¯:")
            logger.warning(f"   - åˆ†æçš„è¡Œä¸š: {[info['industry'] for info in affected_industries]}")
            logger.warning(f"   - è·å–çš„åŸå§‹è‚¡ç¥¨æ€»æ•°: {len(all_related_stocks)}")
            logger.warning(f"   - å»é‡åè‚¡ç¥¨æ•°: {len(unique_stocks)}")
            if unique_stocks:
                max_score = max(stock["current_score"] for stock in unique_stocks)
                logger.warning(f"   - æœ€é«˜è¯„åˆ†: {max_score} (é˜ˆå€¼: 6.0)")
        
        return top_stocks

    async def _get_stocks_by_industry_name(self, industry_name: str) -> List[str]:
        """æ ¹æ®è¡Œä¸šåç§°è·å–è‚¡ç¥¨ä»£ç åˆ—è¡¨ - å·²å¼ƒç”¨ï¼Œä½¿ç”¨AKShareæ¥å£"""
        logger.warning(f"âš ï¸  _get_stocks_by_industry_nameå·²å¼ƒç”¨ï¼Œåº”ä½¿ç”¨AKShareæ¥å£")
        # ä¿ç•™ä½œä¸ºå¤‡ç”¨ï¼Œä½†ä¸åº”è¯¥è¢«è°ƒç”¨
        industry_stock_mapping = {
            "é“¶è¡Œ": ["600000", "600036", "600016", "000001", "002142"],
            "ç§‘æŠ€": ["000858", "300059", "002415", "300496", "600570"],
            "åŒ»è¯": ["000661", "002007", "300003", "600276", "002821"],
            "æ–°èƒ½æº": ["002594", "300750", "002460", "688599", "300274"], 
            "æ¶ˆè´¹": ["000858", "600519", "000568", "002304", "600887"],
            "åˆ¶é€ ": ["000002", "600519", "000858", "002027", "600031"],
            "é‡‘è": ["600000", "600030", "000002", "601318", "601166"]
        }
        return industry_stock_mapping.get(industry_name, [])
    
    def _determine_market(self, stock_code: str) -> str:
        """ç¡®å®šè‚¡ç¥¨å¸‚åœº"""
        if stock_code.startswith(('60', '68')):
            return "SH"  # ä¸Šæµ·
        elif stock_code.startswith(('00', '30')):
            return "SZ"  # æ·±åœ³
        else:
            return "CN"  # é»˜è®¤
    
    def _deduplicate_stocks(self, stocks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å»é‡è‚¡ç¥¨åˆ—è¡¨ï¼Œä¿ç•™æœ€é«˜è¯„åˆ†"""
        unique_stocks = {}
        
        for stock in stocks:
            code = stock["code"]
            if code not in unique_stocks or stock["current_score"] > unique_stocks[code]["current_score"]:
                unique_stocks[code] = stock
        
        return list(unique_stocks.values())

    def post(self, shared_store: Dict[str, Any], prep_data: Dict[str, Any], exec_result: Dict[str, Any]) -> str:
        """åå¤„ç†ï¼šå°†è‚¡ç¥¨åˆ†æç»“æœå­˜å‚¨åˆ°å…±äº«å­˜å‚¨"""
        shared_store.update({
            "industry_analysis": exec_result.get("industry_analysis", {}),
            "related_stocks": exec_result.get("related_stocks", []),
            "analysis_approach": exec_result.get("analysis_approach", "unknown"),
            "stock_count": exec_result.get("stock_count", 0)
        })
        return "generate_advice"

class InvestmentAdvisorAgent(Node):
    """æŠ•èµ„å»ºè®®Agent - ç»¼åˆåˆ†æå¹¶æä¾›æœ€ç»ˆæŠ•èµ„å»ºè®®"""
    
    def __init__(self, llm_client: QwenLLMClient):
        super().__init__()
        self.llm_client = llm_client
    
    def prep(self, shared_store: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡æŠ•èµ„å»ºè®®ç”Ÿæˆæ‰€éœ€çš„æ•°æ®"""
        return {
            "classification": shared_store.get("classification", {}),
            "industry_analysis": shared_store.get("industry_analysis", {}),
            "related_stocks": shared_store.get("related_stocks", []),
            "analysis_type": shared_store.get("analysis_type", "industry_focused"),
            "mentioned_stocks": shared_store.get("mentioned_stocks", []),
            "shared_store": shared_store
        }
    
    def exec(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”ŸæˆæŠ•èµ„å»ºè®® - åŒæ­¥æ–¹æ³•"""
        # ä¿®å¤: å¦‚æœå·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œç›´æ¥è¿”å›åç¨‹è®©ä¸Šå±‚å¤„ç†
        try:
            loop = asyncio.get_running_loop()
            if loop.is_running():
                # åœ¨å·²è¿è¡Œçš„äº‹ä»¶å¾ªç¯ä¸­ï¼Œä¸èƒ½ä½¿ç”¨asyncio.run()
                import warnings
                warnings.warn("execæ–¹æ³•åœ¨è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ä¸­è¢«è°ƒç”¨ï¼Œå»ºè®®ä½¿ç”¨asyncç‰ˆæœ¬", RuntimeWarning)
                return {}
        except RuntimeError:
            # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œå¯ä»¥ä½¿ç”¨asyncio.run()
            pass
        
        return asyncio.run(self._exec_async(prep_data))
    
    async def _exec_async(self, prep_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¼‚æ­¥ç”ŸæˆæŠ•èµ„å»ºè®®"""
        classification = prep_data.get("classification", {})
        industry_analysis = prep_data.get("industry_analysis", {})
        related_stocks = prep_data.get("related_stocks", [])
        analysis_type = prep_data.get("analysis_type", "industry_focused")
        mentioned_stocks = prep_data.get("mentioned_stocks", [])
        
        # ğŸ”¥ ä¿®å¤é—®é¢˜4: æ€§èƒ½ä¼˜åŒ– - å½“æ‰¾åˆ°0åªè‚¡ç¥¨æ—¶è·³è¿‡LLMåˆ†æ
        if len(related_stocks) == 0 and len(mentioned_stocks) == 0:
            logger.warning("âš¡ æ€§èƒ½ä¼˜åŒ–: æœªæ‰¾åˆ°ä»»ä½•ç›¸å…³è‚¡ç¥¨ï¼Œè·³è¿‡LLMåˆ†æä»¥èŠ‚çœtoken")
            
            # è¿”å›æ ‡å‡†åŒ–çš„ç©ºç»“æœï¼Œé¿å…LLMè°ƒç”¨
            default_advice = {
                "recommendation": "è§‚æœ›",
                "rationale": "æœªæ‰¾åˆ°è¶³å¤Ÿçš„ç›¸å…³è‚¡ç¥¨æ•°æ®æ”¯æ’‘æŠ•èµ„å†³ç­–ï¼Œå»ºè®®è§‚æœ›ç­‰å¾…æ›´å¤šä¿¡æ¯",
                "risk_assessment": "ä¿¡æ¯ä¸è¶³å¯¼è‡´çš„ä¸ç¡®å®šæ€§é£é™©",
                "time_horizon": "çŸ­æœŸ",
                "position_size": "æš‚ä¸å‚ä¸",
                "stop_loss": "N/A",
                "confidence_level": 2,
                "key_factors": ["ç¼ºä¹ç›¸å…³è‚¡ç¥¨æ•°æ®", "ä¿¡æ¯ä¸å……åˆ†"],
                "alternative_scenarios": "ç­‰å¾…æ›´å¤šç›¸å…³æ–°é—»æˆ–æ•°æ®åå†è¯„ä¼°",
                "token_saved": True,  # æ ‡è®°ä¸ºèŠ‚çœtokençš„ç»“æœ
                "analysis_skipped_reason": "æ— ç›¸å…³è‚¡ç¥¨æ•°æ®"
            }
            
            logger.info("ğŸ’¡ å·²è¿”å›é»˜è®¤è§‚æœ›å»ºè®®ï¼ŒèŠ‚çœäº†LLM tokenæ¶ˆè€—")
            return {
                "investment_advice": default_advice,
                "action": "done"
            }
        
        # å¦‚æœæœ‰ç›¸å…³è‚¡ç¥¨ï¼Œè®°å½•æ•°é‡ç”¨äºè°ƒè¯•
        logger.info(f"ğŸ“Š å°†åˆ†æ {len(related_stocks)} åªç›¸å…³è‚¡ç¥¨ + {len(mentioned_stocks)} åªæåŠè‚¡ç¥¨")
        
        prompt = self._build_investment_advice_prompt(
            classification, industry_analysis, related_stocks, analysis_type, mentioned_stocks
        )
        
        try:
            async with self.llm_client as client:
                response = await client.chat_completion(
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.4,
                    max_tokens=1000
                )
            
            # è§£ææŠ•èµ„å»ºè®®
            investment_advice = self._parse_advice_response(response.content)
            investment_advice["token_saved"] = False  # æ ‡è®°ä¸ºæ­£å¸¸LLMåˆ†æ
            
            logger.info("ğŸ’° æŠ•èµ„å»ºè®®ç”Ÿæˆå®Œæˆ (ä½¿ç”¨LLMåˆ†æ)")
            
            return {
                "investment_advice": investment_advice,
                "action": "done"
            }
        
        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ•èµ„å»ºè®®å¤±è´¥: {e}")
            return {
                "error": str(e),
                "action": "error"
            }
    
    def post(self, shared_store: Dict[str, Any], prep_data: Dict[str, Any], exec_result: Dict[str, Any]) -> str:
        """åå¤„ç† - ä¿å­˜ç»“æœåˆ°å…±äº«å­˜å‚¨å¹¶è¿”å›ä¸‹ä¸€æ­¥åŠ¨ä½œ"""
        if "investment_advice" in exec_result:
            shared_store["investment_advice"] = exec_result["investment_advice"]
        
        if "error" in exec_result:
            shared_store["error"] = exec_result["error"]
        
        return exec_result.get("action", "done")
    
    def _build_investment_advice_prompt(self, classification: Dict, 
                                      industry_analysis: Dict, 
                                      related_stocks: List[Dict],
                                      analysis_type: str,
                                      mentioned_stocks: List[Dict]) -> str:
        """æ„å»ºæŠ•èµ„å»ºè®®Prompt"""
        
        # æ ¹æ®åˆ†æç±»å‹è°ƒæ•´æç¤ºå†…å®¹
        if analysis_type == "stock_specific" and mentioned_stocks:
            focus_section = f"""
åˆ†æè·¯å¾„ï¼šä¸ªè‚¡åˆ†æ (æ£€æµ‹åˆ° {len(mentioned_stocks)} åªå…·ä½“è‚¡ç¥¨)
é‡ç‚¹å…³æ³¨è‚¡ç¥¨ï¼š{', '.join([f"{s['code']}({s.get('name', '')})" for s in mentioned_stocks])}
"""
            stocks_info = "\n".join([
                f"- {stock.get('code', '')} {stock.get('name', '')}: è¯„åˆ†{stock.get('current_score', 0)}/10 - {stock.get('analysis_source', '')}"
                for stock in related_stocks[:5]
            ])
        else:
            focus_section = f"""
åˆ†æè·¯å¾„ï¼šè¡Œä¸šåˆ†æ (æœªæ£€æµ‹åˆ°å…·ä½“è‚¡ç¥¨)
é‡ç‚¹å…³æ³¨è¡Œä¸šï¼š{', '.join([ind.get('industry', '') for ind in industry_analysis.get('affected_industries', [])[:3]])}
"""
            stocks_info = "\n".join([
                f"- {stock.get('code', '')} {stock.get('name', '')}: è¯„åˆ†{stock.get('current_score', 0)}/10 - {stock.get('industry', '')}è¡Œä¸š"
                for stock in related_stocks[:5]
            ])
        
        return f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ•èµ„é¡¾é—®ã€‚è¯·åŸºäºä»¥ä¸‹åˆ†æç»“æœæä¾›ä¸“ä¸šçš„æŠ•èµ„å»ºè®®ï¼š

{focus_section}

æ–°é—»åˆ†ç±»ï¼š
- ç±»å‹ï¼š{classification.get('news_type', 'æœªçŸ¥')}
- é‡è¦æ€§ï¼š{classification.get('importance_score', 0)}åˆ†
- æƒ…æ„Ÿå€¾å‘ï¼š{classification.get('sentiment', 'ä¸­æ€§')}
- å¸‚åœºå½±å“èŒƒå›´ï¼š{classification.get('market_scope', 'æœªçŸ¥')}

è¡Œä¸šå½±å“åˆ†æï¼š
{json.dumps(industry_analysis, ensure_ascii=False, indent=2)}

æ¨èè‚¡ç¥¨ï¼ˆæŒ‰è¯„åˆ†æ’åºï¼‰ï¼š
{stocks_info}

è¯·æä¾›ï¼š
1. æŠ•èµ„å»ºè®®ï¼š[ä¹°å…¥/æŒæœ‰/å–å‡º/è§‚æœ›]
2. æŠ•èµ„é€»è¾‘ï¼šè¯¦ç»†è¯´æ˜æŠ•èµ„ç†ç”±ï¼ˆè€ƒè™‘åˆ†æè·¯å¾„ç‰¹ç‚¹ï¼‰
3. é£é™©è¯„ä¼°ï¼šä¸»è¦é£é™©ç‚¹å’Œæ³¨æ„äº‹é¡¹
4. æ—¶é—´å»ºè®®ï¼š[çŸ­æœŸ/ä¸­æœŸ/é•¿æœŸ]æŒæœ‰å»ºè®®
5. ä»“ä½å»ºè®®ï¼šå»ºè®®çš„ä»“ä½æ¯”ä¾‹
6. æ­¢æŸå»ºè®®ï¼šé£é™©æ§åˆ¶æªæ–½
7. ä¿¡å¿ƒæŒ‡æ•°ï¼š1-10åˆ†ï¼ˆå¯¹è¿™ä¸ªå»ºè®®çš„ä¿¡å¿ƒç¨‹åº¦ï¼‰

è¿”å›JSONæ ¼å¼ï¼š
{{
  "recommendation": "ä¹°å…¥/æŒæœ‰/å–å‡º/è§‚æœ›",
  "rationale": "æŠ•èµ„é€»è¾‘è¯¦ç»†è¯´æ˜",
  "risk_assessment": "é£é™©è¯„ä¼°å†…å®¹",
  "time_horizon": "çŸ­æœŸ/ä¸­æœŸ/é•¿æœŸ",
  "position_size": "ä»“ä½å»ºè®®",
  "stop_loss": "æ­¢æŸå»ºè®®",
  "confidence_level": åˆ†æ•°,
  "key_factors": ["å…³é”®å› ç´ 1", "å…³é”®å› ç´ 2"],
  "alternative_scenarios": "å…¶ä»–å¯èƒ½æƒ…å†µåˆ†æ"
}}

æ³¨æ„ï¼š
- å»ºè®®è¦å…·ä½“å¯æ“ä½œ
- å¿…é¡»åŒ…å«é£é™©æç¤º
- è€ƒè™‘å½“å‰å¸‚åœºç¯å¢ƒ
- åŒºåˆ†ä¸ªè‚¡åˆ†æä¸è¡Œä¸šåˆ†æçš„ä¸åŒç­–ç•¥
- æä¾›å®¢è§‚ç†æ€§çš„åˆ†æ"""
    
    def _parse_advice_response(self, response_text: str) -> Dict[str, Any]:
        """è§£ææŠ•èµ„å»ºè®®å“åº”"""
        try:
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            
            if start_idx >= 0 and end_idx > start_idx:
                json_str = response_text[start_idx:end_idx]
                return json.loads(json_str)
            else:
                raise ValueError("æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„JSONå†…å®¹")
        
        except Exception as e:
            logger.error(f"è§£ææŠ•èµ„å»ºè®®å¤±è´¥: {e}")
            return {
                "recommendation": "è§‚æœ›",
                "rationale": "åˆ†æç»“æœè§£æå¤±è´¥",
                "risk_assessment": "å­˜åœ¨ä¸ç¡®å®šæ€§",
                "time_horizon": "çŸ­æœŸ",
                "position_size": "è°¨æ…å‚ä¸",
                "stop_loss": "åŠæ—¶æ­¢æŸ",
                "confidence_level": 3,
                "key_factors": [],
                "alternative_scenarios": "éœ€è¦è¿›ä¸€æ­¥åˆ†æ"
            }

class NewsAnalysisFlow:
    """æ–°é—»åˆ†ææµæ°´çº¿ä¸»ç±»"""
    
    def __init__(self, llm_client: QwenLLMClient):
        """
        åˆå§‹åŒ–æ–°é—»åˆ†ææµæ°´çº¿
        
        Args:
            llm_client: åƒé—®LLMå®¢æˆ·ç«¯
        """
        self.llm_client = llm_client
        
        # åˆå§‹åŒ–å„ä¸ªAgent
        self.classifier_agent = EnhancedNewsClassifierAgent(self.llm_client)
        self.stock_analyzer_agent = EnhancedStockAnalyzerAgent(self.llm_client)
        self.advisor_agent = InvestmentAdvisorAgent(self.llm_client)
    
    def analyze_news_with_article(self, article: NewsArticle) -> EnhancedNewsAnalysisResult:
        """
        åˆ†æNewsArticleå¯¹è±¡
        
        Args:
            article: NewsArticleæ¨¡å‹å¯¹è±¡
            
        Returns:
            å¢å¼ºç‰ˆæ–°é—»åˆ†æç»“æœ
        """
        # æ£€æŸ¥æ˜¯å¦åœ¨è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ä¸­
        try:
            loop = asyncio.get_running_loop()
            if loop.is_running():
                # åœ¨è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ä¸­ï¼Œä½¿ç”¨åŒæ­¥è°ƒç”¨å¼‚æ­¥æ–¹æ³•çš„æ–¹å¼
                import concurrent.futures
                
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, self.analyze_news_with_article_async(article))
                    return future.result()
        except RuntimeError:
            # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨asyncio.run
            pass
        
        return asyncio.run(self.analyze_news_with_article_async(article))
    
    async def analyze_news_with_article_async(self, article: NewsArticle) -> EnhancedNewsAnalysisResult:
        """
        åˆ†æNewsArticleå¯¹è±¡ - å¼‚æ­¥ç‰ˆæœ¬
        
        Args:
            article: NewsArticleæ¨¡å‹å¯¹è±¡
            
        Returns:
            å¢å¼ºç‰ˆæ–°é—»åˆ†æç»“æœ
        """
        start_time = datetime.now()
        
        # åˆå§‹åŒ–å…±äº«å­˜å‚¨ï¼Œä¼ å…¥çœŸå®çš„NewsArticleå¯¹è±¡
        shared_store = {
            "article": article,
            "start_time": start_time
        }
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šå¢å¼ºç‰ˆæ–°é—»åˆ†ç±»
            classifier_prep = self.classifier_agent.prep(shared_store)
            classifier_result = await self.classifier_agent._exec_async(classifier_prep)  # ç›´æ¥è°ƒç”¨å¼‚æ­¥æ–¹æ³•
            action = self.classifier_agent.post(shared_store, classifier_prep, classifier_result)
            
            if action == "error":
                raise Exception(f"åˆ†ç±»å¤±è´¥: {shared_store.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            # ç¬¬äºŒæ­¥ï¼šæ ¹æ®åˆ†æç±»å‹æ‰§è¡Œè‚¡ç¥¨åˆ†æ
            if action in ["analyze_stocks", "analyze_industry"]:
                stock_prep = self.stock_analyzer_agent.prep(shared_store)
                stock_result = await self.stock_analyzer_agent._exec_async(stock_prep)  # ç›´æ¥è°ƒç”¨å¼‚æ­¥æ–¹æ³•
                action = self.stock_analyzer_agent.post(shared_store, stock_prep, stock_result)
                
                if action == "error":
                    raise Exception(f"è‚¡ç¥¨åˆ†æå¤±è´¥: {shared_store.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            # ç¬¬ä¸‰æ­¥ï¼šç”ŸæˆæŠ•èµ„å»ºè®®
            if action == "generate_advice":
                advisor_prep = self.advisor_agent.prep(shared_store)
                advisor_result = await self.advisor_agent._exec_async(advisor_prep)  # ç›´æ¥è°ƒç”¨å¼‚æ­¥æ–¹æ³•
                self.advisor_agent.post(shared_store, advisor_prep, advisor_result)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # è®¡ç®—ä¿¡å¿ƒè¯„åˆ†
            confidence_score = self._calculate_confidence_score(shared_store)
            
            # æ„å»ºç»“æœå¯¹è±¡
            result = EnhancedNewsAnalysisResult(
                news_id=str(article.id),
                article=article,
                analysis_type=shared_store.get("analysis_type", "industry_focused"),
                mentioned_stocks=shared_store.get("mentioned_stocks", []),
                classification=shared_store.get("classification", {}),
                industry_analysis=shared_store.get("industry_analysis", {}),
                related_stocks=shared_store.get("related_stocks", []),
                investment_advice=shared_store.get("investment_advice", {}),
                analysis_time=start_time,
                confidence_score=confidence_score,
                processing_time=processing_time
            )
            
            logger.info(f"æ–°é—»åˆ†æå®Œæˆ: {article.id}, è€—æ—¶: {processing_time:.2f}ç§’")
            return result
        
        except Exception as e:
            logger.error(f"æ–°é—»åˆ†ææµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
            # è¿”å›é”™è¯¯ç»“æœ
            return EnhancedNewsAnalysisResult(
                news_id=str(article.id),
                article=article,
                analysis_type="industry_focused",
                mentioned_stocks=[],
                classification={},
                industry_analysis={},
                related_stocks=[],
                investment_advice={"recommendation": "è§‚æœ›", "rationale": f"åˆ†æå¤±è´¥: {str(e)}"},
                analysis_time=start_time,
                confidence_score=0.0,
                processing_time=(datetime.now() - start_time).total_seconds()
            )

    def analyze_news(self, news_content: str, news_id: str = None) -> EnhancedNewsAnalysisResult:
        """
        åˆ†æå•æ¡æ–°é—»å†…å®¹ï¼ˆå‘åå…¼å®¹ï¼‰
        
        Args:
            news_content: æ–°é—»å†…å®¹
            news_id: æ–°é—»IDï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ–°é—»åˆ†æç»“æœ
        """
        # åˆ›å»ºä¸´æ—¶NewsArticleå¯¹è±¡
        temp_article = NewsArticle(
            id=int(news_id) if news_id and news_id.isdigit() else 0,
            title=news_content[:100] + "..." if len(news_content) > 100 else news_content,
            url="",
            url_hash="",
            content=news_content,
            source_id=0,
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
        
        return self.analyze_news_with_article(temp_article)

    def _calculate_confidence_score(self, shared_store: Dict[str, Any]) -> float:
        """è®¡ç®—åˆ†æç»“æœçš„ä¿¡å¿ƒè¯„åˆ†"""
        try:
            # åŸºç¡€åˆ†æ•°
            base_score = 0.5
            
            # åˆ†ç±»è´¨é‡è¯„åˆ†
            classification = shared_store.get("classification", {})
            if classification.get("importance_score", 0) >= 7:
                base_score += 0.2
            
            # è¡Œä¸šåˆ†æè´¨é‡è¯„åˆ†
            industry_analysis = shared_store.get("industry_analysis", {})
            affected_industries = industry_analysis.get("affected_industries", [])
            if len(affected_industries) > 0:
                avg_impact = sum(ind.get("impact_degree", 0) for ind in affected_industries) / len(affected_industries)
                if avg_impact >= 7:
                    base_score += 0.2
            
            # è‚¡ç¥¨å…³è”è´¨é‡è¯„åˆ†
            related_stocks = shared_store.get("related_stocks", [])
            if len(related_stocks) >= 3:
                base_score += 0.1
            
            # æŠ•èµ„å»ºè®®è´¨é‡è¯„åˆ†
            investment_advice = shared_store.get("investment_advice", {})
            advice_confidence = investment_advice.get("confidence_level", 0)
            if advice_confidence >= 7:
                base_score += 0.2
            
            return min(1.0, base_score)
        
        except Exception as e:
            logger.error(f"è®¡ç®—ä¿¡å¿ƒè¯„åˆ†å¤±è´¥: {e}")
            return 0.5

# ä¾¿æ·å‡½æ•°
def analyze_single_news(news_content: str, news_id: str = None) -> EnhancedNewsAnalysisResult:
    """
    å¿«é€Ÿåˆ†æå•æ¡æ–°é—»çš„ä¾¿æ·å‡½æ•°
    
    Args:
        news_content: æ–°é—»å†…å®¹
        news_id: æ–°é—»IDï¼ˆå¯é€‰ï¼‰
    
    Returns:
        æ–°é—»åˆ†æç»“æœ
    """
    # ä¸´æ—¶åˆ›å»ºå®¢æˆ·ç«¯
    qwen_client = QwenLLMClient()
    analysis_flow = NewsAnalysisFlow(qwen_client)
    
    return analysis_flow.analyze_news(news_content, news_id) 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ–°é—»åˆ†ç±»åˆ†æèŠ‚ç‚¹

ä»æ–°é—»å†…å®¹ä¸­åˆ†ç±»æ–°é—»ç±»å‹å¹¶æ£€æµ‹ç›¸å…³è‚¡ç¥¨
"""

import logging
import re
import os
from typing import Dict, Any, List

from dotenv import load_dotenv
from ...interfaces.node_interface import BaseAnalysisNode
from ....handler.ticker_handler import TickerHandler

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class MockTickerHandler:
    """ç”¨äºæµ‹è¯•ç¯å¢ƒçš„Mock TickerHandlerï¼Œé¿å…æ•°æ®åº“è¿æ¥é—®é¢˜"""
    
    def __init__(self):
        logger.info("ğŸ§ª ä½¿ç”¨Mock TickerHandler (æµ‹è¯•æ¨¡å¼)")
    
    async def get_ticker_by_code(self, code: str):
        """Mockæ–¹æ³•ï¼šè¿”å›æ¨¡æ‹Ÿçš„è‚¡ç¥¨ä¿¡æ¯"""
        return None
    
    async def get_ticker_data(self, code: str, days: int = 30):
        """Mockæ–¹æ³•ï¼šè¿”å›ç©ºçš„è¯„åˆ†æ•°æ®"""
        return []


class NewsClassifierNode(BaseAnalysisNode):
    """æ–°é—»åˆ†ç±»å™¨Agent - ä¸»è¦ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ™ºèƒ½åˆ†ç±»"""
    
    def __init__(self, llm_client, test_mode: bool = False):
        super().__init__()
        self.description = "æ–°é—»åˆ†ç±»å’Œè‚¡ç¥¨æ£€æµ‹èŠ‚ç‚¹"
        self.llm_client = llm_client
        
        # ğŸ”§ æ ¹æ®æµ‹è¯•æ¨¡å¼å†³å®šä½¿ç”¨çœŸå®è¿˜æ˜¯Mockçš„TickerHandler
        self.test_mode = test_mode or os.getenv('AI_TEST_MODE', '').lower() in ['true', '1', 'mock']
        
        if self.test_mode:
            self.ticker_handler = MockTickerHandler()
            logger.info("ğŸ§ª AI Agentè¿è¡Œåœ¨æµ‹è¯•æ¨¡å¼ä¸‹")
        else:
            try:
                self.ticker_handler = TickerHandler()
                logger.info("ğŸš€ AI Agentä½¿ç”¨çœŸå®æ•°æ®åº“è¿æ¥")
            except Exception as e:
                logger.warning(f"âš ï¸ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°æµ‹è¯•æ¨¡å¼: {e}")
                self.ticker_handler = MockTickerHandler()
                self.test_mode = True
        
        # ğŸ”¥ ç®€åŒ–çš„è‚¡ç¥¨æ£€æµ‹æ­£åˆ™ - åªä¿ç•™æœ€å¯é çš„æ¨¡å¼
        self.stock_code_patterns = [
            # ä¸­æ–‡å…¬å¸å+ä»£ç æ ¼å¼ï¼ˆæœ€å¯é ï¼‰
            r'([\\u4e00-\\u9fa5A-Za-z&]{2,20})[ï¼ˆ\\(](\\d{5,6})[ï¼‰\\)]',
            # è‹±æ–‡å…¬å¸å+ä»£ç æ ¼å¼
            r'([A-Za-z&\\s]{3,20})[ï¼ˆ\\(](\\d{5,6})[ï¼‰\\)]',
        ]
    
    def analyze(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ–°é—»åˆ†ç±»åˆ†æ"""
        return self.work(input_data)
    
    def prep(self, shared_store: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡åˆ†ç±»æ‰€éœ€çš„æ•°æ®"""
        article = shared_store.get("article")
        if not article:
            return {}
        
        # è·å–æ–‡ç« å†…å®¹
        content = article.get_analysis_content()
        
        return {
            "title": article.title,
            "content": content or "",
            "article": article
        }
    
    def work(self, prepared_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ–°é—»åˆ†ç±» - ä¸»è¦ä½¿ç”¨å¤§æ¨¡å‹"""
        title = prepared_data.get("title", "")
        content = prepared_data.get("content", "")
        article = prepared_data.get("article")
        
        # 1. ğŸ¯ ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ–°é—»åˆ†ç±»å’Œè‚¡ç¥¨æ£€æµ‹
        llm_result = self._classify_with_llm(title, content)
        
        # 2. ğŸ” ç®€å•çš„è‚¡ç¥¨ä»£ç æå–ä½œä¸ºè¡¥å……
        detected_stocks = self._extract_stock_codes(title + " " + content)
        
        # 3. ğŸ“Š æ•´åˆåˆ†æç»“æœ
        analysis_type = llm_result.get("analysis_type", "industry_focused")
        confidence = llm_result.get("confidence", 0.8)
        llm_stocks = llm_result.get("mentioned_stocks", [])
        
        # åˆå¹¶LLMæ£€æµ‹å’Œæ­£åˆ™æ£€æµ‹çš„è‚¡ç¥¨
        all_stocks = self._merge_stock_results(llm_stocks, detected_stocks)
        
        logger.info(f"ğŸ“Š LLMåˆ†æè·¯å¾„å†³ç­–: {analysis_type} | ç†ç”±: {llm_result.get('reason', 'å¤§æ¨¡å‹åˆ†æ')}, æ£€æµ‹åˆ°{len(all_stocks)}åªè‚¡ç¥¨")
        
        return {
            "analysis_type": analysis_type,
            "confidence": confidence,
            "mentioned_stocks": all_stocks,
            "llm_reason": llm_result.get("reason", ""),
            "title": title,
            "content": content
        }
    
    def _classify_with_llm(self, title: str, content: str) -> Dict[str, Any]:
        """ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ–°é—»åˆ†ç±»å’Œè‚¡ç¥¨æ£€æµ‹"""
        
        # æ„å»ºåˆ†ç±»æç¤ºè¯
        analysis_prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–°é—»å†…å®¹ï¼Œåˆ¤æ–­å…¶ç±»å‹å¹¶æå–è‚¡ç¥¨ä¿¡æ¯ï¼š

æ ‡é¢˜ï¼š{title}
å†…å®¹ï¼š{content[:1000]}...

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¿”å›JSONç»“æœï¼š
{{
    "analysis_type": "stock_specific" æˆ– "industry_focused",
    "confidence": 0.0-1.0ä¹‹é—´çš„ç½®ä¿¡åº¦,
    "reason": "åˆ¤æ–­ç†ç”±",
    "mentioned_stocks": [
        {{"name": "è‚¡ç¥¨åç§°", "code": "è‚¡ç¥¨ä»£ç "}}
    ]
}}

åˆ†ç±»æ ‡å‡†ï¼š
- stock_specific: æ˜ç¡®æåŠå…·ä½“è‚¡ç¥¨åç§°å’Œä»£ç çš„æ–°é—»
- industry_focused: ä¸»è¦è®¨è®ºè¡Œä¸šã€ä¸»é¢˜ã€æ”¿ç­–ç­‰çš„æ–°é—»

è¯·é‡ç‚¹å…³æ³¨æ ‡é¢˜å’Œå†…å®¹ä¸­æ˜¯å¦åŒ…å«"å…¬å¸å(ä»£ç )"æ ¼å¼çš„è‚¡ç¥¨ä¿¡æ¯ã€‚"""

        try:
            # ğŸ”¥ ä½¿ç”¨æ­£ç¡®çš„åŒæ­¥è°ƒç”¨æ–¹æ³•
            response = self.llm_client.chat_completions_create(
                messages=[{"role": "user", "content": analysis_prompt}],
                temperature=0.3,
                max_tokens=300
            )
            
            # è§£æLLMå“åº”
            response_text = response.content.strip()
            logger.info(f"ğŸ” LLMåŸå§‹å“åº”: {response_text[:200]}...")  # è°ƒè¯•æ—¥å¿—
            
            # å°è¯•è§£æJSON
            import json
            import re
            
            # ğŸ”¥ å…ˆå»é™¤markdownä»£ç å—åŒ…è£…
            cleaned_text = response_text
            # ç§»é™¤```jsonå¼€å¤´å’Œ```ç»“å°¾
            cleaned_text = re.sub(r'^```json\s*', '', cleaned_text, flags=re.IGNORECASE)
            cleaned_text = re.sub(r'\s*```$', '', cleaned_text)
            
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', cleaned_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                logger.info(f"ğŸ” æå–çš„JSON: {json_str[:200]}...")  # è°ƒè¯•æ—¥å¿—
                result = json.loads(json_str)
                
                # éªŒè¯å’Œæ ‡å‡†åŒ–ç»“æœ
                return {
                    "analysis_type": result.get("analysis_type", "industry_focused"),
                    "confidence": max(0.0, min(1.0, float(result.get("confidence", 0.8)))),
                    "reason": result.get("reason", "LLMåˆ†æ"),
                    "mentioned_stocks": result.get("mentioned_stocks", [])
                }
            else:
                logger.warning(f"LLMè¿”å›ç»“æœæ— æ³•è§£æä¸ºJSONï¼ŒåŸå§‹å†…å®¹: {response_text[:500]}")
                return self._get_default_classification()
                
        except Exception as e:
            logger.error(f"LLMåˆ†ç±»å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤åˆ†ç±»")
            return self._get_default_classification()
    
    def _extract_stock_codes(self, text: str) -> List[Dict[str, Any]]:
        """ç®€åŒ–çš„è‚¡ç¥¨ä»£ç æå–"""
        stocks = []
        
        for pattern in self.stock_code_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if len(match) == 2:  # (name, code)
                    name, code = match
                    stocks.append({
                        "name": name.strip(),
                        "code": code.strip(),
                        "source": "regex"
                    })
        
        # å»é‡
        seen_codes = set()
        unique_stocks = []
        for stock in stocks:
            if stock["code"] not in seen_codes:
                seen_codes.add(stock["code"])
                unique_stocks.append(stock)
        
        return unique_stocks
    
    def _merge_stock_results(self, llm_stocks: List[Dict], regex_stocks: List[Dict]) -> List[Dict[str, Any]]:
        """åˆå¹¶LLMå’Œæ­£åˆ™æ£€æµ‹çš„è‚¡ç¥¨ç»“æœ"""
        merged = {}
        
        # æ·»åŠ LLMæ£€æµ‹çš„è‚¡ç¥¨
        for stock in llm_stocks:
            code = stock.get("code", "").strip()
            if code:
                merged[code] = {
                    "name": stock.get("name", "").strip(),
                    "code": code,
                    "source": "llm"
                }
        
        # æ·»åŠ æ­£åˆ™æ£€æµ‹çš„è‚¡ç¥¨ï¼ˆå¦‚æœLLMæ²¡æœ‰æ£€æµ‹åˆ°ï¼‰
        for stock in regex_stocks:
            code = stock.get("code", "").strip()
            if code and code not in merged:
                merged[code] = stock
        
        return list(merged.values())
    
    def _get_default_classification(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤åˆ†ç±»ç»“æœ"""
        return {
            "analysis_type": "industry_focused",
            "confidence": 0.7,
            "reason": "é»˜è®¤åˆ†ç±»ï¼ˆLLMåˆ†æå¤±è´¥ï¼‰",
            "mentioned_stocks": []
        }
    
    def post(self, shared_store: Dict[str, Any], prep_data: Dict[str, Any], exec_result: Dict[str, Any]) -> str:
        """åå¤„ç†ï¼šå°†åˆ†ç±»ç»“æœå­˜å‚¨åˆ°å…±äº«å­˜å‚¨å¹¶å†³å®šä¸‹ä¸€æ­¥åŠ¨ä½œ"""
        # å°†åˆ†ç±»ç»“æœä¿å­˜åˆ°å…±äº«å­˜å‚¨
        shared_store.update({
            "analysis_type": exec_result.get("analysis_type", "industry_focused"),
            "confidence": exec_result.get("confidence", 0.8),
            "mentioned_stocks": exec_result.get("mentioned_stocks", []),
            "llm_reason": exec_result.get("llm_reason", ""),
            "classification": {
                "analysis_type": exec_result.get("analysis_type", "industry_focused"),
                "confidence": exec_result.get("confidence", 0.8),
                "reason": exec_result.get("llm_reason", "")
            }
        })
        
        # å†³å®šä¸‹ä¸€æ­¥åŠ¨ä½œ
        analysis_type = exec_result.get("analysis_type", "industry_focused")
        if analysis_type == "stock_specific":
            return "analyze_stocks"
        else:
            return "analyze_industry" 
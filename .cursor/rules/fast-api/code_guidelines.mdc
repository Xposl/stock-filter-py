---
description: 
globs: 
alwaysApply: true
---
# FastAPI 编码规范

## 概述

本文档为当前基于fastApi项目提供了一套编码规范和最佳实践，基于项目的三层架构（API-Handler-Repository-Model）和业务特点，旨在确保代码的一致性、可读性和可维护性。

## 通用编码风格

- **PEP 8**: 遵循 [PEP 8 -- Style Guide for Python Code](mdc:https:/www.python.org/dev/peps/pep-0008)。
- **Linters 和 Formatters**: 推荐使用 `Flake8` (或 `Pylint`) 进行代码风格检查，使用 `Black` 和 `isort` 进行代码格式化和导入排序。
    - **配置示例 (`pyproject.toml` for Black and isort):**
      ```toml
      [tool.black]
      line-length = 88
      target-version = ['py38', 'py39', 'py310', 'py311'] # 根据项目 Python 版本调整

      [tool.isort]
      profile = "black"
      line_length = 88
      ```
- **类型提示**: 强制使用类型提示 (Type Hinting)，并使用 `mypy`进行静态类型检查。
    - **示例:**
      ```python
      from fastapi import FastAPI
      from pydantic import BaseModel

      app = FastAPI()

      class Item(BaseModel):
          name: str
          price: float
          is_offer: bool | None = None

      @app.post("/items/")
      async def create_item(item: Item) -> Item:
          return item
      ```
- **命名约定**:
    - **变量和函数名**: `snake_case` (例如: `ticker_id`, `get_ticker_details`)
    - **类名**: `PascalCase` (例如: `TickerRepository`, `NewsAggregator`)
    - **常量**: `UPPER_SNAKE_CASE` (例如: `MAX_ARTICLES_PER_FETCH`)
    - **模块和包名**: `snake_case` (例如: `news_aggregator`, `ticker_handler`)
- **文档字符串 (Docstrings)**: 为所有公共模块、函数、类和方法编写清晰的文档字符串。推荐使用 Google 风格或 reStructuredText 风格。
    - **示例 (Google 风格):**
      ```python
      async def get_item_by_id(item_id: int, db: Session) -> models.Item | None:
          """Fetches an item by its ID from the database.

          Args:
              item_id: The ID of the item to fetch.
              db: The database session.

          Returns:
              The item object if found, otherwise None.
          """
          return db.query(models.Item).filter(models.Item.id == item_id).first()
      ```
- **注释**: 只为复杂或不明显的代码段添加注释。代码本身应尽可能自解释。

## 定架构规范

### 1. **API层规范** (`api/`)

#### 主应用程序 ([api.py](mdc:api/api.py))
```python
from fastapi import FastAPI, HTTPException, Depends
from typing import Dict, Any
from core.auth.auth_middleware import auth_required
from .routers import ticker, news, scheduler

app = FastAPI(
    title="InvestNote API",
    description="Investment notes and analysis API",
    root_path="/investnote"
)

# 注册路由模块
app.include_router(ticker.router)
app.include_router(news.router)
app.include_router(scheduler.router)

@app.get("/")
async def root():
    return {"message": "InvestNote API Service"}
```

#### 路由模块定义 ([routers/ticker.py](mdc:api/routers/ticker.py))
```python
from fastapi import APIRouter, HTTPException, Depends
from typing import Optional, Dict, Any
from core.data_source_helper import DataSourceHelper
from ..models import PageRequest

# 创建路由器
router = APIRouter(tags=["股票"])

@router.post("/pages")
async def get_ticker_pages(request: PageRequest):
    """获取股票列表，支持分页、搜索和排序"""
    try:
        # 业务逻辑处理
        return {"status": "success", "data": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

#### API层模块化规范
- **主应用**: 只包含基础路由、中间件、路由注册
- **路由模块**: 按功能拆分，使用APIRouter创建
- **标签组织**: 每个路由器设置合适的tags便于文档分类
- **路径保持**: 拆分后保持原有API端点路径不变
- **依赖共享**: 共享的依赖和模型定义
- **异常处理**: 统一的错误处理模式

#### 路由模块文件结构
- **[ticker.py](mdc:api/routers/ticker.py)**: 股票数据相关路由
- **[news.py](mdc:api/routers/news.py)**: 新闻聚合相关路由  
- **[scheduler.py](mdc:api/routers/scheduler.py)**: 定时任务相关路由

### 2. **Handler层规范** (`core/handler/`)

#### Handler类定义
```python
# core/handler/ticker_analysis_handler.py
from typing import Dict, List, Optional, Any
from ..service.ticker_repository import TickerRepository
from ..service.ticker_score_repository import TickerScoreRepository
from ..models.ticker import Ticker

class TickerAnalysisHandler:
    """股票分析处理器 - 协调多个Repository执行复杂业务逻辑"""
    
    def __init__(self):
        self.ticker_repo = TickerRepository()
        self.score_repo = TickerScoreRepository()
    
    async def analyze_ticker_performance(
        self, 
        ticker_code: str, 
        analysis_days: int = 30
    ) -> Dict[str, Any]:
        """分析股票表现 - 业务逻辑协调多个数据源"""
        
        # 1. 获取基础数据
        ticker = await self.ticker_repo.get_by_code(ticker_code)
        if not ticker:
            raise ValueError(f"股票代码 {ticker_code} 不存在")
        
        # 2. 获取评分历史
        score_history = await self.score_repo.get_score_history(
            ticker.id, days=analysis_days
        )
        
        # 3. 执行业务逻辑计算
        performance_metrics = self._calculate_performance_metrics(
            ticker, score_history
        )
        
        return {
            "ticker": ticker,
            "metrics": performance_metrics,
            "analysis_period": analysis_days
        }
    
    def _calculate_performance_metrics(
        self, 
        ticker: Ticker, 
        score_history: List[Dict]
    ) -> Dict[str, float]:
        """私有方法 - 计算性能指标"""
        # 具体业务逻辑实现
        return {
            "avg_score": sum(s["score"] for s in score_history) / len(score_history),
            "score_trend": self._calculate_trend(score_history),
            "volatility": self._calculate_volatility(score_history)
        }
```

#### Handler层责任
- 封装业务逻辑和业务规则
- 协调多个Repository执行复杂操作
- 数据转换和业务计算
- 业务异常处理
- **禁止**: 直接数据库操作或SQL查询

### 3. **Repository层规范** (`core/service/`)

#### Repository类定义
```python
# core/service/ticker_repository.py
import copy
import logging
import os
from typing import List, Dict, Any, Optional, Union
from datetime import datetime

from core.database.db_adapter import DbAdapter
from core.models.ticker import Ticker, TickerCreate, TickerUpdate, ticker_to_dict, dict_to_ticker
from core.enum.ticker_group import get_group_id_by_code

# 配置日志
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 获取占位符类型
DB_TYPE = os.getenv('DB_TYPE', 'sqlite').lower()
# SQLite 使用 ? 占位符，其他数据库使用 %s
PLACEHOLDER = '?' if DB_TYPE == 'sqlite' else '%s'

class TickerRepository:
    """
    使用Pydantic模型的Ticker仓库类
    """
    table = 'ticker'

    def __init__(self, db_connection: Optional[Any] = None):
        """
        初始化Ticker仓库
        
        Args:
            db_connection: 可选的数据库连接，如果未提供将使用DbAdapter创建新连接
        """
        if db_connection:
            self.db = db_connection
        else:
            self.db = DbAdapter()
    
    def get_by_code(self, code: str) -> Optional[Ticker]:
        """
        根据股票代码获取股票信息
        
        Args:
            code: 股票代码
            
        Returns:
            Ticker对象或None
        """
        try:
            sql = f"SELECT * FROM {self.table} WHERE code = {PLACEHOLDER}"
            result = self.db.query_one(sql, (code,))
            if result:
                return dict_to_ticker(result)
            return None
        except Exception as e:
            logger.error(f"获取股票信息错误: {e}")
            return None
```

#### Repository层责任
- 封装所有数据库操作
- 提供CRUD方法和复杂查询
- 数据库事务管理
- 查询优化和缓存
- **禁止**: 包含业务逻辑或业务规则

### 4. **Model层规范** (`core/models/`)

#### Pydantic模型定义 (推荐方式)
```python
# core/models/ticker.py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from datetime import datetime
from typing import Optional, Union
from pydantic import BaseModel, Field, ConfigDict

class TickerBase(BaseModel):
    """Ticker基础模型，包含共有字段"""
    code: str = Field(..., description="股票代码")
    name: str = Field(..., description="股票名称")
    group_id: int = Field(default=0, description="组ID")
    type: Optional[int] = Field(default=1, description="类型")
    source: Optional[int] = Field(default=1, description="数据来源")
    status: Optional[int] = Field(default=1, description="状态")
    is_deleted: Optional[bool] = Field(default=False, description="是否删除")
    remark: Optional[str] = Field(default=None, description="备注信息")
    
    model_config = ConfigDict(from_attributes=True)

class TickerCreate(TickerBase):
    """用于创建Ticker的模型"""
    pass

class TickerUpdate(BaseModel):
    """用于更新Ticker的模型，所有字段都是可选的"""
    name: Optional[str] = Field(default=None, description="股票名称")
    group_id: Optional[int] = Field(default=None, description="组ID")
    status: Optional[int] = Field(default=None, description="状态")
    remark: Optional[str] = Field(default=None, description="备注信息")
    
    model_config = ConfigDict(from_attributes=True)

class Ticker(TickerBase):
    """完整的Ticker模型，包含ID"""
    id: int = Field(..., description="ID")
    create_time: Optional[datetime] = Field(default_factory=datetime.now, description="创建时间")
    version: Optional[int] = Field(default=1, description="版本号")
    
    model_config = ConfigDict(from_attributes=True)

# 用于序列化和反序列化的辅助函数
def ticker_to_dict(ticker: Union[Ticker, TickerCreate, TickerUpdate]) -> dict:
    """将Ticker模型转换为字典，用于数据库操作"""
    if isinstance(ticker, (TickerCreate, TickerUpdate)):
        return ticker.model_dump(exclude_unset=True, exclude_none=True)
    else:
        return ticker.model_dump(exclude_none=True)

def dict_to_ticker(data: dict) -> Ticker:
    """将字典转换为Ticker模型，处理各种数据类型转换和默认值"""
    # 数据类型处理和验证逻辑
    processed_data = data.copy()
    
    # 处理日期字段
    for date_field in ['create_time']:
        if date_field in processed_data and isinstance(processed_data[date_field], str):
            try:
                processed_data[date_field] = datetime.fromisoformat(processed_data[date_field])
            except ValueError:
                processed_data[date_field] = datetime.now()
    
    return Ticker(**processed_data)
```

#### 新闻模型定义示例
```python
# core/models/news_article.py
from datetime import datetime
from typing import Optional, List, Dict, Any
from pydantic import BaseModel, Field, ConfigDict
from enum import Enum

class ArticleStatus(str, Enum):
    """文章状态枚举"""
    PENDING = "pending"
    PROCESSING = "processing"
    PROCESSED = "processed"
    FAILED = "failed"
    ARCHIVED = "archived"

class NewsArticleBase(BaseModel):
    """新闻文章基础模型"""
    title: str = Field(..., description="文章标题")
    url: str = Field(..., description="文章URL")
    url_hash: str = Field(..., description="URL哈希（去重用）")
    content: Optional[str] = Field(default=None, description="文章正文内容")
    source_id: int = Field(..., description="新闻源ID")
    status: ArticleStatus = Field(default=ArticleStatus.PENDING, description="处理状态")
    
    model_config = ConfigDict(from_attributes=True)

class NewsArticleCreate(NewsArticleBase):
    """用于创建新闻文章的模型"""
    pass

class NewsArticle(NewsArticleBase):
    """完整的新闻文章模型"""
    id: int = Field(..., description="ID")
    created_at: Optional[datetime] = Field(default_factory=datetime.now, description="创建时间")
    updated_at: Optional[datetime] = Field(default_factory=datetime.now, description="更新时间")
    
    model_config = ConfigDict(from_attributes=True)
```

#### Model层架构要求

1. **统一使用Pydantic模型**: 项目中所有模型都必须使用Pydantic BaseModel，不再使用SQLAlchemy模型
2. **三层模型结构**: 
   - `XxxBase`: 包含共有字段的基础模型
   - `XxxCreate`: 用于创建操作的模型
   - `XxxUpdate`: 用于更新操作的模型，所有字段可选
   - `Xxx`: 完整模型，包含ID和时间戳
3. **辅助函数**: 每个模型文件必须包含 `xxx_to_dict()` 和 `dict_to_xxx()` 函数
4. **数据验证**: 使用Field进行字段验证和描述
5. **配置**: 使用 `ConfigDict(from_attributes=True)` 支持ORM对象转换

#### 数据库表更新要求

每次新增或修改模型时，必须同时更新对应的SQL建表脚本：
- `sql/create_table_sqlite.sql` - SQLite版本
- `sql/create_table.sql` - MySQL版本

#### Repository层与模型的配合

Repository层负责：
- 使用辅助函数进行模型与字典的转换
- 处理数据库字段到Pydantic模型的映射
- 执行所有CRUD操作

### 5. **新闻聚合模块规范** (`core/news_aggregator/`)

#### 新闻聚合器实现
```python
# core/news_aggregator/rss_aggregator.py
import asyncio
import aiohttp
from typing import List, Dict, Optional, Any
from ..models.news_source import NewsSource
from ..models.news_article import NewsArticle

class RSSAggregator:
    """RSS新闻聚合器 - 处理RSS源数据抓取"""
    
    def __init__(self, session: Optional[aiohttp.ClientSession] = None):
        self.session = session
        self._own_session = session is None
    
    async def __aenter__(self):
        if self._own_session:
            self.session = aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=30),
                headers={'User-Agent': 'InvestNote RSS Aggregator 1.0'}
            )
        return self
    
    async def fetch_rss_feed(self, news_source: NewsSource) -> List[Dict[str, Any]]:
        """抓取RSS源数据
        
        Args:
            news_source: 新闻源配置
            
        Returns:
            解析后的文章数据列表
            
        Raises:
            ValueError: RSS内容获取失败
            Exception: 解析异常
        """
        try:
            # 实现RSS抓取逻辑
            pass
        except Exception as e:
            logger.error(f"RSS抓取失败 {news_source.name}: {e}")
            raise
```

### 6. **AI代理模块规范** (`core/ai_agents/`)

#### AI代理基类
```python
# core/ai_agents/base_agent.py
from abc import ABC, abstractmethod
from typing import Dict, Any, List
from ..models.news_article import NewsArticle

class BaseAgent(ABC):
    """AI代理基类 - 定义所有代理的通用接口"""
    
    def __init__(self, agent_name: str, config: Dict[str, Any]):
        self.agent_name = agent_name
        self.config = config
    
    @abstractmethod
    async def analyze(self, articles: List[NewsArticle]) -> Dict[str, Any]:
        """分析新闻文章
        
        Args:
            articles: 待分析的新闻文章列表
            
        Returns:
            分析结果字典
        """
        pass
    
    @abstractmethod
    async def extract_insights(self, analysis_result: Dict[str, Any]) -> List[str]:
        """提取投资洞察
        
        Args:
            analysis_result: 分析结果
            
        Returns:
            投资洞察列表
        """
        pass
```

## 异步编程规范

### 1. **异步函数定义**
```python
# 正确：数据库操作使用异步
async def get_ticker_data(ticker_id: int) -> Optional[Ticker]:
    async with get_async_session() as session:
        result = await session.execute(
            select(Ticker).where(Ticker.id == ticker_id)
        )
        return result.scalar_one_or_none()

# 正确：外部API调用使用异步
async def fetch_news_from_api(url: str) -> Dict[str, Any]:
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            return await response.json()
```

### 2. **异步上下文管理器**
```python
# 推荐：使用异步上下文管理器管理资源
class NewsAggregator:
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.session.close()

# 使用方式
async with NewsAggregator() as aggregator:
    articles = await aggregator.fetch_articles()
```

### 3. **并发处理**
```python
# 推荐：使用asyncio.gather处理并发任务
async def fetch_multiple_sources(sources: List[NewsSource]) -> List[Dict]:
    tasks = [
        fetch_rss_feed(source) for source in sources
    ]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # 处理异常
    valid_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            logger.error(f"Source {sources[i].name} failed: {result}")
        else:
            valid_results.extend(result)
    
    return valid_results
```

## 错误处理和日志规范

### 1. **异常处理**
```python
# 推荐：分层异常处理
from fastapi import HTTPException
import logging

logger = logging.getLogger(__name__)

# Repository层：记录并重新抛出
async def get_ticker_by_id(ticker_id: int) -> Optional[Ticker]:
    try:
        # 数据库操作
        return ticker
    except DatabaseError as e:
        logger.error(f"Database error in get_ticker_by_id: {e}")
        raise

# Handler层：业务异常处理
async def process_ticker_analysis(ticker_id: int) -> Dict[str, Any]:
    try:
        ticker = await self.ticker_repo.get_ticker_by_id(ticker_id)
        if not ticker:
            raise ValueError(f"Ticker {ticker_id} not found")
        return analysis_result
    except ValueError as e:
        logger.warning(f"Business logic error: {e}")
        raise
    except Exception as e:
        logger.error(f"Unexpected error in ticker analysis: {e}")
        raise

# API层：HTTP异常处理
@app.get("/ticker/{ticker_id}")
async def get_ticker_analysis(ticker_id: int):
    try:
        result = await ticker_handler.process_ticker_analysis(ticker_id)
        return {"status": "success", "data": result}
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        logger.error(f"API error: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")
```

### 2. **日志规范**
```python
import logging

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# 日志使用示例
class TickerHandler:
    async def update_ticker_data(self, ticker_id: int, data: Dict):
        logger.info(f"开始更新股票数据: ticker_id={ticker_id}")
        
        try:
            result = await self.repository.update(ticker_id, data)
            logger.info(f"股票数据更新成功: ticker_id={ticker_id}")
            return result
        except Exception as e:
            logger.error(f"股票数据更新失败: ticker_id={ticker_id}, error={e}")
            raise
```

## 测试规范

### 1. **单元测试**
```python
# tests/test_ticker_handler.py
import pytest
from unittest.mock import AsyncMock, patch
from core.handler.ticker_handler import TickerHandler
from core.models.ticker import Ticker

class TestTickerHandler:
    @pytest.fixture
    async def ticker_handler(self):
        return TickerHandler()
    
    @pytest.fixture
    def sample_ticker(self):
        return Ticker(
            id=1,
            code="AAPL",
            name="Apple Inc.",
            status=1
        )
    
    @patch('core.service.ticker_repository.TickerRepository.get_by_id')
    async def test_get_ticker_success(self, mock_get_by_id, ticker_handler, sample_ticker):
        # Arrange
        mock_get_by_id.return_value = sample_ticker
        
        # Act
        result = await ticker_handler.get_ticker_by_id(1)
        
        # Assert
        assert result == sample_ticker
        mock_get_by_id.assert_called_once_with(1)
    
    async def test_get_ticker_not_found(self, ticker_handler):
        with patch.object(ticker_handler.repository, 'get_by_id', return_value=None):
            result = await ticker_handler.get_ticker_by_id(999)
            assert result is None
```

### 2. **集成测试**
```python
# tests/test_integration_news.py
import pytest
from httpx import AsyncClient
from main import app

@pytest.mark.asyncio
async def test_news_aggregation_flow():
    async with AsyncClient(app=app, base_url="http://test") as ac:
        # 1. 创建新闻源
        source_data = {
            "name": "Test RSS Source",
            "source_type": "rss",
            "url": "https://example.com/rss.xml"
        }
        response = await ac.post("/news/sources", json=source_data)
        assert response.status_code == 201
        source_id = response.json()["data"]["id"]
        
        # 2. 触发新闻抓取
        response = await ac.post(f"/news/sources/{source_id}/fetch")
        assert response.status_code == 200
        
        # 3. 验证文章创建
        response = await ac.get(f"/news/articles?source_id={source_id}")
        assert response.status_code == 200
        assert len(response.json()["data"]) > 0
```

## 性能优化规范

### 1. **数据库查询优化**
```python
# 推荐：使用索引和适当的查询条件
async def get_recent_high_score_tickers(days: int = 7, min_score: float = 8.0):
    # 确保相关字段有索引
    sql = """
    SELECT t.*, ts.score 
    FROM ticker t 
    JOIN ticker_score ts ON t.id = ts.ticker_id 
    WHERE ts.create_time >= DATE_SUB(NOW(), INTERVAL :days DAY)
    AND ts.score >= :min_score
    AND t.status = 1
    ORDER BY ts.score DESC
    LIMIT 100
    """
    return await self.db_helper.fetch_all(sql, {
        "days": days, 
        "min_score": min_score
    })

# 避免：N+1查询问题
# 错误示例 - 会产生N+1查询
async def get_tickers_with_scores_bad():
    tickers = await self.get_all_tickers()  # 1次查询
    results = []
    for ticker in tickers:
        score = await self.get_ticker_score(ticker.id)  # N次查询
        results.append({"ticker": ticker, "score": score})
    return results

# 正确示例 - 使用JOIN一次查询
async def get_tickers_with_scores_good():
    sql = """
    SELECT t.*, ts.score 
    FROM ticker t 
    LEFT JOIN ticker_score ts ON t.id = ts.ticker_id
    WHERE t.status = 1
    """
    return await self.db_helper.fetch_all(sql)
```

### 2. **缓存策略**
```python
from functools import wraps
import asyncio
from typing import Dict, Any

# 简单内存缓存装饰器
def cache_result(ttl: int = 300):
    cache: Dict[str, Any] = {}
    
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # 生成缓存键
            cache_key = f"{func.__name__}:{hash(str(args) + str(kwargs))}"
            
            # 检查缓存
            if cache_key in cache:
                result, timestamp = cache[cache_key]
                if time.time() - timestamp < ttl:
                    return result
            
            # 执行函数并缓存结果
            result = await func(*args, **kwargs)
            cache[cache_key] = (result, time.time())
            return result
        return wrapper
    return decorator

# 使用示例
class NewsHandler:
    @cache_result(ttl=600)  # 缓存10分钟
    async def get_trending_topics(self) -> List[str]:
        # 复杂的数据处理逻辑
        return trending_topics
```

## 安全规范

### 1. **输入验证**
```python
from pydantic import BaseModel, Field, validator

class CreateTickerRequest(BaseModel):
    code: str = Field(..., min_length=1, max_length=20, regex=r'^[A-Z0-9]+$')
    name: str = Field(..., min_length=1, max_length=255)
    market: str = Field(..., regex=r'^(US|HK|CN)$')
    
    @validator('code')
    def validate_code(cls, v):
        if not v.isalnum():
            raise ValueError('股票代码只能包含字母和数字')
        return v.upper()
```

### 2. **敏感信息处理**
```python
import os
from typing import Optional

class Config:
    """配置管理类 - 敏感信息从环境变量读取"""
    
    DATABASE_URL: str = os.getenv('DATABASE_URL', 'sqlite:///./investnote.db')
    API_KEYS: Dict[str, str] = {
        'news_api': os.getenv('NEWS_API_KEY', ''),
        'stock_api': os.getenv('STOCK_API_KEY', '')
    }
    
    # 不要在代码中硬编码敏感信息
    @classmethod
    def get_api_key(cls, service: str) -> Optional[str]:
        return cls.API_KEYS.get(service)
```

## 部署和运维规范

### 1. **健康检查端点**
```python
@app.get("/health")
async def health_check():
    """系统健康检查"""
    try:
        # 检查数据库连接
        await check_database_connection()
        
        # 检查其他关键服务
        services_status = {
            "database": "healthy",
            "redis": "healthy" if await check_redis() else "unhealthy",
            "external_apis": "healthy" if await check_external_apis() else "degraded"
        }
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "services": services_status
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }
```

### 2. **监控和指标**
```python
from prometheus_client import Counter, Histogram, start_http_server
import time

# 定义指标
REQUEST_COUNT = Counter('http_requests_total', 'HTTP请求总数', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP请求耗时')

# 中间件示例
@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    start_time = time.time()
    
    response = await call_next(request)
    
    # 记录指标
    REQUEST_COUNT.labels(
        method=request.method,
        endpoint=request.url.path
    ).inc()
    
    REQUEST_DURATION.observe(time.time() - start_time)
    
    return response
```

## 代码审查清单

在进行代码审查时，请确保检查以下项目：

### 功能性
- [ ] 代码是否实现了需求规格说明中的所有功能？
- [ ] 是否有适当的错误处理？
- [ ] 是否遵循了项目的架构分层原则？

### 代码质量
- [ ] 是否遵循了PEP 8代码风格？
- [ ] 是否有适当的类型提示？
- [ ] 是否有清晰的文档字符串？
- [ ] 变量和函数命名是否有意义？

### 性能
- [ ] 是否避免了N+1查询问题？
- [ ] 是否适当使用了异步编程？
- [ ] 是否有不必要的数据库查询？

### 安全性
- [ ] 是否对用户输入进行了验证？
- [ ] 是否避免了SQL注入风险？
- [ ] 敏感信息是否得到了适当保护？

### 测试
- [ ] 是否有适当的单元测试？
- [ ] 测试覆盖率是否达到要求？
- [ ] 是否包含了边界条件测试？

### 维护性
- [ ] 代码是否易于理解和修改？
- [ ] 是否遵循了DRY（Don't Repeat Yourself）原则？
- [ ] 是否有适当的注释？

通过遵循这些规范，我们可以确保 InvestNote-py 项目的代码质量、性能和可维护性。

## 项目架构规范

### 三层架构模式

本项目采用标准的三层架构模式：

```
Handler (业务逻辑层) -> Repository (数据访问层) -> Database (数据库层)
```

#### Handler层规范

**构造函数模式：**
```python
class ExampleHandler:
    """示例处理器"""
    
    def __init__(self):
        """
        初始化处理器
        """
        self.repository = ExampleRepository()
```

**关键原则：**
- Handler直接初始化Repository，不使用依赖注入
- Handler负责业务逻辑协调，不直接操作数据库
- 所有数据库操作通过Repository进行
- Handler方法应该是async的，支持异步操作

#### Repository层规范

**构造函数模式：**
```python
class ExampleRepository:
    """示例数据访问类"""
    
    def __init__(self):
        """
        初始化仓库
        """
        self.db = DbAdapter()
```

**关键原则：**
- Repository直接初始化DbAdapter
- 所有SQL操作使用`:name`占位符格式（DbAdapter会自动转换）
- Repository负责数据的CRUD操作和简单的数据转换
- 使用模型的辅助函数进行数据转换：`xxx_to_dict()` 和 `dict_to_xxx()`

### 数据库操作规范

#### SQL占位符格式

**统一使用`:name`格式：**
```python
sql = "SELECT * FROM table WHERE id = :id AND name = :name"
params = {"id": 123, "name": "example"}
self.db.execute(sql, params)
```

**DbAdapter会自动转换：**
- SQLite: 保持`:name`格式
- MySQL: 转换为`%(name)s`格式
- PostgreSQL: 转换为`%(name)s`格式

#### 事务处理

```python
try:
    self.db.execute(sql, params)
    self.db.commit()
    return result
except Exception as e:
    logger.error(f"操作失败: {e}")
    self.db.rollback()
    return None
```

## Pydantic模型规范

### 模型结构

每个实体应该定义四个模型类：

```python
class EntityBase(BaseModel):
    """基础模型，包含共有字段"""
    name: str = Field(..., description="名称")
    # ... 其他字段
    
    model_config = ConfigDict(from_attributes=True)

class EntityCreate(EntityBase):
    """用于创建的模型"""
    pass

class EntityUpdate(BaseModel):
    """用于更新的模型，所有字段都是可选的"""
    name: Optional[str] = Field(default=None, description="名称")
    # ... 其他字段
    
    model_config = ConfigDict(from_attributes=True)

class Entity(EntityBase):
    """完整的模型，包含ID和时间戳"""
    id: int = Field(..., description="ID")
    created_at: Optional[datetime] = Field(default_factory=datetime.now, description="创建时间")
    updated_at: Optional[datetime] = Field(default_factory=datetime.now, description="更新时间")
    
    model_config = ConfigDict(from_attributes=True)
```

### 辅助函数

每个模型文件必须包含转换函数：

```python
def entity_to_dict(entity: Union[Entity, EntityCreate, EntityUpdate]) -> dict:
    """将模型转换为字典，用于数据库操作"""
    result = {}
    
    if isinstance(entity, (EntityCreate, EntityUpdate)):
        result = entity.model_dump(exclude_unset=True, exclude_none=True)
    else:
        result = entity.model_dump(exclude_none=True)
    
    # 处理枚举字段
    if 'status' in result and isinstance(result['status'], Enum):
        result['status'] = result['status'].value
    
    # 处理JSON字段
    if 'json_field' in result and result['json_field'] is not None:
        result['json_field'] = json.dumps(result['json_field'], ensure_ascii=False)
    
    return result

def dict_to_entity(data: dict) -> Entity:
    """将字典转换为模型，处理各种数据类型转换和默认值"""
    processed_data = data.copy()
    
    # 处理枚举字段
    if 'status' in processed_data:
        status = processed_data['status']
        if isinstance(status, str):
            try:
                processed_data['status'] = StatusEnum(status)
            except ValueError:
                processed_data['status'] = StatusEnum.DEFAULT
    
    # 处理JSON字段
    if 'json_field' in processed_data:
        json_value = processed_data['json_field']
        if json_value is None or (isinstance(json_value, str) and not json_value.strip()):
            processed_data['json_field'] = None
        elif isinstance(json_value, str):
            try:
                processed_data['json_field'] = json.loads(json_value)
            except (ValueError, json.JSONDecodeError):
                processed_data['json_field'] = None
    
    # 处理日期字段
    for date_field in ['created_at', 'updated_at']:
        if date_field in processed_data:
            date_value = processed_data[date_field]
            if isinstance(date_value, str):
                try:
                    processed_data[date_field] = datetime.fromisoformat(date_value.replace('Z', '+00:00'))
                except (ValueError, AttributeError):
                    processed_data[date_field] = None
    
    return Entity(**processed_data)
```

## 新闻聚合系统规范

### RSS聚合器

**基本结构：**
```python
class RSSAggregator:
    def __init__(self, session: Optional[aiohttp.ClientSession] = None):
        self.session = session
        self._own_session = session is None
    
    async def __aenter__(self):
        if self._own_session:
            self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self._own_session and self.session:
            await self.session.close()
```

**使用模式：**
```python
async with RSSAggregator() as aggregator:
    articles = await aggregator.fetch_rss_feed(news_source)
```

### API聚合器

**用于处理雪球、东方财富等API源：**
```python
class APIAggregator:
    def __init__(self, session: Optional[aiohttp.ClientSession] = None):
        # 类似RSS聚合器的结构
        pass
    
    async def fetch_xueqiu_data(self, news_source: NewsSource) -> List[Dict[str, Any]]:
        """抓取雪球数据"""
        pass
    
    async def fetch_eastmoney_data(self, news_source: NewsSource) -> List[Dict[str, Any]]:
        """抓取东方财富数据"""
        pass
```

## 依赖管理规范

### requirements.txt更新

当添加新的依赖包时，必须更新[requirements.txt](mdc:requirements.txt)：

```txt
# 新闻聚合相关依赖
feedparser==6.0.11
newspaper3k==0.2.8
beautifulsoup4==4.13.3
lxml==5.3.1
lxml_html_clean==0.4.2
aiohttp==3.9.1
# RSS解析和网页内容提取
html2text==2024.2.26
requests-html==0.10.0
```

### 依赖安装

```bash
pip install feedparser newspaper3k 'lxml[html_clean]'
```

## 错误处理规范

### 统一错误处理模式

```python
async def example_operation(self, param: str) -> Optional[Result]:
    """示例操作"""
    try:
        # 执行操作
        result = await self.some_operation(param)
        
        if result:
            logger.info(f"操作成功: {param}")
            return result
        else:
            logger.warning(f"操作无结果: {param}")
            return None
            
    except Exception as e:
        logger.error(f"操作失败 ({param}): {e}")
        return None
```

### 数据库操作错误处理

```python
try:
    self.db.execute(sql, params)
    self.db.commit()
    return await self.get_by_id(entity_id)
except Exception as e:
    logger.error(f"数据库操作失败: {e}")
    self.db.rollback()
    return None
```

## 日志规范

### 日志级别使用

- `logger.debug()`: 调试信息，包含详细的参数和状态
- `logger.info()`: 正常操作信息，如成功创建、更新等
- `logger.warning()`: 警告信息，如数据已存在、无结果等
- `logger.error()`: 错误信息，包含异常和失败操作

### 日志格式

```python
# 成功操作
logger.info(f"成功创建新闻源: {result.name} (ID: {result.id})")

# 警告信息
logger.warning(f"新闻源已存在: {source.name}")

# 错误信息
logger.error(f"创建新闻源失败: {e}")

# 调试信息
logger.debug(f"创建新闻源参数: {source_dict}")
```

## 测试规范

### 测试文件结构

```
test/
├── test_rss_simple.py          # RSS功能简单测试
├── test_news_aggregation_complete.py  # 完整新闻聚合测试
└── test_models/                # 模型测试
    ├── test_news_source.py
    └── test_news_article.py
```

### 测试模式

```python
async def test_functionality():
    """测试功能"""
    logger.info("🚀 开始测试...")
    
    try:
        # 执行测试
        result = await some_operation()
        
        if result:
            logger.info("✅ 测试成功")
            return True
        else:
            logger.warning("⚠️ 测试无结果")
            return False
            
    except Exception as e:
        logger.error(f"❌ 测试失败: {e}")
        return False
```

## 初始化脚本规范

### 数据初始化脚本

```python
# scripts/init_xxx.py
async def main():
    """主初始化函数"""
    logger.info("🚀 开始初始化...")
    
    success_count = 0
    total_count = len(data_list)
    
    for data in data_list:
        try:
            result = await handler.create_entity(data)
            if result:
                success_count += 1
                logger.info(f"  ✅ 创建成功: {data['name']} (ID: {result.id})")
            else:
                logger.error(f"  ❌ 创建失败: {data['name']}")
        except Exception as e:
            logger.error(f"  ❌ 创建异常: {data['name']} - {e}")
    
    logger.info(f"📊 初始化完成统计:")
    logger.info(f"  ✅ 成功: {success_count} 个")
    logger.info(f"  ❌ 失败: {total_count - success_count} 个")
    logger.info(f"  📝 总计: {total_count} 个")
```

## 代码质量要求

### 类型提示

所有函数和方法必须包含完整的类型提示：

```python
async def create_entity(self, entity_data: Dict[str, Any]) -> Optional[Entity]:
    """创建实体"""
    pass

def process_list(self, items: List[str]) -> Dict[str, int]:
    """处理列表"""
    pass
```

### 文档字符串

所有类和方法必须包含详细的文档字符串：

```python
class ExampleHandler:
    """
    示例处理器
    负责处理示例相关的业务逻辑
    """
    
    async def create_example(self, data: Dict[str, Any]) -> Optional[Example]:
        """
        创建示例
        
        Args:
            data: 示例数据字典
            
        Returns:
            创建成功的示例模型，失败返回None
        """
        pass
```

### 代码组织

- 每个文件开头包含编码声明和模块文档
- 导入语句按标准库、第三方库、本地模块的顺序组织
- 类和函数之间使用适当的空行分隔
- 复杂逻辑添加注释说明

这些规范确保代码的一致性、可维护性和可扩展性。

---
description: 
globs: 
alwaysApply: true
---
# FastAPI ç¼–ç è§„èŒƒ

## æ¦‚è¿°

æœ¬æ–‡æ¡£ä¸ºå½“å‰åŸºäºfastApié¡¹ç›®æä¾›äº†ä¸€å¥—ç¼–ç è§„èŒƒå’Œæœ€ä½³å®è·µï¼ŒåŸºäºé¡¹ç›®çš„ä¸‰å±‚æ¶æ„ï¼ˆAPI-Handler-Repository-Modelï¼‰å’Œä¸šåŠ¡ç‰¹ç‚¹ï¼Œæ—¨åœ¨ç¡®ä¿ä»£ç çš„ä¸€è‡´æ€§ã€å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

## é€šç”¨ç¼–ç é£æ ¼

- **PEP 8**: éµå¾ª [PEP 8 -- Style Guide for Python Code](mdc:https:/www.python.org/dev/peps/pep-0008)ã€‚
- **Linters å’Œ Formatters**: æ¨èä½¿ç”¨ `Flake8` (æˆ– `Pylint`) è¿›è¡Œä»£ç é£æ ¼æ£€æŸ¥ï¼Œä½¿ç”¨ `Black` å’Œ `isort` è¿›è¡Œä»£ç æ ¼å¼åŒ–å’Œå¯¼å…¥æ’åºã€‚
    - **é…ç½®ç¤ºä¾‹ (`pyproject.toml` for Black and isort):**
      ```toml
      [tool.black]
      line-length = 88
      target-version = ['py38', 'py39', 'py310', 'py311'] # æ ¹æ®é¡¹ç›® Python ç‰ˆæœ¬è°ƒæ•´

      [tool.isort]
      profile = "black"
      line_length = 88
      ```
- **ç±»å‹æç¤º**: å¼ºåˆ¶ä½¿ç”¨ç±»å‹æç¤º (Type Hinting)ï¼Œå¹¶ä½¿ç”¨ `mypy`è¿›è¡Œé™æ€ç±»å‹æ£€æŸ¥ã€‚
    - **ç¤ºä¾‹:**
      ```python
      from fastapi import FastAPI
      from pydantic import BaseModel

      app = FastAPI()

      class Item(BaseModel):
          name: str
          price: float
          is_offer: bool | None = None

      @app.post("/items/")
      async def create_item(item: Item) -> Item:
          return item
      ```
- **å‘½åçº¦å®š**:
    - **å˜é‡å’Œå‡½æ•°å**: `snake_case` (ä¾‹å¦‚: `ticker_id`, `get_ticker_details`)
    - **ç±»å**: `PascalCase` (ä¾‹å¦‚: `TickerRepository`, `NewsAggregator`)
    - **å¸¸é‡**: `UPPER_SNAKE_CASE` (ä¾‹å¦‚: `MAX_ARTICLES_PER_FETCH`)
    - **æ¨¡å—å’ŒåŒ…å**: `snake_case` (ä¾‹å¦‚: `news_aggregator`, `ticker_handler`)
- **æ–‡æ¡£å­—ç¬¦ä¸² (Docstrings)**: ä¸ºæ‰€æœ‰å…¬å…±æ¨¡å—ã€å‡½æ•°ã€ç±»å’Œæ–¹æ³•ç¼–å†™æ¸…æ™°çš„æ–‡æ¡£å­—ç¬¦ä¸²ã€‚æ¨èä½¿ç”¨ Google é£æ ¼æˆ– reStructuredText é£æ ¼ã€‚
    - **ç¤ºä¾‹ (Google é£æ ¼):**
      ```python
      async def get_item_by_id(item_id: int, db: Session) -> models.Item | None:
          """Fetches an item by its ID from the database.

          Args:
              item_id: The ID of the item to fetch.
              db: The database session.

          Returns:
              The item object if found, otherwise None.
          """
          return db.query(models.Item).filter(models.Item.id == item_id).first()
      ```
- **æ³¨é‡Š**: åªä¸ºå¤æ‚æˆ–ä¸æ˜æ˜¾çš„ä»£ç æ®µæ·»åŠ æ³¨é‡Šã€‚ä»£ç æœ¬èº«åº”å°½å¯èƒ½è‡ªè§£é‡Šã€‚

## å®šæ¶æ„è§„èŒƒ

### 1. **APIå±‚è§„èŒƒ** (`api/`)

#### ä¸»åº”ç”¨ç¨‹åº ([api.py](mdc:api/api.py))
```python
from fastapi import FastAPI, HTTPException, Depends
from typing import Dict, Any
from core.auth.auth_middleware import auth_required
from .routers import ticker, news, scheduler

app = FastAPI(
    title="InvestNote API",
    description="Investment notes and analysis API",
    root_path="/investnote"
)

# æ³¨å†Œè·¯ç”±æ¨¡å—
app.include_router(ticker.router)
app.include_router(news.router)
app.include_router(scheduler.router)

@app.get("/")
async def root():
    return {"message": "InvestNote API Service"}
```

#### è·¯ç”±æ¨¡å—å®šä¹‰ ([routers/ticker.py](mdc:api/routers/ticker.py))
```python
from fastapi import APIRouter, HTTPException, Depends
from typing import Optional, Dict, Any
from core.data_source_helper import DataSourceHelper
from ..models import PageRequest

# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter(tags=["è‚¡ç¥¨"])

@router.post("/pages")
async def get_ticker_pages(request: PageRequest):
    """è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œæ”¯æŒåˆ†é¡µã€æœç´¢å’Œæ’åº"""
    try:
        # ä¸šåŠ¡é€»è¾‘å¤„ç†
        return {"status": "success", "data": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

#### APIå±‚æ¨¡å—åŒ–è§„èŒƒ
- **ä¸»åº”ç”¨**: åªåŒ…å«åŸºç¡€è·¯ç”±ã€ä¸­é—´ä»¶ã€è·¯ç”±æ³¨å†Œ
- **è·¯ç”±æ¨¡å—**: æŒ‰åŠŸèƒ½æ‹†åˆ†ï¼Œä½¿ç”¨APIRouteråˆ›å»º
- **æ ‡ç­¾ç»„ç»‡**: æ¯ä¸ªè·¯ç”±å™¨è®¾ç½®åˆé€‚çš„tagsä¾¿äºæ–‡æ¡£åˆ†ç±»
- **è·¯å¾„ä¿æŒ**: æ‹†åˆ†åä¿æŒåŸæœ‰APIç«¯ç‚¹è·¯å¾„ä¸å˜
- **ä¾èµ–å…±äº«**: å…±äº«çš„ä¾èµ–å’Œæ¨¡å‹å®šä¹‰
- **å¼‚å¸¸å¤„ç†**: ç»Ÿä¸€çš„é”™è¯¯å¤„ç†æ¨¡å¼

#### è·¯ç”±æ¨¡å—æ–‡ä»¶ç»“æ„
- **[ticker.py](mdc:api/routers/ticker.py)**: è‚¡ç¥¨æ•°æ®ç›¸å…³è·¯ç”±
- **[news.py](mdc:api/routers/news.py)**: æ–°é—»èšåˆç›¸å…³è·¯ç”±  
- **[scheduler.py](mdc:api/routers/scheduler.py)**: å®šæ—¶ä»»åŠ¡ç›¸å…³è·¯ç”±

### 2. **Handlerå±‚è§„èŒƒ** (`core/handler/`)

#### Handlerç±»å®šä¹‰
```python
# core/handler/ticker_analysis_handler.py
from typing import Dict, List, Optional, Any
from ..service.ticker_repository import TickerRepository
from ..service.ticker_score_repository import TickerScoreRepository
from ..models.ticker import Ticker

class TickerAnalysisHandler:
    """è‚¡ç¥¨åˆ†æå¤„ç†å™¨ - åè°ƒå¤šä¸ªRepositoryæ‰§è¡Œå¤æ‚ä¸šåŠ¡é€»è¾‘"""
    
    def __init__(self):
        self.ticker_repo = TickerRepository()
        self.score_repo = TickerScoreRepository()
    
    async def analyze_ticker_performance(
        self, 
        ticker_code: str, 
        analysis_days: int = 30
    ) -> Dict[str, Any]:
        """åˆ†æè‚¡ç¥¨è¡¨ç° - ä¸šåŠ¡é€»è¾‘åè°ƒå¤šä¸ªæ•°æ®æº"""
        
        # 1. è·å–åŸºç¡€æ•°æ®
        ticker = await self.ticker_repo.get_by_code(ticker_code)
        if not ticker:
            raise ValueError(f"è‚¡ç¥¨ä»£ç  {ticker_code} ä¸å­˜åœ¨")
        
        # 2. è·å–è¯„åˆ†å†å²
        score_history = await self.score_repo.get_score_history(
            ticker.id, days=analysis_days
        )
        
        # 3. æ‰§è¡Œä¸šåŠ¡é€»è¾‘è®¡ç®—
        performance_metrics = self._calculate_performance_metrics(
            ticker, score_history
        )
        
        return {
            "ticker": ticker,
            "metrics": performance_metrics,
            "analysis_period": analysis_days
        }
    
    def _calculate_performance_metrics(
        self, 
        ticker: Ticker, 
        score_history: List[Dict]
    ) -> Dict[str, float]:
        """ç§æœ‰æ–¹æ³• - è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        # å…·ä½“ä¸šåŠ¡é€»è¾‘å®ç°
        return {
            "avg_score": sum(s["score"] for s in score_history) / len(score_history),
            "score_trend": self._calculate_trend(score_history),
            "volatility": self._calculate_volatility(score_history)
        }
```

#### Handlerå±‚è´£ä»»
- å°è£…ä¸šåŠ¡é€»è¾‘å’Œä¸šåŠ¡è§„åˆ™
- åè°ƒå¤šä¸ªRepositoryæ‰§è¡Œå¤æ‚æ“ä½œ
- æ•°æ®è½¬æ¢å’Œä¸šåŠ¡è®¡ç®—
- ä¸šåŠ¡å¼‚å¸¸å¤„ç†
- **ç¦æ­¢**: ç›´æ¥æ•°æ®åº“æ“ä½œæˆ–SQLæŸ¥è¯¢

### 3. **Repositoryå±‚è§„èŒƒ** (`core/service/`)

#### Repositoryç±»å®šä¹‰
```python
# core/service/ticker_repository.py
import copy
import logging
import os
from typing import List, Dict, Any, Optional, Union
from datetime import datetime

from core.database.db_adapter import DbAdapter
from core.models.ticker import Ticker, TickerCreate, TickerUpdate, ticker_to_dict, dict_to_ticker
from core.enum.ticker_group import get_group_id_by_code

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# è·å–å ä½ç¬¦ç±»å‹
DB_TYPE = os.getenv('DB_TYPE', 'sqlite').lower()
# SQLite ä½¿ç”¨ ? å ä½ç¬¦ï¼Œå…¶ä»–æ•°æ®åº“ä½¿ç”¨ %s
PLACEHOLDER = '?' if DB_TYPE == 'sqlite' else '%s'

class TickerRepository:
    """
    ä½¿ç”¨Pydanticæ¨¡å‹çš„Tickerä»“åº“ç±»
    """
    table = 'ticker'

    def __init__(self, db_connection: Optional[Any] = None):
        """
        åˆå§‹åŒ–Tickerä»“åº“
        
        Args:
            db_connection: å¯é€‰çš„æ•°æ®åº“è¿æ¥ï¼Œå¦‚æœæœªæä¾›å°†ä½¿ç”¨DbAdapteråˆ›å»ºæ–°è¿æ¥
        """
        if db_connection:
            self.db = db_connection
        else:
            self.db = DbAdapter()
    
    def get_by_code(self, code: str) -> Optional[Ticker]:
        """
        æ ¹æ®è‚¡ç¥¨ä»£ç è·å–è‚¡ç¥¨ä¿¡æ¯
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            Tickerå¯¹è±¡æˆ–None
        """
        try:
            sql = f"SELECT * FROM {self.table} WHERE code = {PLACEHOLDER}"
            result = self.db.query_one(sql, (code,))
            if result:
                return dict_to_ticker(result)
            return None
        except Exception as e:
            logger.error(f"è·å–è‚¡ç¥¨ä¿¡æ¯é”™è¯¯: {e}")
            return None
```

#### Repositoryå±‚è´£ä»»
- å°è£…æ‰€æœ‰æ•°æ®åº“æ“ä½œ
- æä¾›CRUDæ–¹æ³•å’Œå¤æ‚æŸ¥è¯¢
- æ•°æ®åº“äº‹åŠ¡ç®¡ç†
- æŸ¥è¯¢ä¼˜åŒ–å’Œç¼“å­˜
- **ç¦æ­¢**: åŒ…å«ä¸šåŠ¡é€»è¾‘æˆ–ä¸šåŠ¡è§„åˆ™

### 4. **Modelå±‚è§„èŒƒ** (`core/models/`)

#### Pydanticæ¨¡å‹å®šä¹‰ (æ¨èæ–¹å¼)
```python
# core/models/ticker.py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from datetime import datetime
from typing import Optional, Union
from pydantic import BaseModel, Field, ConfigDict

class TickerBase(BaseModel):
    """TickeråŸºç¡€æ¨¡å‹ï¼ŒåŒ…å«å…±æœ‰å­—æ®µ"""
    code: str = Field(..., description="è‚¡ç¥¨ä»£ç ")
    name: str = Field(..., description="è‚¡ç¥¨åç§°")
    group_id: int = Field(default=0, description="ç»„ID")
    type: Optional[int] = Field(default=1, description="ç±»å‹")
    source: Optional[int] = Field(default=1, description="æ•°æ®æ¥æº")
    status: Optional[int] = Field(default=1, description="çŠ¶æ€")
    is_deleted: Optional[bool] = Field(default=False, description="æ˜¯å¦åˆ é™¤")
    remark: Optional[str] = Field(default=None, description="å¤‡æ³¨ä¿¡æ¯")
    
    model_config = ConfigDict(from_attributes=True)

class TickerCreate(TickerBase):
    """ç”¨äºåˆ›å»ºTickerçš„æ¨¡å‹"""
    pass

class TickerUpdate(BaseModel):
    """ç”¨äºæ›´æ–°Tickerçš„æ¨¡å‹ï¼Œæ‰€æœ‰å­—æ®µéƒ½æ˜¯å¯é€‰çš„"""
    name: Optional[str] = Field(default=None, description="è‚¡ç¥¨åç§°")
    group_id: Optional[int] = Field(default=None, description="ç»„ID")
    status: Optional[int] = Field(default=None, description="çŠ¶æ€")
    remark: Optional[str] = Field(default=None, description="å¤‡æ³¨ä¿¡æ¯")
    
    model_config = ConfigDict(from_attributes=True)

class Ticker(TickerBase):
    """å®Œæ•´çš„Tickeræ¨¡å‹ï¼ŒåŒ…å«ID"""
    id: int = Field(..., description="ID")
    create_time: Optional[datetime] = Field(default_factory=datetime.now, description="åˆ›å»ºæ—¶é—´")
    version: Optional[int] = Field(default=1, description="ç‰ˆæœ¬å·")
    
    model_config = ConfigDict(from_attributes=True)

# ç”¨äºåºåˆ—åŒ–å’Œååºåˆ—åŒ–çš„è¾…åŠ©å‡½æ•°
def ticker_to_dict(ticker: Union[Ticker, TickerCreate, TickerUpdate]) -> dict:
    """å°†Tickeræ¨¡å‹è½¬æ¢ä¸ºå­—å…¸ï¼Œç”¨äºæ•°æ®åº“æ“ä½œ"""
    if isinstance(ticker, (TickerCreate, TickerUpdate)):
        return ticker.model_dump(exclude_unset=True, exclude_none=True)
    else:
        return ticker.model_dump(exclude_none=True)

def dict_to_ticker(data: dict) -> Ticker:
    """å°†å­—å…¸è½¬æ¢ä¸ºTickeræ¨¡å‹ï¼Œå¤„ç†å„ç§æ•°æ®ç±»å‹è½¬æ¢å’Œé»˜è®¤å€¼"""
    # æ•°æ®ç±»å‹å¤„ç†å’ŒéªŒè¯é€»è¾‘
    processed_data = data.copy()
    
    # å¤„ç†æ—¥æœŸå­—æ®µ
    for date_field in ['create_time']:
        if date_field in processed_data and isinstance(processed_data[date_field], str):
            try:
                processed_data[date_field] = datetime.fromisoformat(processed_data[date_field])
            except ValueError:
                processed_data[date_field] = datetime.now()
    
    return Ticker(**processed_data)
```

#### æ–°é—»æ¨¡å‹å®šä¹‰ç¤ºä¾‹
```python
# core/models/news_article.py
from datetime import datetime
from typing import Optional, List, Dict, Any
from pydantic import BaseModel, Field, ConfigDict
from enum import Enum

class ArticleStatus(str, Enum):
    """æ–‡ç« çŠ¶æ€æšä¸¾"""
    PENDING = "pending"
    PROCESSING = "processing"
    PROCESSED = "processed"
    FAILED = "failed"
    ARCHIVED = "archived"

class NewsArticleBase(BaseModel):
    """æ–°é—»æ–‡ç« åŸºç¡€æ¨¡å‹"""
    title: str = Field(..., description="æ–‡ç« æ ‡é¢˜")
    url: str = Field(..., description="æ–‡ç« URL")
    url_hash: str = Field(..., description="URLå“ˆå¸Œï¼ˆå»é‡ç”¨ï¼‰")
    content: Optional[str] = Field(default=None, description="æ–‡ç« æ­£æ–‡å†…å®¹")
    source_id: int = Field(..., description="æ–°é—»æºID")
    status: ArticleStatus = Field(default=ArticleStatus.PENDING, description="å¤„ç†çŠ¶æ€")
    
    model_config = ConfigDict(from_attributes=True)

class NewsArticleCreate(NewsArticleBase):
    """ç”¨äºåˆ›å»ºæ–°é—»æ–‡ç« çš„æ¨¡å‹"""
    pass

class NewsArticle(NewsArticleBase):
    """å®Œæ•´çš„æ–°é—»æ–‡ç« æ¨¡å‹"""
    id: int = Field(..., description="ID")
    created_at: Optional[datetime] = Field(default_factory=datetime.now, description="åˆ›å»ºæ—¶é—´")
    updated_at: Optional[datetime] = Field(default_factory=datetime.now, description="æ›´æ–°æ—¶é—´")
    
    model_config = ConfigDict(from_attributes=True)
```

#### Modelå±‚æ¶æ„è¦æ±‚

1. **ç»Ÿä¸€ä½¿ç”¨Pydanticæ¨¡å‹**: é¡¹ç›®ä¸­æ‰€æœ‰æ¨¡å‹éƒ½å¿…é¡»ä½¿ç”¨Pydantic BaseModelï¼Œä¸å†ä½¿ç”¨SQLAlchemyæ¨¡å‹
2. **ä¸‰å±‚æ¨¡å‹ç»“æ„**: 
   - `XxxBase`: åŒ…å«å…±æœ‰å­—æ®µçš„åŸºç¡€æ¨¡å‹
   - `XxxCreate`: ç”¨äºåˆ›å»ºæ“ä½œçš„æ¨¡å‹
   - `XxxUpdate`: ç”¨äºæ›´æ–°æ“ä½œçš„æ¨¡å‹ï¼Œæ‰€æœ‰å­—æ®µå¯é€‰
   - `Xxx`: å®Œæ•´æ¨¡å‹ï¼ŒåŒ…å«IDå’Œæ—¶é—´æˆ³
3. **è¾…åŠ©å‡½æ•°**: æ¯ä¸ªæ¨¡å‹æ–‡ä»¶å¿…é¡»åŒ…å« `xxx_to_dict()` å’Œ `dict_to_xxx()` å‡½æ•°
4. **æ•°æ®éªŒè¯**: ä½¿ç”¨Fieldè¿›è¡Œå­—æ®µéªŒè¯å’Œæè¿°
5. **é…ç½®**: ä½¿ç”¨ `ConfigDict(from_attributes=True)` æ”¯æŒORMå¯¹è±¡è½¬æ¢

#### æ•°æ®åº“è¡¨æ›´æ–°è¦æ±‚

æ¯æ¬¡æ–°å¢æˆ–ä¿®æ”¹æ¨¡å‹æ—¶ï¼Œå¿…é¡»åŒæ—¶æ›´æ–°å¯¹åº”çš„SQLå»ºè¡¨è„šæœ¬ï¼š
- `sql/create_table_sqlite.sql` - SQLiteç‰ˆæœ¬
- `sql/create_table.sql` - MySQLç‰ˆæœ¬

#### Repositoryå±‚ä¸æ¨¡å‹çš„é…åˆ

Repositoryå±‚è´Ÿè´£ï¼š
- ä½¿ç”¨è¾…åŠ©å‡½æ•°è¿›è¡Œæ¨¡å‹ä¸å­—å…¸çš„è½¬æ¢
- å¤„ç†æ•°æ®åº“å­—æ®µåˆ°Pydanticæ¨¡å‹çš„æ˜ å°„
- æ‰§è¡Œæ‰€æœ‰CRUDæ“ä½œ

### 5. **æ–°é—»èšåˆæ¨¡å—è§„èŒƒ** (`core/news_aggregator/`)

#### æ–°é—»èšåˆå™¨å®ç°
```python
# core/news_aggregator/rss_aggregator.py
import asyncio
import aiohttp
from typing import List, Dict, Optional, Any
from ..models.news_source import NewsSource
from ..models.news_article import NewsArticle

class RSSAggregator:
    """RSSæ–°é—»èšåˆå™¨ - å¤„ç†RSSæºæ•°æ®æŠ“å–"""
    
    def __init__(self, session: Optional[aiohttp.ClientSession] = None):
        self.session = session
        self._own_session = session is None
    
    async def __aenter__(self):
        if self._own_session:
            self.session = aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=30),
                headers={'User-Agent': 'InvestNote RSS Aggregator 1.0'}
            )
        return self
    
    async def fetch_rss_feed(self, news_source: NewsSource) -> List[Dict[str, Any]]:
        """æŠ“å–RSSæºæ•°æ®
        
        Args:
            news_source: æ–°é—»æºé…ç½®
            
        Returns:
            è§£æåçš„æ–‡ç« æ•°æ®åˆ—è¡¨
            
        Raises:
            ValueError: RSSå†…å®¹è·å–å¤±è´¥
            Exception: è§£æå¼‚å¸¸
        """
        try:
            # å®ç°RSSæŠ“å–é€»è¾‘
            pass
        except Exception as e:
            logger.error(f"RSSæŠ“å–å¤±è´¥ {news_source.name}: {e}")
            raise
```

### 6. **AIä»£ç†æ¨¡å—è§„èŒƒ** (`core/ai_agents/`)

#### AIä»£ç†åŸºç±»
```python
# core/ai_agents/base_agent.py
from abc import ABC, abstractmethod
from typing import Dict, Any, List
from ..models.news_article import NewsArticle

class BaseAgent(ABC):
    """AIä»£ç†åŸºç±» - å®šä¹‰æ‰€æœ‰ä»£ç†çš„é€šç”¨æ¥å£"""
    
    def __init__(self, agent_name: str, config: Dict[str, Any]):
        self.agent_name = agent_name
        self.config = config
    
    @abstractmethod
    async def analyze(self, articles: List[NewsArticle]) -> Dict[str, Any]:
        """åˆ†ææ–°é—»æ–‡ç« 
        
        Args:
            articles: å¾…åˆ†æçš„æ–°é—»æ–‡ç« åˆ—è¡¨
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        pass
    
    @abstractmethod
    async def extract_insights(self, analysis_result: Dict[str, Any]) -> List[str]:
        """æå–æŠ•èµ„æ´å¯Ÿ
        
        Args:
            analysis_result: åˆ†æç»“æœ
            
        Returns:
            æŠ•èµ„æ´å¯Ÿåˆ—è¡¨
        """
        pass
```

## å¼‚æ­¥ç¼–ç¨‹è§„èŒƒ

### 1. **å¼‚æ­¥å‡½æ•°å®šä¹‰**
```python
# æ­£ç¡®ï¼šæ•°æ®åº“æ“ä½œä½¿ç”¨å¼‚æ­¥
async def get_ticker_data(ticker_id: int) -> Optional[Ticker]:
    async with get_async_session() as session:
        result = await session.execute(
            select(Ticker).where(Ticker.id == ticker_id)
        )
        return result.scalar_one_or_none()

# æ­£ç¡®ï¼šå¤–éƒ¨APIè°ƒç”¨ä½¿ç”¨å¼‚æ­¥
async def fetch_news_from_api(url: str) -> Dict[str, Any]:
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            return await response.json()
```

### 2. **å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨**
```python
# æ¨èï¼šä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç®¡ç†èµ„æº
class NewsAggregator:
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.session.close()

# ä½¿ç”¨æ–¹å¼
async with NewsAggregator() as aggregator:
    articles = await aggregator.fetch_articles()
```

### 3. **å¹¶å‘å¤„ç†**
```python
# æ¨èï¼šä½¿ç”¨asyncio.gatherå¤„ç†å¹¶å‘ä»»åŠ¡
async def fetch_multiple_sources(sources: List[NewsSource]) -> List[Dict]:
    tasks = [
        fetch_rss_feed(source) for source in sources
    ]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # å¤„ç†å¼‚å¸¸
    valid_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            logger.error(f"Source {sources[i].name} failed: {result}")
        else:
            valid_results.extend(result)
    
    return valid_results
```

## é”™è¯¯å¤„ç†å’Œæ—¥å¿—è§„èŒƒ

### 1. **å¼‚å¸¸å¤„ç†**
```python
# æ¨èï¼šåˆ†å±‚å¼‚å¸¸å¤„ç†
from fastapi import HTTPException
import logging

logger = logging.getLogger(__name__)

# Repositoryå±‚ï¼šè®°å½•å¹¶é‡æ–°æŠ›å‡º
async def get_ticker_by_id(ticker_id: int) -> Optional[Ticker]:
    try:
        # æ•°æ®åº“æ“ä½œ
        return ticker
    except DatabaseError as e:
        logger.error(f"Database error in get_ticker_by_id: {e}")
        raise

# Handlerå±‚ï¼šä¸šåŠ¡å¼‚å¸¸å¤„ç†
async def process_ticker_analysis(ticker_id: int) -> Dict[str, Any]:
    try:
        ticker = await self.ticker_repo.get_ticker_by_id(ticker_id)
        if not ticker:
            raise ValueError(f"Ticker {ticker_id} not found")
        return analysis_result
    except ValueError as e:
        logger.warning(f"Business logic error: {e}")
        raise
    except Exception as e:
        logger.error(f"Unexpected error in ticker analysis: {e}")
        raise

# APIå±‚ï¼šHTTPå¼‚å¸¸å¤„ç†
@app.get("/ticker/{ticker_id}")
async def get_ticker_analysis(ticker_id: int):
    try:
        result = await ticker_handler.process_ticker_analysis(ticker_id)
        return {"status": "success", "data": result}
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        logger.error(f"API error: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")
```

### 2. **æ—¥å¿—è§„èŒƒ**
```python
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# æ—¥å¿—ä½¿ç”¨ç¤ºä¾‹
class TickerHandler:
    async def update_ticker_data(self, ticker_id: int, data: Dict):
        logger.info(f"å¼€å§‹æ›´æ–°è‚¡ç¥¨æ•°æ®: ticker_id={ticker_id}")
        
        try:
            result = await self.repository.update(ticker_id, data)
            logger.info(f"è‚¡ç¥¨æ•°æ®æ›´æ–°æˆåŠŸ: ticker_id={ticker_id}")
            return result
        except Exception as e:
            logger.error(f"è‚¡ç¥¨æ•°æ®æ›´æ–°å¤±è´¥: ticker_id={ticker_id}, error={e}")
            raise
```

## æµ‹è¯•è§„èŒƒ

### 1. **å•å…ƒæµ‹è¯•**
```python
# tests/test_ticker_handler.py
import pytest
from unittest.mock import AsyncMock, patch
from core.handler.ticker_handler import TickerHandler
from core.models.ticker import Ticker

class TestTickerHandler:
    @pytest.fixture
    async def ticker_handler(self):
        return TickerHandler()
    
    @pytest.fixture
    def sample_ticker(self):
        return Ticker(
            id=1,
            code="AAPL",
            name="Apple Inc.",
            status=1
        )
    
    @patch('core.service.ticker_repository.TickerRepository.get_by_id')
    async def test_get_ticker_success(self, mock_get_by_id, ticker_handler, sample_ticker):
        # Arrange
        mock_get_by_id.return_value = sample_ticker
        
        # Act
        result = await ticker_handler.get_ticker_by_id(1)
        
        # Assert
        assert result == sample_ticker
        mock_get_by_id.assert_called_once_with(1)
    
    async def test_get_ticker_not_found(self, ticker_handler):
        with patch.object(ticker_handler.repository, 'get_by_id', return_value=None):
            result = await ticker_handler.get_ticker_by_id(999)
            assert result is None
```

### 2. **é›†æˆæµ‹è¯•**
```python
# tests/test_integration_news.py
import pytest
from httpx import AsyncClient
from main import app

@pytest.mark.asyncio
async def test_news_aggregation_flow():
    async with AsyncClient(app=app, base_url="http://test") as ac:
        # 1. åˆ›å»ºæ–°é—»æº
        source_data = {
            "name": "Test RSS Source",
            "source_type": "rss",
            "url": "https://example.com/rss.xml"
        }
        response = await ac.post("/news/sources", json=source_data)
        assert response.status_code == 201
        source_id = response.json()["data"]["id"]
        
        # 2. è§¦å‘æ–°é—»æŠ“å–
        response = await ac.post(f"/news/sources/{source_id}/fetch")
        assert response.status_code == 200
        
        # 3. éªŒè¯æ–‡ç« åˆ›å»º
        response = await ac.get(f"/news/articles?source_id={source_id}")
        assert response.status_code == 200
        assert len(response.json()["data"]) > 0
```

## æ€§èƒ½ä¼˜åŒ–è§„èŒƒ

### 1. **æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–**
```python
# æ¨èï¼šä½¿ç”¨ç´¢å¼•å’Œé€‚å½“çš„æŸ¥è¯¢æ¡ä»¶
async def get_recent_high_score_tickers(days: int = 7, min_score: float = 8.0):
    # ç¡®ä¿ç›¸å…³å­—æ®µæœ‰ç´¢å¼•
    sql = """
    SELECT t.*, ts.score 
    FROM ticker t 
    JOIN ticker_score ts ON t.id = ts.ticker_id 
    WHERE ts.create_time >= DATE_SUB(NOW(), INTERVAL :days DAY)
    AND ts.score >= :min_score
    AND t.status = 1
    ORDER BY ts.score DESC
    LIMIT 100
    """
    return await self.db_helper.fetch_all(sql, {
        "days": days, 
        "min_score": min_score
    })

# é¿å…ï¼šN+1æŸ¥è¯¢é—®é¢˜
# é”™è¯¯ç¤ºä¾‹ - ä¼šäº§ç”ŸN+1æŸ¥è¯¢
async def get_tickers_with_scores_bad():
    tickers = await self.get_all_tickers()  # 1æ¬¡æŸ¥è¯¢
    results = []
    for ticker in tickers:
        score = await self.get_ticker_score(ticker.id)  # Næ¬¡æŸ¥è¯¢
        results.append({"ticker": ticker, "score": score})
    return results

# æ­£ç¡®ç¤ºä¾‹ - ä½¿ç”¨JOINä¸€æ¬¡æŸ¥è¯¢
async def get_tickers_with_scores_good():
    sql = """
    SELECT t.*, ts.score 
    FROM ticker t 
    LEFT JOIN ticker_score ts ON t.id = ts.ticker_id
    WHERE t.status = 1
    """
    return await self.db_helper.fetch_all(sql)
```

### 2. **ç¼“å­˜ç­–ç•¥**
```python
from functools import wraps
import asyncio
from typing import Dict, Any

# ç®€å•å†…å­˜ç¼“å­˜è£…é¥°å™¨
def cache_result(ttl: int = 300):
    cache: Dict[str, Any] = {}
    
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = f"{func.__name__}:{hash(str(args) + str(kwargs))}"
            
            # æ£€æŸ¥ç¼“å­˜
            if cache_key in cache:
                result, timestamp = cache[cache_key]
                if time.time() - timestamp < ttl:
                    return result
            
            # æ‰§è¡Œå‡½æ•°å¹¶ç¼“å­˜ç»“æœ
            result = await func(*args, **kwargs)
            cache[cache_key] = (result, time.time())
            return result
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
class NewsHandler:
    @cache_result(ttl=600)  # ç¼“å­˜10åˆ†é’Ÿ
    async def get_trending_topics(self) -> List[str]:
        # å¤æ‚çš„æ•°æ®å¤„ç†é€»è¾‘
        return trending_topics
```

## å®‰å…¨è§„èŒƒ

### 1. **è¾“å…¥éªŒè¯**
```python
from pydantic import BaseModel, Field, validator

class CreateTickerRequest(BaseModel):
    code: str = Field(..., min_length=1, max_length=20, regex=r'^[A-Z0-9]+$')
    name: str = Field(..., min_length=1, max_length=255)
    market: str = Field(..., regex=r'^(US|HK|CN)$')
    
    @validator('code')
    def validate_code(cls, v):
        if not v.isalnum():
            raise ValueError('è‚¡ç¥¨ä»£ç åªèƒ½åŒ…å«å­—æ¯å’Œæ•°å­—')
        return v.upper()
```

### 2. **æ•æ„Ÿä¿¡æ¯å¤„ç†**
```python
import os
from typing import Optional

class Config:
    """é…ç½®ç®¡ç†ç±» - æ•æ„Ÿä¿¡æ¯ä»ç¯å¢ƒå˜é‡è¯»å–"""
    
    DATABASE_URL: str = os.getenv('DATABASE_URL', 'sqlite:///./investnote.db')
    API_KEYS: Dict[str, str] = {
        'news_api': os.getenv('NEWS_API_KEY', ''),
        'stock_api': os.getenv('STOCK_API_KEY', '')
    }
    
    # ä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯
    @classmethod
    def get_api_key(cls, service: str) -> Optional[str]:
        return cls.API_KEYS.get(service)
```

## éƒ¨ç½²å’Œè¿ç»´è§„èŒƒ

### 1. **å¥åº·æ£€æŸ¥ç«¯ç‚¹**
```python
@app.get("/health")
async def health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    try:
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        await check_database_connection()
        
        # æ£€æŸ¥å…¶ä»–å…³é”®æœåŠ¡
        services_status = {
            "database": "healthy",
            "redis": "healthy" if await check_redis() else "unhealthy",
            "external_apis": "healthy" if await check_external_apis() else "degraded"
        }
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "services": services_status
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }
```

### 2. **ç›‘æ§å’ŒæŒ‡æ ‡**
```python
from prometheus_client import Counter, Histogram, start_http_server
import time

# å®šä¹‰æŒ‡æ ‡
REQUEST_COUNT = Counter('http_requests_total', 'HTTPè¯·æ±‚æ€»æ•°', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTPè¯·æ±‚è€—æ—¶')

# ä¸­é—´ä»¶ç¤ºä¾‹
@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    start_time = time.time()
    
    response = await call_next(request)
    
    # è®°å½•æŒ‡æ ‡
    REQUEST_COUNT.labels(
        method=request.method,
        endpoint=request.url.path
    ).inc()
    
    REQUEST_DURATION.observe(time.time() - start_time)
    
    return response
```

## ä»£ç å®¡æŸ¥æ¸…å•

åœ¨è¿›è¡Œä»£ç å®¡æŸ¥æ—¶ï¼Œè¯·ç¡®ä¿æ£€æŸ¥ä»¥ä¸‹é¡¹ç›®ï¼š

### åŠŸèƒ½æ€§
- [ ] ä»£ç æ˜¯å¦å®ç°äº†éœ€æ±‚è§„æ ¼è¯´æ˜ä¸­çš„æ‰€æœ‰åŠŸèƒ½ï¼Ÿ
- [ ] æ˜¯å¦æœ‰é€‚å½“çš„é”™è¯¯å¤„ç†ï¼Ÿ
- [ ] æ˜¯å¦éµå¾ªäº†é¡¹ç›®çš„æ¶æ„åˆ†å±‚åŸåˆ™ï¼Ÿ

### ä»£ç è´¨é‡
- [ ] æ˜¯å¦éµå¾ªäº†PEP 8ä»£ç é£æ ¼ï¼Ÿ
- [ ] æ˜¯å¦æœ‰é€‚å½“çš„ç±»å‹æç¤ºï¼Ÿ
- [ ] æ˜¯å¦æœ‰æ¸…æ™°çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼Ÿ
- [ ] å˜é‡å’Œå‡½æ•°å‘½åæ˜¯å¦æœ‰æ„ä¹‰ï¼Ÿ

### æ€§èƒ½
- [ ] æ˜¯å¦é¿å…äº†N+1æŸ¥è¯¢é—®é¢˜ï¼Ÿ
- [ ] æ˜¯å¦é€‚å½“ä½¿ç”¨äº†å¼‚æ­¥ç¼–ç¨‹ï¼Ÿ
- [ ] æ˜¯å¦æœ‰ä¸å¿…è¦çš„æ•°æ®åº“æŸ¥è¯¢ï¼Ÿ

### å®‰å…¨æ€§
- [ ] æ˜¯å¦å¯¹ç”¨æˆ·è¾“å…¥è¿›è¡Œäº†éªŒè¯ï¼Ÿ
- [ ] æ˜¯å¦é¿å…äº†SQLæ³¨å…¥é£é™©ï¼Ÿ
- [ ] æ•æ„Ÿä¿¡æ¯æ˜¯å¦å¾—åˆ°äº†é€‚å½“ä¿æŠ¤ï¼Ÿ

### æµ‹è¯•
- [ ] æ˜¯å¦æœ‰é€‚å½“çš„å•å…ƒæµ‹è¯•ï¼Ÿ
- [ ] æµ‹è¯•è¦†ç›–ç‡æ˜¯å¦è¾¾åˆ°è¦æ±‚ï¼Ÿ
- [ ] æ˜¯å¦åŒ…å«äº†è¾¹ç•Œæ¡ä»¶æµ‹è¯•ï¼Ÿ

### ç»´æŠ¤æ€§
- [ ] ä»£ç æ˜¯å¦æ˜“äºç†è§£å’Œä¿®æ”¹ï¼Ÿ
- [ ] æ˜¯å¦éµå¾ªäº†DRYï¼ˆDon't Repeat Yourselfï¼‰åŸåˆ™ï¼Ÿ
- [ ] æ˜¯å¦æœ‰é€‚å½“çš„æ³¨é‡Šï¼Ÿ

é€šè¿‡éµå¾ªè¿™äº›è§„èŒƒï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿ InvestNote-py é¡¹ç›®çš„ä»£ç è´¨é‡ã€æ€§èƒ½å’Œå¯ç»´æŠ¤æ€§ã€‚

## é¡¹ç›®æ¶æ„è§„èŒƒ

### ä¸‰å±‚æ¶æ„æ¨¡å¼

æœ¬é¡¹ç›®é‡‡ç”¨æ ‡å‡†çš„ä¸‰å±‚æ¶æ„æ¨¡å¼ï¼š

```
Handler (ä¸šåŠ¡é€»è¾‘å±‚) -> Repository (æ•°æ®è®¿é—®å±‚) -> Database (æ•°æ®åº“å±‚)
```

#### Handlerå±‚è§„èŒƒ

**æ„é€ å‡½æ•°æ¨¡å¼ï¼š**
```python
class ExampleHandler:
    """ç¤ºä¾‹å¤„ç†å™¨"""
    
    def __init__(self):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        """
        self.repository = ExampleRepository()
```

**å…³é”®åŸåˆ™ï¼š**
- Handlerç›´æ¥åˆå§‹åŒ–Repositoryï¼Œä¸ä½¿ç”¨ä¾èµ–æ³¨å…¥
- Handlerè´Ÿè´£ä¸šåŠ¡é€»è¾‘åè°ƒï¼Œä¸ç›´æ¥æ“ä½œæ•°æ®åº“
- æ‰€æœ‰æ•°æ®åº“æ“ä½œé€šè¿‡Repositoryè¿›è¡Œ
- Handleræ–¹æ³•åº”è¯¥æ˜¯asyncçš„ï¼Œæ”¯æŒå¼‚æ­¥æ“ä½œ

#### Repositoryå±‚è§„èŒƒ

**æ„é€ å‡½æ•°æ¨¡å¼ï¼š**
```python
class ExampleRepository:
    """ç¤ºä¾‹æ•°æ®è®¿é—®ç±»"""
    
    def __init__(self):
        """
        åˆå§‹åŒ–ä»“åº“
        """
        self.db = DbAdapter()
```

**å…³é”®åŸåˆ™ï¼š**
- Repositoryç›´æ¥åˆå§‹åŒ–DbAdapter
- æ‰€æœ‰SQLæ“ä½œä½¿ç”¨`:name`å ä½ç¬¦æ ¼å¼ï¼ˆDbAdapterä¼šè‡ªåŠ¨è½¬æ¢ï¼‰
- Repositoryè´Ÿè´£æ•°æ®çš„CRUDæ“ä½œå’Œç®€å•çš„æ•°æ®è½¬æ¢
- ä½¿ç”¨æ¨¡å‹çš„è¾…åŠ©å‡½æ•°è¿›è¡Œæ•°æ®è½¬æ¢ï¼š`xxx_to_dict()` å’Œ `dict_to_xxx()`

### æ•°æ®åº“æ“ä½œè§„èŒƒ

#### SQLå ä½ç¬¦æ ¼å¼

**ç»Ÿä¸€ä½¿ç”¨`:name`æ ¼å¼ï¼š**
```python
sql = "SELECT * FROM table WHERE id = :id AND name = :name"
params = {"id": 123, "name": "example"}
self.db.execute(sql, params)
```

**DbAdapterä¼šè‡ªåŠ¨è½¬æ¢ï¼š**
- SQLite: ä¿æŒ`:name`æ ¼å¼
- MySQL: è½¬æ¢ä¸º`%(name)s`æ ¼å¼
- PostgreSQL: è½¬æ¢ä¸º`%(name)s`æ ¼å¼

#### äº‹åŠ¡å¤„ç†

```python
try:
    self.db.execute(sql, params)
    self.db.commit()
    return result
except Exception as e:
    logger.error(f"æ“ä½œå¤±è´¥: {e}")
    self.db.rollback()
    return None
```

## Pydanticæ¨¡å‹è§„èŒƒ

### æ¨¡å‹ç»“æ„

æ¯ä¸ªå®ä½“åº”è¯¥å®šä¹‰å››ä¸ªæ¨¡å‹ç±»ï¼š

```python
class EntityBase(BaseModel):
    """åŸºç¡€æ¨¡å‹ï¼ŒåŒ…å«å…±æœ‰å­—æ®µ"""
    name: str = Field(..., description="åç§°")
    # ... å…¶ä»–å­—æ®µ
    
    model_config = ConfigDict(from_attributes=True)

class EntityCreate(EntityBase):
    """ç”¨äºåˆ›å»ºçš„æ¨¡å‹"""
    pass

class EntityUpdate(BaseModel):
    """ç”¨äºæ›´æ–°çš„æ¨¡å‹ï¼Œæ‰€æœ‰å­—æ®µéƒ½æ˜¯å¯é€‰çš„"""
    name: Optional[str] = Field(default=None, description="åç§°")
    # ... å…¶ä»–å­—æ®µ
    
    model_config = ConfigDict(from_attributes=True)

class Entity(EntityBase):
    """å®Œæ•´çš„æ¨¡å‹ï¼ŒåŒ…å«IDå’Œæ—¶é—´æˆ³"""
    id: int = Field(..., description="ID")
    created_at: Optional[datetime] = Field(default_factory=datetime.now, description="åˆ›å»ºæ—¶é—´")
    updated_at: Optional[datetime] = Field(default_factory=datetime.now, description="æ›´æ–°æ—¶é—´")
    
    model_config = ConfigDict(from_attributes=True)
```

### è¾…åŠ©å‡½æ•°

æ¯ä¸ªæ¨¡å‹æ–‡ä»¶å¿…é¡»åŒ…å«è½¬æ¢å‡½æ•°ï¼š

```python
def entity_to_dict(entity: Union[Entity, EntityCreate, EntityUpdate]) -> dict:
    """å°†æ¨¡å‹è½¬æ¢ä¸ºå­—å…¸ï¼Œç”¨äºæ•°æ®åº“æ“ä½œ"""
    result = {}
    
    if isinstance(entity, (EntityCreate, EntityUpdate)):
        result = entity.model_dump(exclude_unset=True, exclude_none=True)
    else:
        result = entity.model_dump(exclude_none=True)
    
    # å¤„ç†æšä¸¾å­—æ®µ
    if 'status' in result and isinstance(result['status'], Enum):
        result['status'] = result['status'].value
    
    # å¤„ç†JSONå­—æ®µ
    if 'json_field' in result and result['json_field'] is not None:
        result['json_field'] = json.dumps(result['json_field'], ensure_ascii=False)
    
    return result

def dict_to_entity(data: dict) -> Entity:
    """å°†å­—å…¸è½¬æ¢ä¸ºæ¨¡å‹ï¼Œå¤„ç†å„ç§æ•°æ®ç±»å‹è½¬æ¢å’Œé»˜è®¤å€¼"""
    processed_data = data.copy()
    
    # å¤„ç†æšä¸¾å­—æ®µ
    if 'status' in processed_data:
        status = processed_data['status']
        if isinstance(status, str):
            try:
                processed_data['status'] = StatusEnum(status)
            except ValueError:
                processed_data['status'] = StatusEnum.DEFAULT
    
    # å¤„ç†JSONå­—æ®µ
    if 'json_field' in processed_data:
        json_value = processed_data['json_field']
        if json_value is None or (isinstance(json_value, str) and not json_value.strip()):
            processed_data['json_field'] = None
        elif isinstance(json_value, str):
            try:
                processed_data['json_field'] = json.loads(json_value)
            except (ValueError, json.JSONDecodeError):
                processed_data['json_field'] = None
    
    # å¤„ç†æ—¥æœŸå­—æ®µ
    for date_field in ['created_at', 'updated_at']:
        if date_field in processed_data:
            date_value = processed_data[date_field]
            if isinstance(date_value, str):
                try:
                    processed_data[date_field] = datetime.fromisoformat(date_value.replace('Z', '+00:00'))
                except (ValueError, AttributeError):
                    processed_data[date_field] = None
    
    return Entity(**processed_data)
```

## æ–°é—»èšåˆç³»ç»Ÿè§„èŒƒ

### RSSèšåˆå™¨

**åŸºæœ¬ç»“æ„ï¼š**
```python
class RSSAggregator:
    def __init__(self, session: Optional[aiohttp.ClientSession] = None):
        self.session = session
        self._own_session = session is None
    
    async def __aenter__(self):
        if self._own_session:
            self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self._own_session and self.session:
            await self.session.close()
```

**ä½¿ç”¨æ¨¡å¼ï¼š**
```python
async with RSSAggregator() as aggregator:
    articles = await aggregator.fetch_rss_feed(news_source)
```

### APIèšåˆå™¨

**ç”¨äºå¤„ç†é›ªçƒã€ä¸œæ–¹è´¢å¯Œç­‰APIæºï¼š**
```python
class APIAggregator:
    def __init__(self, session: Optional[aiohttp.ClientSession] = None):
        # ç±»ä¼¼RSSèšåˆå™¨çš„ç»“æ„
        pass
    
    async def fetch_xueqiu_data(self, news_source: NewsSource) -> List[Dict[str, Any]]:
        """æŠ“å–é›ªçƒæ•°æ®"""
        pass
    
    async def fetch_eastmoney_data(self, news_source: NewsSource) -> List[Dict[str, Any]]:
        """æŠ“å–ä¸œæ–¹è´¢å¯Œæ•°æ®"""
        pass
```

## ä¾èµ–ç®¡ç†è§„èŒƒ

### requirements.txtæ›´æ–°

å½“æ·»åŠ æ–°çš„ä¾èµ–åŒ…æ—¶ï¼Œå¿…é¡»æ›´æ–°[requirements.txt](mdc:requirements.txt)ï¼š

```txt
# æ–°é—»èšåˆç›¸å…³ä¾èµ–
feedparser==6.0.11
newspaper3k==0.2.8
beautifulsoup4==4.13.3
lxml==5.3.1
lxml_html_clean==0.4.2
aiohttp==3.9.1
# RSSè§£æå’Œç½‘é¡µå†…å®¹æå–
html2text==2024.2.26
requests-html==0.10.0
```

### ä¾èµ–å®‰è£…

```bash
pip install feedparser newspaper3k 'lxml[html_clean]'
```

## é”™è¯¯å¤„ç†è§„èŒƒ

### ç»Ÿä¸€é”™è¯¯å¤„ç†æ¨¡å¼

```python
async def example_operation(self, param: str) -> Optional[Result]:
    """ç¤ºä¾‹æ“ä½œ"""
    try:
        # æ‰§è¡Œæ“ä½œ
        result = await self.some_operation(param)
        
        if result:
            logger.info(f"æ“ä½œæˆåŠŸ: {param}")
            return result
        else:
            logger.warning(f"æ“ä½œæ— ç»“æœ: {param}")
            return None
            
    except Exception as e:
        logger.error(f"æ“ä½œå¤±è´¥ ({param}): {e}")
        return None
```

### æ•°æ®åº“æ“ä½œé”™è¯¯å¤„ç†

```python
try:
    self.db.execute(sql, params)
    self.db.commit()
    return await self.get_by_id(entity_id)
except Exception as e:
    logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
    self.db.rollback()
    return None
```

## æ—¥å¿—è§„èŒƒ

### æ—¥å¿—çº§åˆ«ä½¿ç”¨

- `logger.debug()`: è°ƒè¯•ä¿¡æ¯ï¼ŒåŒ…å«è¯¦ç»†çš„å‚æ•°å’ŒçŠ¶æ€
- `logger.info()`: æ­£å¸¸æ“ä½œä¿¡æ¯ï¼Œå¦‚æˆåŠŸåˆ›å»ºã€æ›´æ–°ç­‰
- `logger.warning()`: è­¦å‘Šä¿¡æ¯ï¼Œå¦‚æ•°æ®å·²å­˜åœ¨ã€æ— ç»“æœç­‰
- `logger.error()`: é”™è¯¯ä¿¡æ¯ï¼ŒåŒ…å«å¼‚å¸¸å’Œå¤±è´¥æ“ä½œ

### æ—¥å¿—æ ¼å¼

```python
# æˆåŠŸæ“ä½œ
logger.info(f"æˆåŠŸåˆ›å»ºæ–°é—»æº: {result.name} (ID: {result.id})")

# è­¦å‘Šä¿¡æ¯
logger.warning(f"æ–°é—»æºå·²å­˜åœ¨: {source.name}")

# é”™è¯¯ä¿¡æ¯
logger.error(f"åˆ›å»ºæ–°é—»æºå¤±è´¥: {e}")

# è°ƒè¯•ä¿¡æ¯
logger.debug(f"åˆ›å»ºæ–°é—»æºå‚æ•°: {source_dict}")
```

## æµ‹è¯•è§„èŒƒ

### æµ‹è¯•æ–‡ä»¶ç»“æ„

```
test/
â”œâ”€â”€ test_rss_simple.py          # RSSåŠŸèƒ½ç®€å•æµ‹è¯•
â”œâ”€â”€ test_news_aggregation_complete.py  # å®Œæ•´æ–°é—»èšåˆæµ‹è¯•
â””â”€â”€ test_models/                # æ¨¡å‹æµ‹è¯•
    â”œâ”€â”€ test_news_source.py
    â””â”€â”€ test_news_article.py
```

### æµ‹è¯•æ¨¡å¼

```python
async def test_functionality():
    """æµ‹è¯•åŠŸèƒ½"""
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•...")
    
    try:
        # æ‰§è¡Œæµ‹è¯•
        result = await some_operation()
        
        if result:
            logger.info("âœ… æµ‹è¯•æˆåŠŸ")
            return True
        else:
            logger.warning("âš ï¸ æµ‹è¯•æ— ç»“æœ")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False
```

## åˆå§‹åŒ–è„šæœ¬è§„èŒƒ

### æ•°æ®åˆå§‹åŒ–è„šæœ¬

```python
# scripts/init_xxx.py
async def main():
    """ä¸»åˆå§‹åŒ–å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–...")
    
    success_count = 0
    total_count = len(data_list)
    
    for data in data_list:
        try:
            result = await handler.create_entity(data)
            if result:
                success_count += 1
                logger.info(f"  âœ… åˆ›å»ºæˆåŠŸ: {data['name']} (ID: {result.id})")
            else:
                logger.error(f"  âŒ åˆ›å»ºå¤±è´¥: {data['name']}")
        except Exception as e:
            logger.error(f"  âŒ åˆ›å»ºå¼‚å¸¸: {data['name']} - {e}")
    
    logger.info(f"ğŸ“Š åˆå§‹åŒ–å®Œæˆç»Ÿè®¡:")
    logger.info(f"  âœ… æˆåŠŸ: {success_count} ä¸ª")
    logger.info(f"  âŒ å¤±è´¥: {total_count - success_count} ä¸ª")
    logger.info(f"  ğŸ“ æ€»è®¡: {total_count} ä¸ª")
```

## ä»£ç è´¨é‡è¦æ±‚

### ç±»å‹æç¤º

æ‰€æœ‰å‡½æ•°å’Œæ–¹æ³•å¿…é¡»åŒ…å«å®Œæ•´çš„ç±»å‹æç¤ºï¼š

```python
async def create_entity(self, entity_data: Dict[str, Any]) -> Optional[Entity]:
    """åˆ›å»ºå®ä½“"""
    pass

def process_list(self, items: List[str]) -> Dict[str, int]:
    """å¤„ç†åˆ—è¡¨"""
    pass
```

### æ–‡æ¡£å­—ç¬¦ä¸²

æ‰€æœ‰ç±»å’Œæ–¹æ³•å¿…é¡»åŒ…å«è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼š

```python
class ExampleHandler:
    """
    ç¤ºä¾‹å¤„ç†å™¨
    è´Ÿè´£å¤„ç†ç¤ºä¾‹ç›¸å…³çš„ä¸šåŠ¡é€»è¾‘
    """
    
    async def create_example(self, data: Dict[str, Any]) -> Optional[Example]:
        """
        åˆ›å»ºç¤ºä¾‹
        
        Args:
            data: ç¤ºä¾‹æ•°æ®å­—å…¸
            
        Returns:
            åˆ›å»ºæˆåŠŸçš„ç¤ºä¾‹æ¨¡å‹ï¼Œå¤±è´¥è¿”å›None
        """
        pass
```

### ä»£ç ç»„ç»‡

- æ¯ä¸ªæ–‡ä»¶å¼€å¤´åŒ…å«ç¼–ç å£°æ˜å’Œæ¨¡å—æ–‡æ¡£
- å¯¼å…¥è¯­å¥æŒ‰æ ‡å‡†åº“ã€ç¬¬ä¸‰æ–¹åº“ã€æœ¬åœ°æ¨¡å—çš„é¡ºåºç»„ç»‡
- ç±»å’Œå‡½æ•°ä¹‹é—´ä½¿ç”¨é€‚å½“çš„ç©ºè¡Œåˆ†éš”
- å¤æ‚é€»è¾‘æ·»åŠ æ³¨é‡Šè¯´æ˜

è¿™äº›è§„èŒƒç¡®ä¿ä»£ç çš„ä¸€è‡´æ€§ã€å¯ç»´æŠ¤æ€§å’Œå¯æ‰©å±•æ€§ã€‚
